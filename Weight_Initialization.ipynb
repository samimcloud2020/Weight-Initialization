{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "If the weights are not correctly initialized, it may give rise to the Vanishing Gradient problem or the Exploding Gradient problem. Hence, selecting an appropriate weight initialization strategy is critical when training DL models.\n",
        "\n",
        "\n",
        "fan_in = Number of input paths towards the neuron\n",
        "\n",
        "fan_out = Number of output paths towards the neuron\n",
        "\n",
        "![image.png](data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAfMAAAEjCAYAAAAmMehkAAAgAElEQVR4Ae2dB5wdVfn+HzqIIqAidorKD0EFsWHBQO7cTUIA6R1UQJAioUpombnp2dy5W1J2N73spkAgCQnSlKYiHQSCys/6U/nbQUBKkj3/ee7OWSab3c2W2+bOM5/P/cyduVPO+d4555lzznveF0jWMhXAWwAMgPUAFgHYL1kIlFsREAEREAERiD+BvQA0AXgzFPUNANoAfCr+WVMOREAEREAERCBZBD4CYDqAN0JR3xgI+nIAn04WBuVWBERABERABOJP4IMA6gG8Hop6eyDoKwAcFP+sKQciIAIiIAIikCwCewLwAbwWijrH1VcCOCRZGJRbERABERABEYg/gT0ATAHwakTU1wD4YvyzphyIgAiIgAiIQLIIvBfARAD/iYj6HQC+kiwMyq0IiIAIiIAIxJ/A7gDGAngpIup3A/h6/LOmHIiACIiACIhAsgjsFmTXBfCviKjfC+DwZGFQbkVABERABEQg/gTeDeB6AP+MiPoDAFLxz5pyIAIiIAIiIALJIvCuwPHMaAB/j4j6zwAMSxYG5VYEREAEREAE4k9g52A621UA/hoR9YcBjIx/1pQDERABERABEUgWgXcElu+XA3gxIuqPAzgmWRiUWxEQAREQARGIP4EdAVwK4M8RUX8KwHEAtop/9pQDERABERABEUgOgR2C8fSLAPwxIurPADgJwNbJwaCcioAIiIAIiED8CWwP4AIAv4+I+nMATpWob/rnGuCzBrjeAI8ZYKdNf9WWCIiACIiACJSfwHYAzgXwm4io/zLYPjNwSrNN+ZNXnhQYYC8DPGWAVw1gws+c8qRGdxUBERABERCBvhHYNmilfwvACxFR53fu42+JWwzwRQP8KSLmmgmQuKdAGRYBERCBeBJga5ytcrbOGaGNH7ba2XpnKz6WiwE+Y3pIvwF2NsCHu8uYAZ4PxZwtdHWxdwdJ+0RABERABCqWAI3hOH7OcXQr6hxf5zg7x9tjsRjgYAM8EgoyX1KYmS8Y4A4D1BjgIAO8aID/7ZohA+wbaZXf0vV3bYuACIiACIhAXAhQ1GnpTot3K+q0hKdFPC3jK3YxwEkGeDMiyDRk28oAfwz3XWyAvQ3wlgHe6JoRA1weOZfDDVpEQAREQAREINYEOBedc9I5N92KOuesc+4657BX1BKK9mgDULBpwPY0ExhpbVPAPxjuu88AdKSzyWKA+8NzNxiAoWe1iIAIiIAIiEDVEKD3OIqfFXV6l6OXOXqbq6jFAD8MBfkyJiywUP9muD3TJjTobn8oMHSjTUDnYoD3BNPRKOJ8EWDAGi0iIAIiIAIiUJUEaN1Nf+9W1OkHnv7g6Re+7IsBPhIKMlvhezBBBrjNAO0G+Fi4zXHxZ7saxxng7FDIKeZXlD0zSoAIiIAIiIAIFJkAI7IxMpsVdUZsY+Q2RnAr2xIZ876biTDAMaFA/zvc5vh5G53CdE1kYP1+S0TMP9H1d22LgAiIgAiIQLUSYOx0dklbUWdsdcZYZ6z1ki8GaA4FmXPFXQNwbJwtbX4mBpbsK02HHcAmaTPAV2gQFx73ugHet8kB2hABERABERCBBBA4HMC9EVH/V5BnF8Bupcy7AY4OLdVp0T4rnE/+o1Ck2bV+WDQ97HoPHMXcHnSx/67L57mux0bP03cREAEREAERqGYCXwfALm7bUn8pcBE7FsDupcq0AXY1XQzzZJleKvq6jwiIgAiIQDUR+AqAOyKi/p9gjvpEaLpXNf3HyosIiEBlEKAXz+uC+nZMPz+cZpxI192V8bfFKxVfBLAmIuqvBtPZpiC0NI9XVpRaERABEahYArMj9aztGe1t/VsA+1dsbpSwiiVwCICVkYftNQA+gD0rNsVKmAiIgAjEh8DeAN6K1LG9CTlnIuWn7sYne0pppRE4CMAKAO3hQ/d6YCRXj9AzW6UlVukRAREQgRgRYN3ak4hvDH9bVokePGPEWEntQuDTAJYDsA8Y/aRPB/CRLsdpUwREQAREoGcCdNhFb5Y/D8Xa1qndifoEAHTTrUUECk7gUwDagrnpG8IH8c2g670JwF4Fv5MuKAIiIALVQ4D2SC0AXom0xunn47HItu0BZff7t6sn68pJJRPYD8CiwCJzffgg8uGjQcc+lZxopU0ERGDgBAywrQH2irhafn+4zX388Pd3ht/3CJxCfcAAu4fb7zDAhw3w0XA7CYGR6LfjEnQEkYq2vOnj47Sw+5xj57ZxxGPo/fKIgf9LOlMEBkaAblTnRUSd4s5tuVcdGE+dJQIVS4BRDA2wLOKlkZ4aHwv8QkwL4iO8EtnP7xcFwj413EfPjt8IIiIuCrefD+ItnNA1owb4XCD087tz39z12ArfHgJgMQDaGFkR/38AJvdQNy4Mj5PFeoX/sUlIHlvkbJlb60yKOlvubMFrEQERqCICBlgSEe4ssxZELjwisu9vYSt9PwM8bADOq+Yxewchj//BiIcWhwEcA9xsgF9Hzv+c/T1G6/cDuDpocf86IuAcD789DE29XS95YeucbrZlsd4LJP1UWgIcO+cYOsfS+UbK7iOOsXOsXYsIiEAVEDDA/xhgYyi+Lxpge2YraH3fGxHkkYGIjzXAUJvlIJ7CNUH0w/F2OzyHXfHfM8CfI+dyFk0clq2DqJTDwxk/tiHDeu+PAQ46hOmPgbAM3eLwjycwjXyIae1Oq3c+3HxDpTU8reK1iIAIxJxA0BV+a0R8T2d2DDAssu9utrij2TTAMxw3j+6z3w3gRc6tdDFn/UaxpmjbbnSKOaeaUdwp8lpEoKoIfDCcl27HjmityQe+0gtrVf0JyowIFJqAAQ6NiC+nWeWXIIzxk5H950T2H2Y6Xujtrk3WBrg+cl4l1g/sJj8u7DaPTidjtzq719nNrkUEqp4APcfRgxw9ydk3WXqYo6c5LSIgAjEkEIyTPxAR4C8xCwY4JbKvwWbLAK0GYGCnbpcKFnMa89JwjQZstu5i44QGbjR00yICiSRAAw/6eqfPd1sw6AueczC1iIAIxIhAYMnOcXFatPPTyqQb4KDIvpcNsIsBOIXt4d6yVmFivmM4dSwaJpr11dPhVLOShorujZt+E4FyE+AcU0ZlY3Q2K+qM2sbobVpEQARiQCAY594qmGL2bCjeb4aivdwAKyKCPiowlrvBAN/pLUsVIua06aG7ajpzsfUSnbzQ2YsaHL39gfot8QQYN53x0xlH3RYexlfvsTsu8cQEQAQqiIABzo4I9y2hRfuOgYX6X8P9vzPA0wZga7fHpYxi3tW9qq2HaAdAt6v8XYsIiEAfCbDbygXwr4ios4vr8D6er8NEQATKQCCYaradAf4vIuj5F/GwNW674NkL1+tSBjHvyb0qW+aaddPrv6UfRWDLBN4dzE2/vks3F50ppLZ8qo4QAREoB4HA+9sVoZj/0N7fALsZgGPm6+nC1e7vaR16kbPif3RPxw1yf1/cqw7yFjpdBEQgSuBdgeOZ0QD+HmmpM6bvsOhB+l49BIa4uV2Hubm9UmOmfm2o6w9Le/7Z9uNk/GtTXm6M/aS97Gj7G9dD3Vwq5Wa/zPPTtbXqFi3xY2GAdxngXwb4fPTWBqjtOtc8+ju/G+CrgZX7jwzQHmnd8wXgtsD9675djx/gdn/dqw7wNjpNBESgJwKsmK8C8NeIqNMqdmRPJ2h/ZRJwXXfrtFt/YCrjnxSKcYvj5e5yPP8Fx/M3OJ5vtvQ5Zfr3t3hMeI1XHc9/NpXxb0t72Ya051+WdrMjjxjnf6gy6cQ/VcEc8s28PIYiz2mpPS4GYAAWBmnZIXpQuC/vBja6vx/fB+NetR+30aEiIAL9IfCOwPL9cgAvRkT9cQDH9OciOrY0BE5cvnybdGbqIY7nX+q4uXmO5z/heP7rvYn1iPF164+trVt/1vRpG85rmW5GLWjq+CxsMjfcPCv/uXDpMZ3fO39f0GTObZpuzmhofOPY2vq3ho/PbeHFIPcvJ+Pf63h+nePlTk2NqdtiF3BpqOkuBSBQSPeqBUiOLiECItATAVrEXgrgzxFRfyr0zCTfxj1RK/L+Q5qbt0u5uSFpL+umM/7djue/0p1wn5Ct3/C92TPMtctazKQ1c8yMexeY1kcWm9vWLTW3P7/lD8W8L8eteqbNLPz5ItN4z3wzftUcc/WSZnNO0/QNIyfUre8uXY7n/9Fx/SXpjH/hEWOnFKprt8jUdfkIAblXjcDQVxGIEwF2yV3UxTfyMwBOkl/k0vyN7LJOe/45ac+/OeX5/+kqkif5DRsvW9hkJt42x8z9yUKz8pklfRLi3sS6r2Le2zVufrLNzPjxApO5dba5YPaM9pET67pryf/acf36lFdXM8R1e51SVRrauks3BORetRso2iUCcSXAaE0XAPh9pKX+HIBTJeqF/0sp4KlMdlTa83/WVbxPqWtoH720Od8aXvF026CFuztBLoSYd3fdxQ8vNlNun2sumTfTjJywqbiHLyoLOeZ+ouvmo4MVnqyu2A8Ccq/aD1g6VATiRoBv6XTw8JuIqP8y2D4zcEozGCOauHEoeHqHuw27OF72fMfz73M8v92K+IjxuXZ2mVMElz9eHPHuKrzFEvPofdY+v9TM/slCc8NNszgOv9HmN1z/2/H8ubS4LzhoXbA3AnKv2hsd/SYCVUhg26CV/i0AL0REnd+5j79p6SOBdKbuS47nz3Y8/zUraMPH5dovmjvT1N8136x+dvDd5lER7cv3Uoh513QsfazVuLfONqfVbybszzuZ7OVD3Kl0TaylOATkXrU4XHVVEYgNAbbG2Spn69y6Z2Srna13tuK1dENgeEPDDuE4+NNWwLmmtbh/5zyzqgwCHhXXcoh59P5tjy4219/UYr45uT46zv5GyssuTmWyB3eDVLv6T0DuVfvPTGeIQNUT4FQVjp9zHN2KOsfXOc6u8c/w7z9y4sTdwrnfL1oRP2Zyfft1y1oMBSwqaOX8Xm4xt3lfu26pmf6j+TSgM+mxuc6hByfj/yjl5Y6s+lJVnAzKvWpxuOqqIlBVBCjqtHSnxbsV9T+GFvGbOKuoqlxvITPDJzS8z3FzWcfz6WQl75Dl9IZGk7trXp+ni1mBK8W6UsQ8mtflT7QaGv4dOb4uOr7+rONlT4Qxmi7Z+zMo96q989GvIiACPRBg5XocAM5Nt6LOOeucu56YKUhsiTuuPz46H/z8lumm+b6FFdMKjwqm/V6JYm7Txrnt41bNMcfVvi3qac9/OuX5cmy0eWGUe9XNmWiPCIjAAAmwkqUXOSvq9C5HL3P0NleVy6G+v1M641/veP5LtiXOrmI6WLGiVMnrShZzy23NuiV5C//jp9RHW+qP0qlOVT5Ufc+U3Kv2nZWOFAERGAAB+nmnv3cr6vQDT3/wVRWwI+1lT3Y8//dWxOkydd5P4yHiVijjIOY2rWueW2Imrpljjp38dkvdyfgrhrq5fQbwjMb1FLlXjes/p3SLQIwJMCIbI7NZUWfENkZuYwS32C60sk55/gNWxM9obDSzHqzs7nQriF3XcRJzm/bbnltivFtmmRHjcral/kba9ScePXlyrJ+rLRQIuVfdAiD9LAIiUHwCjJ3OGOpW1P8ZxlhnrPXYLEe5ze8Ijdvy06iOmVzXXnv7XHN7H/2gWzGqpHUcxdzyu+nJVjNqYZNxMp3W73+oMst3uVeNTe2ghIpAsggcDuDeiKj/K8i+C4AWuBW9ML634/m/ZWu8JpMzo5e1mJW/KL2TFytkhVrHWcwtg/k/W2TOnDatczpbysstTbu1e1T0A9V74uRetXc++lUERKBCCHwdwN0RUX8pcBE7FsDuFZK+zmTQ9WrKzc6xXeqnN0wzCx6K17i4Fb3u1tUg5vl8rVtqxq+eE+16/2cq45/W+UdW/he5V638/0gpFAER6IHAVwDcERH1/wCYCKAi3HkOzeQOta1xul1lVDA6N+lOFOO6r2rEPAz3uuzxVsMpgfblK+36ralJkyp5OEfuVXuoHLRbBEQgfgToqWpNRNRfDaazTQFQlq7SE5cv3ybl5cY4np+P1X1mY6Npe7S1qkTcvnxUm5jbfNX+cG60lf77mozP3qBKWeRetVL+CaVDBESgKAQOAbAyIuqvAfAB7NmHu+3Sh2O2eEjN+NwHHC/3IFt26Yxvrl0+y3CesxWJaltXq5jzf1ryaGt0LH2Dk/FvLLMHOblX3WIJ1AEiIALVROAgACsAtIfC/npgJFcP4IM9ZHLvwF/8rwC8r4ff+7SbYTgdz/8Lhfy4KfWm5YEFVSvi9qWkmsWceeSL2I03zzKBkFsDuTVD3NyufXogCnOQ3KsWhqOuIgIiEGMCHE9cDmBjKOpvBII9HQDn3EaXpeHvnNM+IBeyKS93ieP5b1HIGdFsxVOliSduRbVc62oXc8u16f4F5uiJHc5m0l7uf4e6dZ+JPkBF+C73qkWAqkuKgAjEm8CnALQFc9M3hKL9ZtD13gRgLwBslVux5zz2ZQD6HIzjkObm7Rw3Ny/fre75hlHNqs3IzQpad+ukiDnzvuyJVnNGY6Ntob+W8rLHF7hYyL1qgYHqciIgAtVJYD8AiwCsD0X9LQDPh9+tQxquJ/Ql+7Rydjz/Hgr5iPG59vq751d9t3pXQU+SmDPv9B53GR3NdES025jK5K7sy7PSyzFyr9oLHP0kAiIgAr0RoFONeWFL3Y6rR8Wc37/T2wVSY+o+6nj+s6zUj51Sb+ZX0dzxroLd23bSxNyyGLtydqfnuLSXm8EZDL09L938Jveq3UDRLhEQAREYCIGo5XtXMWeX/BHdXTSV8T9tDd1OrWs0yx9Pxvi4FbLoOqliTgbsiRk+zs/7d09l/NsYAa+75yWyT+5VIzD0VQREQAQKQaDrWHlXMec256vvH73Z0EzdFxzP/ydb5Oc0Ta8Kl6xRce7v9ySLOVnN/ekic/Sk+ryvfSfj3zvEnf7O6PMSfpd71W6gaJcIiIAIFILA7G7GyingHEeniFtxZ0z1/JQ1Og5xPP9lCvmFc2YYhtTsr/hV2/FJF3P+n62PLDbfnFLXIeie/1A4dU3uVQtRSnUNERABEdgCgbMCwR4DYC6AuwCsA0B3sFbEo+ufHXa5O8Lx/Nco5N+f35Qoi/XeXkAk5h3ueZc+1mpOmNqQF/S9vjb0L9hqKwYBss/QK4GPgxYAdPqiRQREQAREoAQE6If7gCCOejo0ghuz4267r91/5AlvUsivWNwc65ClvQnzQH6TmL/ta3/5E63mZL9h476H1+RFfKtttnkUwLkA6H5ViwiIgAiIQLkIhGPk+a71vJCHATkGInzVeI7E/G0x5/9LZ0FHZyZsOPTCq0za83+Wrq2VkJer8Oq+IiACIkAC9PJljd2+P3+mWuTdvMhIzDcVcwo6W+jH1XZ0udMPwRDXHZBXQZVCERABERCBQRI4YtzUj9npZzR2S5JXt/70IEjMNxdz8lvy2GLzzckdVu6pTPZW13XpHEaLCIiACIhAqQiEnt3yDmE4/UxW690LFkVLYt4zm8UPLzZHTeywck95PqP3aREBERABESgFgbyv9dBF62n1DYmfR76lVrrEvGcxJ7tZDywwwzKhYxkv+71SPMO6hwiIgAgknoANmnLslPp2BtbYkpgl/XeJee9izufDv3MejeHoz339UNcflvhCJgAiIAIiUEwCYRhTM2J8XfuChPpa7+/LicR8y2JOpjcwJnqHoL9U4/ofL+ZzrGuLgAiIQGIJpMZM/RrjkbMFlcToZ/0VcXu8xLxvYk5eF82dacOnPtUHP+6JLYvKuAiIgAgMiEDN+NwHrOU645FbodJ6y0IlMd8yI/scrXxmiTnJD6esuTlG7dMiAiIgAiJQCAIMXel4uQfZBXpu03RNQetmLrkVo+7WEvO+izn5LXp4kRk+PhcGZsnRO5wWERABERCBwRJIebkxFPJja+vbVzyd3FCm3Ql1X/ZJzPsn5mRKg7hw/Py1YWPr9hvsM6zzRUAERCDRBIZmcofSwjid8c2sBxaqe72frXIKk8S8/2JObqMWNllBf3iI626b6IKozIuACIjAQAkMdxt2cTz/t2whXbdc4+R9aYV3d4zEfGBivuqZtk6Xr+wdGuhzrPNEQAREINEEHM+fSyE/c9o0c9u6gVXI3Ylb0vZJzAf+7Mx6cKFxMjlauK9nQJ9EF0hlXgREQAT6SyDtTXUcz28fNj7X3vaoHMMM5gVEYj5wMSf30UtbbHf7U+pu729J1vEiIAKJJcCQlLZ7PXPrbI2TD2CcPCr+EvPBifnqZ5eYE7Id09VSmdyViS2YyrgIiIAI9IeA4+ay7F4/vWGapqENUsgp6hLzwYk5Gc68b4Ftnb/KaH39eZ51rAiIgAgkjkAqkz3Y8fwNNZmc3LUWQMgl5oMXctvLccm8mR2CnsmtSlzBVIZFQAREoD8EUp7/AFvlo+XlrWDDC2qZF0bQb36qzRw5oSNcquP66f481zpWBERABBJDIO1lT6aQHzO5vp3TgmyLSOvBiZHEfHD8os/fuFWz863ztOc/7bru1okpnMqoCIiACPSFAINaOJ7/B4p57e1zJeQF6mKnEEnMCyfma55bYo6fWp939ZrO5L7Tl2dbx4iACIhAYgg4Xu4GCvkZjY1mbQGFLNqqSup3iXnhxJzPUN1dna5e/3SU2/yOxBRSZVQEREAEeiNQ4/q7O57/EsV81gML1Cov8MuMxLywYs6XzTOnTesIlZrJXd3bs63fREAERCAxBBwvN4FCfl7LdAl5gYVc3eyFFXLbu9N0f+dUtb+qdZ6YqkoZFQER6IlA2q3dw/H8V9Keb+b9dJHEXGIem2fgrOnT863ztOdf1tPzrf0iIAIikAgC1kHMBbNnxKYSt62zuKzVzV6c1vmMH3e2zv8yxHV3TESBVSZFQAREoCuBIydO3M22yhf+XK3yYr0cSMyLI+b8v85obOxonWf8C7s+39oWAREQgUQQcDL+tRwr/26LWuXFEnJeV2JePDFvuGe+dfP6PIzZKhEFV5kUAREQAUtgeEPDDmnPf5Fi3nK/LNgl5sUT3GKyXbtuqTmutn4jn+OUV1djn2+tRUAERCARBNKefw4rwNMbprUXs7LVtdUyL/YzkFk5J/TZ7q9NROFVJkVABETAEqA7TIp57q55MnwrggV7VMDUzV7cVv+tv2gzw8fVcex8ozO2/hP2GddaBERABKqaQMrNfplC/s3J9RvXrFsiMZeYx/4ZuHxRUzh2nptU1YVXmRMBERABSyDlZudQzK9dPiv2lXi0BVyp39UyL27LnP/7nJ8stIZwfzpx+fJt7LOutQiIgAhUJYHhbsMujue/6mRy7UsebZWYF7lVTqGRmBdfzMn5pFzHNDUZwlVl1aVMiYAIRAk4Gf8CtsrPaZouw7cSCLnEvDRCTs7urR3hUR3XXxJ95vVdBERABKqOgONl76eY+3fK8I0CUIqPWual4bz8iVaTzvjsbv/vEHf6O6uu8CpDIiACIkACR4zzP0SL3+Hj/I2rnpXhWymEnPeQmJdGzMn62zOm58fOUxn/JJV6ERABEahKAqlMdhRb5RfNnVmSFmmpxLLS7yMxL52Yj18VzjlXV3tV1mHKlAiIAADH8x+imNffPV9iXqIudrXMSyfkZL3s8VbDCICO579ML4cq+CIgAiJQVQTCLvb24ePqNqxWF3tJX2bUMi+toJ/Z2NjR1e7ljqyqQqzMiIAIiIB133rhHAVVKXW3vMS8tGI+ZsWsvJg7XnaaSr4IiIAIVBUBJ+OvYBf7lNvnlrRVWmrhrMT7ScxLK+ZzQwcyKc//ZVUVYmVGBEQg2QQOaW7ejmOIHEtc/nibxLyE4+V8uZCYl1bMGUlt5IS6jq72MXUfTXbpV+5FoEQEDPBBA3y4RLdL5G1Sbm4IW+Wn1jVsqMSWa7WnSWJeWjHPv0DNmZkX83Qm951EFnplWgRKRcAAxxrgeQOY8PM7AxxWqvsn6T5pL+tSzEcvbVarvMSt8kpqmS/48XRzwTXnmFO/e6K5oeFqs/a56vU1MGlNxxS1lJddnKSyrryKQEkJGOBCA7xogFkGuCci6Ny3dUkTk4CbOZ5/D8W88R5NSStHL0AltMx/MGWU2ffjnzR77f3xzs+xZx5TtS93ix5eHBrB+b9JQBFXFkWg9AQMsJMB7jXA++zdDfBQKOjtBtDcUAumAOshrrut4/mvcLx8xVMaL0+imPtLx5u99/lEp4hHBX3GyqnVKejrlpojJ+Qo6O1pt3aPAhQlXUIEqpsARdkAZxrgPd3l1ACfM8BX7G9seVPQ7TbXBrgpFPP7ovv1ffAEHNf/PFvlJ2Ub3iqHkOme5TeAO3z44d0KOUW9ccXk6hTz55eac2Z2uHZNe/5Rgy9JuoIIVDEBA3zPAC+HQnwis2qAcwzwmgFONcBwA2wwwB97wmCAHYPr/DU857M9Haf9AyOQzmS/TzG/bGFT1Vbalf7CUM5udo6TU7RPP/9kM3PVVPONmiGdwv61oV83a56r3t6a62/qmG+e9nLjBlZ6dJYIJICAAepCEaYB23oDvD/sQv9vKO4nG+C9oUj/oyckBphgAJ7j9HSM9g+cgOPm5lHMJ6/V/PJyiX45xfyaqZfnxXvywkz+Ze62Z9uMO/0ac61/hbn1yYVV/YJHGxE+++mM/8OBlyCdKQJVTMAA2wTj3DUGuDIU7jXMrgE+H27/jS3ucN8DBritOxwGOCtoyf+fAb7a3e/aN3gCKc9/nBXanJ9Ud8VdLqHuy33LKeYnn3tih5jPd6tauLv7H5Y81mkE12PP4OBLmK4gAlVAwADPheJ9PLNjgAvC7VE2ewZ4wQBD7LZdG2BUMJZ+F1v0dp/WhSUQGr+97mRy7Qp5Wvq5zlZgyinmQ4Z1dKu7M0YnTszXPr/UjBjXYQQ33G3YpbClS1cTgSohYIAvhcL9j6CrfPuwtf6sAd4wwM7MpgGGBgZwq6NZNsB2BmgygBudhhaOr38jeqy+D94FT90AACAASURBVI7AUHfqp9gqP662/k0rLHFar3hsnpl3T2PRPzc/Oq+oQldOMf/M5w7Ot8yvmnhpUfNYqc/VGTboipv98uBKk84WgSolEIyPTw7F/GZmMRDzseH238LtdxtgrQF2twhCy3d2u09haz38pA0wLvh+X1Tc7TlaD5xA2sueTDH/3pwZ7ZVa2faWrovdc4N3Pj5axf2cd81ZRRW6con52nVLzD7h3PLvjT63qHns7X8s52+XLmjqGDf3/HMGXpJ0pghUMQEDzA3F+z+haM8Jt2kQd3s4d3w/i8AAnzXA7yPHWM9vXG/kFDZ7rNaFIZD2sqMp5tcua4llRS4xH9zQwMqnFnZarp/+vVNj+QwM9kXAvWV2h5i7/sTClCpdRQSqjEDYzc4x80cNcDazZ4D6cIyc3eidjhoM8K7Asn2aAeZ181kciPkNVYanIrKT9vwWijldWw62UizH+RLzwYn5TY/M6xTzY047OpbPwGCfO/+OeVbMWyuiUCoRIiACItBfAumMfzfFfOa9C2JZkUvMByfmbT+Z1SnmQ0emYvkMDFbMZz24MC/mjpd7sL/lR8eLgAiIQEUQcDz/BYp526OtsazIL/HO63a8/LQLjzeTFtxYsM/Ce2cUlU+5xswX/HhGp5h/+bAvFzWPgxXdYp2/7PHWUMx9TU+riFpJiRABEegfAWO2cjz/Tfpkvy2m0bFueWKB+Z/PfmIzQd9p551Mbtm42IhTucR89p0NnWJ+4EGfjQ2vQgr7mnVLTE0mPz1tA6dq9q8Q6WgREAERKDOBIW5uV7bKR4yvi7VP9uUPzzF77/fRzQR9l13fZWauro2FQJVLzJtuy3aK+T77ftLQur2QQhmXa31zcn04bq6AK2WulnR7ERCB/hKocf2PU8yPn1L/elwq3Z7S2faTZvPBj+25maDv/r5dzZw76yteoMol5o03T+oUc/pnv+XxeNpO9PRc9HX/KbnGUMyn/k9/y5GOFwEREIGyEkhn6r5EMT+9YVrsxZyV9vwfTTPv2/M9mwn6nh/ewyy6r7hj3n0VjZ6OK5eY+0vGbyLmrQ82V/yLT08MB7P/WzM6oqc5mZzcRpe1VtLNRUAE+k0g5eWOpJif1zIj1t3s0Uq8ea1v3r37LpsJ+kf2/ZBZ+rNZFStU5RLzKQu8TcScY+hRnkn5fsHsGR0tc4VC7Xc9ohNEQASKQ+AqADMAdDrj6ek2TiZ7BsX8+/ObYun9rSehaVgx0ez8rndsJugfP2AfU2y3rD2laUv7yyXm42fdsImYT781HjYGW+LZ399HhV7gUpnsWT2VF+0XAREQgVISuDF0bdqODp/3R/R0cyeTO5difsXi6utarV3smh123GEzQT/w8/ublRUY1rNcYs5Qpxwrtx9/6fhEtsyvbG3uaJlnct/tqbxovwiIgAiUkoAV86iQPQmALY7towlxvNxFFPOr26pPzNkyG9sy2my73bZRDvnvXzjsYLP6mcqaV18uMb8ud0WnkFPQJycwDCqflauXdIh5KuNfHC0j+i4CIiAC5SLQVczZQreC9hcA1wJ4DxOX9vzLKOajl1anmLOSHp0bZbbeZmub/871YcMPNWsraG59ucT8B1NGbSLm41quT2TLfPSylnzL3MlkLy9XwdV9i0OAsbXH6CMGMXwGfhwR707x6rLvDY6rH3zW+VmK+XXL4xlkpa/jopeOO99stdVWm7EYduLQihGucon51ZMv3UTMkxjTnM/R9TfNyot5KuNfUxxJ0VXLRYBCvlnh1z4xqbJnoP0jX/yauW7pzIoRtb4KdH+PO+8HZ3Zbnk8456iKyHu5xLxry/zGxqsrgkd//9/BHn/jzR1i7ng5BXQql+oW6b5qmatnIq49M31pmf8BwNQDjjtlRhJa5raip7/27l7Gzh51StkFrGxiXnvZJi3zGxp+UHYW9v8q5Zq9UywLapkXSVF1WREQgX4T6DpmbgUsL+AAvmyvmIQx866CcMyZwyyPTdYX3vCdsopYucR89NTLNxFzWrd3ZZaEbdqNUMxZJmz50FoEREAEykkgKuabCXg0YdVuzd6dCF3XcPkmIm5b6l9Nf6msIlYuMb++7spNxHxs83Vl5dDdf1aKfZzRQTFnmYiWEX0XAREQgXIROI9d6NEWeE8JqeZ55t0JQP1NE7qde05nMrc+WV6f5OUSc3ar2znmXE+ce2MixZy+FvLd7F6W5UeLCIiACMSHQMQD3IbuxK+a9i348TTDoCu2JW7X9OW++IGmsgtYucTcm3ntJmI+ZZFXdhbleO4uDT3AOV7uzPiUYKVUBERABABY3+znNs+oikArPYnAisfmdRsidad37Gim3TqpIsSrXGI+fvam7lyT6gHu/Fmhb3Y3O1KVgwiIgAjEisDbUdMaX+tJCOO+f82zbeaQr392sxY5HcmMmXFVRQg5GZdLzLsGWmFI1Lj/5wNJ/1nTp+W72YdmcofGqhArsSIgAiJwxNgp+3Kc8Ngp9VUr5kee6mwm5OxiP++asypKtMol5myJR8fMm1ZnK4rLQIR5IOec5Dd0GMCNrf+EagYREAERiBWBIW5uV4r5iHG5NwdSAVb6ORRsOzYeXY84xak4wSqXmE+7ZcomYj77h3UVx6YUz9nRE+vyYl7j+rvHqhArsSIgAiIAY7ZyPP/NtOeb2yrIT3khKu8bp13ZrU/2g7/yaXPbs5UVZIX5LZeYz7q9bhMxX/Cj6YkT89vWLTVOhtPS/PWu626tmkEEREAEYkfA8fwX2DpvfWRx1VTijGe+406bhz/96L4fNjc9Mrci81kuMV90X9MmYt5aAZb9hXiZ6881ljza2tHF7vm/i10BVoJFQAREgAQcL3cXxXzGveWdZ92fyre3YxfcO928Z4/dNutef/fuu5i5dzdUpJAzP+US8+UPz91EzJc9NKdiGfX2vw/mt+b7FubFPOX5dIWsRQREQATiRyDl+s0U80lr4l+JcwraPv/zsc2EfPsdtjPZtkxFi1S5xJzW/nvv84lOQb/l8ep4qeuPuNfePte2zOfGrwQrxSIgAiLAueYZ/xqK+bXL4h0GlaL0hcMO3kzIGfr06qmXVLSQl7Nlznvvf+CnO8V89S+qZ7ilr4J+/U02lrlPV8haREAERCB+BBwveyLF/PyWGW/0tfKrxONGnpbeTMhpwX76xSdUvJCTZ7la5rz3F77ypbyY773vJ2LBqtDP38VzZ3a0zDPZM+JXgpViERABEWDLfGxuf4r5sVPq/1voSrJU1zt/9NndCvmQkV+NjTiVU8yPGHFEXsz323//2PAq5LN1Si6cY+7mDlKlIAIiIAKxJHDi8uXbOJ7/XyeTa1/1TFvsKvMpi8Z0OwVt/4M/aVY9vSg2+SmnmB97xjF5Mf/M5w6ODa9CiTmnZNZkcmyZrx/e0LBDLAuxEi0CIiACJOB4/qNsnc/+ycLYVeYXu+d22yr/4jcONs6x3yjo54ZpVxSNTznF/NujzsiL+aFD4tOTUSgxX/DQImv89pxqAxEQARGINYGUm51DMY+jRXtPYh71+Fao76dfVLzx93KK+WVjL8qL+YgThhftZaVQ4lvo62TvmNch5q6/JNaFWIkXAREQgVTGv5hifumCptiFQpWYLx20AN/YeHVezM++5PRBX6vQYlvs613d1hHH3PGyP1BNIAIiIAKxJpDKZA+mmB9fGz8jOIl5/8ScU/hmrJxqZt/5tgOd8XNuzIv5dbniDSMUW5QHev3TGxrzLfOajP/1WBdiJV4EREAEQiO4l+mj/ean4mUEd3XtJeb9H3pfST7fHV28SGul6GankNd8M50XbkZKO++qb5m165aYqyaNyu+bf8+0RLXMVz7Tafz25qG+v5NqAhEQARGIPQEn49/J1nn93fMTVaEPtEVX6PNKIeYNN03qFHIb9pRGb5ySlkTjN+vG1fH8h2JfgJUBERABESABx8vdQDG/eklLe6GFStfbcld4KcR86qKxm4m5FfXr669K3EvcDTfPCo3fclnVAiIgAiJQFQScTO6rFPMTpsZv3LwaXhZKIeb0Xb//gQduJuhHnTQi391eDRz7k4ezp0/Li3nazY6sikKsTIiACIhAOG7+Twr6kseS55+7PyJQjGNLIeZMt790vPn8V76QF/QDPvNpc/7V3zFJ9Md+6y/arLOYN9K1tTurBhABERCBqiHguP4SivnEKoigVgzBLeY1SyXmNg80fLPfk7iuu6tjfnk6499dNQVYGREBERABEnC83JkU83Obp72ZxAq+nHkutZiXM6+VcO9RC5s6xss9/wqVfhEQARGoKgJpt3YPx/M3DBub2xBHP+2VIBIDTYPEfMtGggNl2/W8teuWmmMm17XzxbUm4x9QVYVYmREBERABEnAy/r2s5Pw75iW6G7arABR7W2JeOjFvuX+BbZU/r1IvAiIgAlVJwPGy51PMz2uZ8VaxBUzXf1vAJOZvsyj2c3HF4tCFq+t7VVmIlSkREAERGOJOfa/j+W/VZHIbafFb7IpV1+8QMYl5acScXexHT67Pd7Gn3foDVeJFQAREoGoJpDP+D9k6n3L7XIn586URGYl5aTg33dfZxa6Qp1VbgyljIiACeQJOJnsGxfz0+gZZtUvMq+qF7uK5M/Pj5Skve52KuwiIgAhUNYEhrruj4/l5BzILHlpUVZV5pXbrq2Ve/Jb5iqfbTM3YHLvY1x8xzv9QVRdiZU4EREAESCDt5nJsnV/R2ixf7SVonUvMiy/m41bPtlbsq1XKRUAERCARBFJjc/s7nt8+Ylxu/apnk+0trBSteYl58cX8lFxDh5i72aMTUYiVSREQAREgAcfL3s/Wudy7Fl9oJObFZfz23PLcn4e47rYq4SIgAiKQGAKO5x9LMT++tuEtTukpRQs1qfeQmBf3+Tq/ZXpHqzzjX5uYAqyMioAIiAAJuK67teP5v6KgMzBFUoW2FPmWmBdPzBc/vNikPZ9i/mqN6++u0i0CIiACiSOQ8rLnUcxPr29YXwpRS+o9JObFE/PLbFAV129MXAFWhkVABESABDhNLe35L1LQ6XAjqWJb7HxLzIsj5sufaDXDxuWDqmw4YuyUfVWqRUAERCCxBFKZ3JX51nlDo1rnRZqmJjEvjphfaf2we9m2xBZgZVwEREAESOBQ39/J8XJ/pqA33jNfrfMiCLrEvPBivvTxVuskZsOwsXX7qTSLgAiIQOIJpDP+hRTzk3MN62+XZXvBX2gk5oUXcztWnnZzCxJfgAVABERABEjgRNfd3vH831LQs4p1LjEvQu9EIe0SWh9ZbGoyedetb2msXHWYCIiACEQI2AAsx0yqW7/yGXmFK6T4qGVe2Jb5+bNmhN7e/JmRR1hfRUAEREAEYMxWac//GVvn1y6fVfDWaSHFMW7XkpgXTsxn3tsZ5vSl4RMa3qeSKwIiIAIi0IWA4/qfdzx/47CMv7Ht0cUS9AJ1N0vMCyPma9YtMSfnGhkZzTiZ7OVdHl9tioAIiIAIWAKO589mZfndlhmKqCYxr6gXuvGr53R0r3v+r2jnYZ9ZrUVABERABLoQSLu1e9h45/6dcvNaiC59tcwH3zJf9nirGTEutzHfKnezI7o8ttoUAREQARHoSiDt+Wez0jxqYt2GFU+1VVTrrBDiWuprSMwHL+bfbekwekt5uaVdn1dti4AIiIAI9EDA8bJ3UNAvnjtTYj7I7naJ+eDEPHfXPHP4tRPN10Zd92/2HPXwyGq3CIiACIhAVwJHjJv6sZTn/4eCXn+3utsH05qXmA9czG9+qs0cPalu476H15itttpqPYDpAD7Q9XnVtgiIgAiIQA8EnIx/AcV85IS6jcsfV3f7QAVdYj5wMbfd63t+5nO/B0AxNwD+C6AWwHt7eHS1WwREQAREIEog7fkrKejfmjGtXa5eByZKEvOBcZtwW6f1+t9rxufYGqcPdo6Zt4ei/h8AGQDvjj6z+i4CIiACItCFwNAJ097jeP6fKOhjVszW+PkAxs8l5v0X80UPLzLDx+VdtpqU5x/T5bH8DIDVoaCzpf5PAKOD1vrOXY4r6qYBvmmAs/v4OSJy3LEGiG6fa4B3FjWxurgIiIAI1HjZw+lMJj02195830IJej8FXWLePzGnO2HrHCbl+s29lMAvA7gnIup/BfB9ADv0ck7BfjLAwQa43wAm/LxkgK8ZIBfZx99GG+CjBnjMAPeG5+1rgGcN8L8GqLGJMsA2BrjUAL8wwD/C4z9tf9daBERABAZFIO1lXbbOj55Yt5HhJwc6fpzE8yTm/RPzi+bODJ3DZJ85ym1+Rx8e3MMB/DQi6n8EcB6Abftw7qAOMcBHDPBGKN5c78YLGuCWiKBfGu57xACd1vgGeDwQ62/YBIRCvioi4v8Jr/EXtdwtJa1FQAQGRcB13a1TGf82CvppDY3tq59VMJa+vphIzPsu5uNWzbZe3v7tjK3/RD8fWjqTeSIi6i8AOCMYV9+6n9fp1+EGmB0R7it5sgG+ENn3pAG+bIAJ9sIGOJBibrfDcy4OzlsbtOzzNgBhK9+2+r8ZPVbfRUAERGDABFKTJr3b8fxfUdAvma/55xLzvot0X1g137/QcCgnP6Tj+UcN+EENovoCWBcR9WcBHDeI6/V6qgH2M8DGULx/xxY2TzDAjyKC/rABOgPDGCDLMfTohQ2wpz3X7g+66N8Mr3Gq3ae1CIiACAyawFB36qfs/PMbblJ0tb6IlFrmWxZ9xijnFEi+KKZcf+ygH9QOQT0LwG8iov4YgGEFuPZmlzDArRHhzreiDeBE9v3cnmSAHQywzgA72n3drQPBf1d4/usGeH93x2ifCIiACAyYwFDXH+Z4/npWvLW3z9X4+RYM4iTmvYs5XQafkG3IR0NLe/7NHNIZ8MO5+YnbATgfwJ8iov4gImPVm5/S/z0GODQi3D+2Vwgs3p8K96/n+Dr3G+BMA4y3x/S0DrrhjwrPndrTMdovAiIgAoMikPb8cyjm7Badce8CCXovgi4x71nMaXtx5rRpHWFNPf+hQ31/p0E9mD2fTAv3ywD8LSLqdwL4Qs+n9O+XYLrZA6H4thvg04Fgb2eA30ZEfhKvaICfBOPsH97S1cPr0UiuWEy2lAT9LgIikAQCjpfNUNBHjM+1z/mJpqz11OUuMe9ezBmf/PxZHQFUHM//zfAJDZ1jykUsP5zPfV0whe1fEVFfCeDAwd4zmHo2MiLcMwzwPQPUGuDX4f5/0nrdAMu3dK9wetrTRl7utoRKv4uACBSCQMrNzqGgj5xY1z7/ZxL07gRdYt6NmK9bat6egub/bdjYOnp3K+WyazB1bRyAV0JR3wigDUB/Leg702yArcK547RAf9UALxhg91DUrVX63wPDuK93ntTNFwOMCMbbf2qA99ifOeXNAKfYba1FQAREoKAEOL7peNk2CvpRE+vaFzy0WF3uXbrcJeabivna55eaUQubOqegpTLZgwv6UPbvYuwN8AG8Hoo6/b/PBvCx/l2m4+jQy5sV7hu5l93kBvh/Yev8yd6ua4AvGuAZAxxggL3Cz5dCy/iTejtXv4mACIjAoAicuHz5No7n30JBP3pyffvCny+SoEcEXWL+tphTyK9c3GyF/JWUm6UXt0pYPgSgCcBboai/CaAx2LdnfxIXjpP/nwHYAn+XPTdwLHNNKObfsfu6rg3wyfA8+zIQXdMhTef1up6rbREQARHojcB3g4ptTF8+W2+7bWafw1LPpcZMzXe5z/2pBN12uUvMO8R87bpNWuT/pZvg3h6+Mv22D4AFADaEov4agMmBsHd2eW8pXQa4LOhmzzuPscfSEYwBnu9tOlrQJd8Qum+ly9foh0ZwHALQIgIiIAIDIsApMQxk0ZfPb3febbfPcGqRNYpruV9W7hR0iflSQ2O3yBj5KxUq5NFCsj86DNVshLaXw5faXaIHdfedY+fd7dc+ERABESgXgS/1Uch/htDndL7L3c3No6APG1fX3njP/MR3uSddzDn9LGK1/u+hmdyh5XqgB3BfjuevjZSDfwTx1K8OWuuaLjYAmDpFBESgPATYwmAkqt5a5svQ1ZOVMVs5rl9PQU9nfDNudbJDpyZZzG9+ss2cNW2aHSP/W5mN3QZTir4CgM5gbFl4EcDFALYfzEV1rgiIgAgUkwC9ZtFy9r5I5WUrseiagSN67FJMZfxr6Gebok6jJ46Z2nHkJK2TKuaLH17c6dmN88jLMP2sGGVkKICHIuXi9wBo1Fb0CG3FyIyuKQIiUJ0E6JWKfrHZ6rCi/Wrku93H6Tvf7gsCx8ue6Hj+fyno57VMN7f+oi1xgp5EMae9xJET6js9u5XIIUxfHslCHTMSwNORsvErAAyG0uPLbaFurOuIgAiIQE8EagDcGnjGokhbwX4KwAUA6DGLrQ+7n4ZAR/R0oe72pzN1X3I8//9R0E/MNpikzUVPmpiPXTnbRj8zTsa/qYguWrt73Eq5j8J9MoBfRsrHLwAcU8pE6F4iIALJJrA7gMsB/DpSEb0ReMBqBcDxwehirdr/AIBWvv1eUmPqPup4/qMU9OHjcmbqD5MToCUpYr7ymU0s1tsZ/azAQVP6/dyV6ASGPP0WgN9FytIjAJwS3V+3EQERSCABBpaYG1jk/jdS8bAS+gEi8Za7cKFVe6fFepff+rw5vKFhh5TrN1PQ+bl8UZOhpXO1j58nQcwXPbzYnJxrtN3qL6UHF4+8z89UhR1IW5PvAfhzpGzR7uRrFZZOJUcEKpeAAbYNXSAeqHmem/1PnEZDI51HI5UMfVGvAcCxvy2FnGR3Yq+xlze7Yy870p5/tpPpGEc/yW8w86rcwUy1i/n41XPY22KF/Bc1rv/xXv7+JPzEskKnMX+PlLcfAjgkCZlXHkVgQATC4AaXG+AfkYhFv+pLiMEB3TBeJ30y9DsdjRDFEJD0aLVXObOSdusPTHv+02yhD8v4ZsyKWVVr7V6tYn7zU215o0bb0+J4uaaj3OZ3lPO5qrB70/3qDQBeioj6CgAHVFg6lRwRKD8BA9QZ4FYDfMwAx0QEPVP+1JUlBRy/OxYAYzVbozWu2U1+OgDGda6I5UTX3d7x/Kl2+hrnIy/6efUFaqlGMffvnGeOmlRnW+N/T3m+jL56LlW7BfPROY3Tzgxhr9giAEnvweiZmH5JHoHA1/EkEwpUGORgQyjoJyaMxgfCVsD/RUSclQeDRxxUySzo2tPx/D/YVvp1y1uqaiy9msR82eOt5rstnTHIjeNl76gZn+Ozp2XLBPYAUAeAhqZ8wWZQlxYAH9nyqTpCBGJEwAAHGaDWAB+1yTbAB0w4phsEKjg5iBHM1mW3iwHGGmA9IxR1e0B17hwS+pC20Z5YSTwH4JKgi32LfqQrBcnRkye/K/Qat4GizilsM++rDt/u1SDm9K0+ftUcM2J859j4P51MlhbcWvpPgOJNEbdlluJOkafYaxGB+BIwwPZhxKD2sFVNoyy+uk4Ot88NhZwhAf/SNafBubsbYI4B1vKFoOvvVbhNkaZYU7Qp3vYtf3ngtY3iHtulxvW/6Hj+U3Yclj69Wx+Jd9d73MW86b4F5pRco3XJahzXX5J2ayU8gy9l7GZndzu73VmG2ZPG7nh2y2sRgXgRCA3YVhmAYf4o1q8a4J2hQNsu85qgxb6zAV4yALuR80t47g/C/Tz3TQMsMEC1GuHwRYXd5nbsjRUAedDIpmq6Ooe47rapTO7KtJd72Xa9X72kObbe4+Iq5nyJ+u6saJe6/6u0lxtuy5/WBSNAgzgaxtkXcxrMsUwrfnnBEOtCRScQdI1vY4B9gtb5hFDMGUuYT/Vh4favI93sPzXAfJuoUPC/Hezbi/vD4ynq1WT8RoM1Di3QgM0Wdq5p4EZDNxq8VeUyxJ36XlpIpzO5fNf7yAl15sYVs2In6nET86WPt5rLFjaZmkxnl/q/nUz28kOamzmPWkvxCHDqGqew2XLOqW2c4lawaaHFS7quLAIdTy4F/U+hGB9OKAa4Ntymv2Nub22APxvgU91BM0A6IuYcj4r7wqljnELGqWS2cHOKmQ+AU84Ss9Rk/ANoaGW73o+aWJefyrbqmXj4eY+LmC9/otVc2dpsasZ2ivhbjuvP5EtVYh62ysgoncxEgxzRCQ2d0ehlqjL+H6WiJwIGGBEK8e/CrnN2s1PcX6YzGJ5HwzcDNPZyjW+F1+C4+zd6Oq7C99N5C+0F6MzFjqNRyOnshU5fEh1D2cnkvup4/j1RUb9uWYu56cnKFvVKF/NFDy/Kt8SHjc3ZcfH1jufPP2LslH0rvLxUe/LoDpZuYe3LPD010uiwanvjqv0Prfr8GWBGKMRLwxZ4W7j993D74wbguHqPc6QNcFd4zvUxBPa+0J1q1Lcz3a3S7Srdr2qJEEi7dYelPP/HVtRrxubM9+fPNAseWlSRrmErVcyb71tozm+ZbgWc6w1p128d6mYT1fMTebQq9Svn8DOAixV1BnZhgBdFaKvUfyyp6Qot0TnWzWllHCOnUZu1bH/BAPcboLOrzwBnBwZzR5FXFyO4M2PGkAFNGNjEzjtlYWXgEwZAYSAULb0QcFz/8ykvt9SOqVPcz542zUy5fa5ZVUE+3ytJzFc81WbGrZqzqXW657+a9rINQ93cPr3g1k/lJUDh5pAjQ61aUWcI1vzMn/ImTXcXgZCAAT4ZTClbaYBFBvgydxvgIgPcbgC6at0+CssAq8NW+B8M8HQ4v5yt2zgsO4ehRRli1BZKhh5lCFKGItXSTwLpcdmP0JNcOuO/ZFvrR47PmcsXNZtZD5R/rnq5xXztuqVm5r0LzEVzZ5pIV7pxvNyf0152dI3r68Wxn89cGQ/nsCOH3KJhiR8CMLSMadKtRWDgBEIL9rL6F+9n6jn9hGP+jAduRfzFYPxrLIAP9/NaOrwbAkNcd0cnkz3D8fz7rKhzfWxtnflBW4uZ/eDCsnTDl0PMKeAt9y/IR6Y7elJdtCud4+GrlVOXRQAACP5JREFUHTd7NKcAdoNRu+JBgA2ciwGwDrH1yY+7CV8cj9wolSJQ4QRofXpSF8tUFjxaqnK/rFOL9Acycpfj5SY4Gf/3UWE/bkq9uWJxs2m8Z75h/O1ShF8tlZjf+os2U3fXPDNqYZM5ZlMBp5g/l/Ky1znu5A8WCbkuWx4CNIq9OhD2f0REfS2Ag8uTHN1VBKqLAFvabHFH35rZImfLXBGTSvxfD83UfcFxs5O7CjujtX17xvT8NLfm+xcWzR98scScLyNN9y8wN9w8y5w9fZpJZzrixNuXl5Tn/9JxfY9T+0qMXLcrPQF6hRwT6flrD90871/6pOiOIhB/Ahzz5tg3x8Bt1xfHxi8AwLFyLWUmkMpkD3Yy/rXsik97PrucO7ugazI5c0Zjo6G3OUYFo3X8mucG33ovhJjf9tySfHqyd8wzV7c1m9PrGzcTb8fz30hn/LvpPS81NqdKvMzPWplu/57QP8VrYR20AQAdccm4sUx/iG4bHwI0HqL1Oa3QrYDTOp1W6rRW11KhBPLBXTz/WMfz6xzPfzRqFW9FngJ/al1j3njs+ptaTO3tcw2ndC15tNXcvm5pn7rp+yzm65aatkcX51vbtMi//qZZ+fueUtfQnXDzJeRNx/N/nvJ8P+XljlQs8Qp90MqTrD3DnsA3w3qJQV3oCvpD5UmO7ioClUuA8785D5zzwa2Ic574DwDExbK+cumWIWUUw5SbG5LK+Nc4Gf8mjjPbWOtW3LuuaVx2/NR6852Z0/JztkctaDL80B0qu7/5oZjb79xvj2EoUZ7H87sYqXX2FkTut8Hxss84Xm552vOvqsn4Xz/U9xPtRKgMj0gcb/mxwMB2dqS38PXQi6TqqDj+m0pzwQiw8uS0EHpkswJOT2302Mb5nvTgpqWKCNBCnl3zqYx/WsrLjXHc3Dwn49/rZDrir0fEtjsBzu87Zfr3e/ytm/N/GzrEmetk/BsdL3eq4+YOGt7Q0KPDpCrCrawUj8AnAjfQbRHPkq8AGBeEXt21eLfUlUWg8gjQIxZ9otM3uhVx+kyn7/Q4TY+rPLIxTxH9lg9zc3sFAv8Nx82OSHv+2Z2fjH89XwDsJ53xr+/8zfPP5vE8j+fL/3nMH4T4JP9AACsj9RjrtOsAvDM+WVBKRaB/BOj/mFHJGJ3MCjjXjF7GKGZqKfWPp44WARGoHAIcJozWbWycXKZ6rXL+IKVk8AQYF5yxhBkn3Io444fTeITxxLWIgAiIQLUQYFCqByN13Z+CKbXnywdGtfy9yczHkHBeJq0+rYg/B+CSoIudczi1iIAIiEC1EhgW2P08Fqn7fgPgLEVoq9a/u/ryRZGmWFO0rYBTzJcHXtoo7lpEQAREIEkEjgPwbKQ+XBfUjycmCYDyGi8C7C5ntzm7z62Is1ud3evsZtciAiIgAkklwFk5ZwS2QS9E6scngtjqI5IKRPmuLAI0WKPhGg3YrIBzTSMQGrrR4E2LCIiACIhABwEG4jkvmI77x0id+VMAh28BkGJObAGQfh4YAU4d4xQyWmtaEed0DE4145QzLSIgAiIgAj0TYEPo+wD+GqlD70EYrrrLaXsDYCteTmm6gNHmwAiwm4hOXOjMhU5drIjT2Qudvshz1sC46iwREIHkEmB8idGBndE/I3XqagCfiSChtznWtxxrl6BHwOhr/wjw4aE7VbpVtQJOd6t0u8p5lVpEQAREQAQGR+DdgbfLTBCT4j9hPcsIbUuDKW5DAXSdDSRBHxzrxJ3NgCYMbMIAJ1bEGfiEAVAYCEWLCIiACIhAYQm8N4gGWRuJTxHtBbX1MC3jJeiF5V51V2OXD0OLMsSofXAYepQhSBmKVIsIiIAIiEDxCXAG0KJIPWzrY7t+RoJe/D8hjnc4IAzt93Lk4XkxsEYfG0QH+nAcM6Q0i4AIiEDMCdixcivgXdcS9Jj/wYVKPqc6nBQ4crkvIuB8WLjN/ZoKUSjSuo4IiIAI9I8ALdijY+VdhdxuS9D7x7WqjmZLmy1utrztA8EWeSMAttC1iIAIiIAIlJdAb61yGsfZuptrCXp5/6uS351j3hz75hi4fRA4Ns4xco6VaxEBERABEagMAmcH9fSYYJiTos7pwPTxzoAttu7uupagV8b/VrRU0Oqc1ue0Qrd/Pq3TaaVOa3UtIiACIiAC8SLA3tXPh34/zo2I/iR53YzXH9mX1HL+N+eBcz64FXHOE+d8cU1p6AtBHSMCIiACIiACZSBAD2z0xEaPbFbAOUeRXTT03EYPblpEQAREQAREQAQqkAB9odMnOn2jWxGnz3T6TqcPdS0iIAIiIAIiIAIVSIDRyBiVjNHJrIBzzehljGJGJ/5aREAEREAEREAEKpAAvQIxPjjjhFsRZ/xwxhFnPHEtIiACIiACIiACFUpgCIDlXZwIPBdE2rkk6GLfpULTrGSJgAiIgAiIQOIJUKQp1hRt2wqnRyCKOsVdiwiIgAiIgAiIQIUSYHc5u83ZfW5FnN3q7F5nN7sWERABERABERCBCiRAgzUartGAzQo41zRwo6EbDd60iIAIiIAIiIAIVCABTh3jFDJOJbMizilmnGrGKWdaREAEREAEREAEKpAAnbfQiQuduUQDz9PZC52+0PmLFhEQAREQAREQgQokQDeqdKdKt6q2FU53q3S7SverWkRABERABERABCqUAAOaMLAJA5xYEWfgEwZAYSAULSIgAiIgAiIgAhVIgCFFGVqUIUatgDP0KEOQMhSpFhEQAREQAREQgQomcCOAlyMi/mJgjT42iEvLsHVaREAEREAEREAEYkCAAeXZGr8PwEkAtotBmpVEERABERABERCBCIH3Ajggsq2vIiACIiACIiACIiACIiACIiACIiACIiACIiACIiACIiACIiACIiACIiACIiACIiACIiACIiACIiACIiACIiACIiACIiACIiACIiACIiACIiACIiACIiACIiACIiACIiACIiACIiACIiACIiACIiACIiACIiACIiACIiACIiACIiACIiACIiACIiACIiACIiACIiACIiACIiACIiACIiACIiACIiACIiACIpBwAv8fEwrfWx3RXU0AAAAASUVORK5CYII=)"
      ],
      "metadata": {
        "id": "8Lmtqru1q248"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "For the above neuron,\n",
        "\n",
        "fan_in = 3 (Number of input paths towards the neuron)\n",
        "\n",
        "fan_out = 2 (Number of output paths towards the neuron)\n",
        "\n",
        "\n",
        "#Weight Initialization Techniques\n",
        "#1. Zero Initialization\n",
        "As the name suggests, all the weights are assigned zero as the initial value is zero initialization. This kind of initialization is highly ineffective as neurons learn the same feature during each iteration. Rather, during any kind of constant initialization, the same issue happens to occur. Thus, constant initializations are not preferred.\n",
        "\n",
        "# Zero Initialization\n",
        "from tensorflow.keras import layers\n",
        "\n",
        "from tensorflow.keras import initializers\n",
        "\n",
        "initializer = tf.keras.initializers.Zeros()\n",
        "\n",
        "layer = tf.keras.layers.Dense(\n",
        "3, kernel_initializer=initializer)\n",
        "\n",
        "\n",
        "#2. Random Initialization\n",
        "In an attempt to overcome the shortcomings of Zero or Constant Initialization, random initialization assigns random values except for zeros as weights to neuron paths. However, assigning values randomly to the weights, problems such as Overfitting, Vanishing Gradient Problem, Exploding Gradient Problem might occur.\n",
        "\n",
        "\n",
        "Random Initialization can be of two kinds:\n",
        "\n",
        "Random Normal\n",
        "\n",
        "Random Uniform\n",
        "\n",
        "##a) Random Normal:\n",
        "The weights are initialized from values in a normal distribution.\n",
        "\n",
        "![image.png](data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAFAAAAAPCAYAAABzyUiPAAADXklEQVRYCd2YWahOURTHf2aZx8xTZjLLPGaKjKFMmed4MJUhCoUoiki8mpIIpSilhDzwoDzwRJ7IG0UpnH/trfWtznfu+XLv7XZX3fZaa6+9z95r/9fwXahetBAYXoFXWgE0rcD9y23rRcAd4Acw0uzaBrgEfAaOAM3NXD9gn5HFLgHmhb9xbi5LbADscN+WfR3gAlAja3FVmdsC3AOuugM1BNY5ncTbQG2jnwrsMfJloIuRi7Hzg/PeArNTjPS461P0VU4lB+oCv4CW5nQzgHZGFjskQcVhp3sU9FG9HDgWhRzjs4BcbyoUPvfKQcB+QCESqX9g6gFrorKSxvrhmwqVjy40N6acQY6ZaPRC4k93HyHypbEpiy3mQK1TeukRN+gY8sky4FBQKrd8CnzvRP8bUF7ISy3CheoWWWARlWYyGdB3RXuDE2sGWcj09MQldyH0D9DMGI4PudOoMtksBx4AFsfVqwCh7IyJ7QXBy9HmRuLkeAEl67RLRFtt/DQ8ivKSd5ZQtSkaFxm3G73WK4znAI3MGY0J760AdE9x4Bjgu7PLErMcuDnkyYL1H0xVkzN3mtkNhheqOhvZsnoIm4uaJEi6DnQ1RtOT4jDUyGmsD9MrwIMkBGcCvVIWvHO6TsGB9vEmAV+dXZaY5UBF60G7eATw2CheA8OCbBEjBw02dp7tmyRYOciSLqFqejy5/LUkFZy0kym8kO4ROjakEbUQaeQRqESvtCMkRlJ1fRWFHGOWA/XAu+we6pdOG8W30PNIpXzULalgQp7szmcgUMlfbYanWoD6sD5+IkUWOlVVPb0BbnplkF8Ajd3cQ2CC0SntWNQMKKOfy3KgCq7amX/UFtAH9fqaUMgMDIl5abBqHWRVMjmkvElIV5jdT/Y/CqgQWRIqt1mF4fWoo40sVtFwwujOmkLYKoS4cr2nnsAs4AtwMZxJwLCk3C6fFZCqsRrU9sFBgr9+GlkalVxMB/GXszb/wwsxcqL+7K8M7alLeF381rSkQOyOghnVaqhvnOtaGpmoGErvSQ6MZ4ijdaDS2F2/KK98KoSFqlBVIqH3VokHUm6eUuIama8u4vhcW6kVWAl0yGVduUbKsVtL+OTaEmyjqfrKc1GojqMeV7+q8lBasStrndq5gv/G/AVkBXMObGh4ZwAAAABJRU5ErkJggg==)\n"
      ],
      "metadata": {
        "id": "aQBEWDQXrIpi"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Random Normal Distribution\n",
        "from tensorflow.keras import layers\n",
        "\n",
        "from tensorflow.keras import initializers\n",
        "\n",
        "initializer = tf.keras.initializers.RandomNormal(\n",
        "mean=0., stddev=1.)\n",
        "\n",
        "layer = tf.keras.layers.Dense(3, kernel_initializer=initializer)\n",
        "\n",
        "\n",
        "##b) Random Uniform:\n",
        "The weights are initialized from values in a uniform distribution.\n",
        "\n",
        "![image.png](data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAFAAAAAPCAYAAABzyUiPAAADXklEQVRYCd2YWahOURTHf2aZx8xTZjLLPGaKjKFMmed4MJUhCoUoiki8mpIIpSilhDzwoDzwRJ7IG0UpnH/trfWtznfu+XLv7XZX3fZaa6+9z95r/9fwXahetBAYXoFXWgE0rcD9y23rRcAd4Acw0uzaBrgEfAaOAM3NXD9gn5HFLgHmhb9xbi5LbADscN+WfR3gAlAja3FVmdsC3AOuugM1BNY5ncTbQG2jnwrsMfJloIuRi7Hzg/PeArNTjPS461P0VU4lB+oCv4CW5nQzgHZGFjskQcVhp3sU9FG9HDgWhRzjs4BcbyoUPvfKQcB+QCESqX9g6gFrorKSxvrhmwqVjy40N6acQY6ZaPRC4k93HyHypbEpiy3mQK1TeukRN+gY8sky4FBQKrd8CnzvRP8bUF7ISy3CheoWWWARlWYyGdB3RXuDE2sGWcj09MQldyH0D9DMGI4PudOoMtksBx4AFsfVqwCh7IyJ7QXBy9HmRuLkeAEl67RLRFtt/DQ8ivKSd5ZQtSkaFxm3G73WK4znAI3MGY0J760AdE9x4Bjgu7PLErMcuDnkyYL1H0xVkzN3mtkNhheqOhvZsnoIm4uaJEi6DnQ1RtOT4jDUyGmsD9MrwIMkBGcCvVIWvHO6TsGB9vEmAV+dXZaY5UBF60G7eATw2CheA8OCbBEjBw02dp7tmyRYOciSLqFqejy5/LUkFZy0kym8kO4ROjakEbUQaeQRqESvtCMkRlJ1fRWFHGOWA/XAu+we6pdOG8W30PNIpXzULalgQp7szmcgUMlfbYanWoD6sD5+IkUWOlVVPb0BbnplkF8Ajd3cQ2CC0SntWNQMKKOfy3KgCq7amX/UFtAH9fqaUMgMDIl5abBqHWRVMjmkvElIV5jdT/Y/CqgQWRIqt1mF4fWoo40sVtFwwujOmkLYKoS4cr2nnsAs4AtwMZxJwLCk3C6fFZCqsRrU9sFBgr9+GlkalVxMB/GXszb/wwsxcqL+7K8M7alLeF381rSkQOyOghnVaqhvnOtaGpmoGErvSQ6MZ4ijdaDS2F2/KK98KoSFqlBVIqH3VokHUm6eUuIama8u4vhcW6kVWAl0yGVduUbKsVtL+OTaEmyjqfrKc1GojqMeV7+q8lBasStrndq5gv/G/AVkBXMObGh4ZwAAAABJRU5ErkJggg==)\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "p1Rq0e9Nro_B"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Random Uniform Initialization\n",
        "from tensorflow.keras import layers\n",
        "\n",
        "from tensorflow.keras import initializers\n",
        "\n",
        "initializer = tf.keras.initializers.RandomUniform(\n",
        "minval=0.,maxval=1.)\n",
        "\n",
        "layer = tf.keras.layers.Dense(3, kernel_initializer=initializer)\n",
        "\n",
        "\n",
        "#3. Xavier/Glorot Initialization\n",
        "In Xavier/Glorot weight initialization, the weights are assigned from values of a uniform distribution as follows:\n",
        "\n",
        "![image.png](data:image/png;base64,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)\n",
        "\n",
        "Xavier/Glorot Initialization often termed as Xavier Uniform Initialization, is suitable for layers where the activation function used is Sigmoid."
      ],
      "metadata": {
        "id": "LP1wFSqvr36T"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Xavier/Glorot Uniform Initialization\n",
        "from tensorflow.keras import layers\n",
        "\n",
        "from tensorflow.keras import initializers\n",
        "\n",
        "initializer = tf.keras.initializers.GlorotUniform()\n",
        "\n",
        "layer = tf.keras.layers.Dense(3, kernel_initializer=initializer)\n",
        "\n",
        "\n",
        "#4. Normalized Xavier/Glorot Initialization\n",
        "In Normalized Xavier/Glorot weight initialization, the weights are assigned from values of a normal distribution as follows:\n",
        "\n",
        "![image.png](data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAFEAAAAPCAYAAACcCyOxAAADeElEQVRYCd2XWaiNURTHf+bM85Ap8/yAlClSZColU+ZZFCEZM4QHUiRJJIVSpjIkU5SpTA9KRHjilQclLx7w/a+9b8u637nn3nPuOcWq07fWf689rvHA/0PVge1AjQJfaRbQrMB7VMny64GnwGegjllxJHAfeAAsN7jYTUBfg9UF1iX6o4JuIzOWD1sTOFoEY+VzxtK5a4GvwLxS5A8zE2jpsHbAAYedBloETJ5zwY3nI04GVuSzQDHmNgyPdwh44jZc7GSJ+4BeBm8LvDSy2IdAB4flKip1PPOT+wNbgeZmIIZGfWC2wYvBjgM6Ad2AXy5Ml6UcwF9oLnDD6ckTFzksk1grpAGlgvjr6ZQvWsMpFHYB84ENQbEN8CHwg4AfboFsouaPyKAkKzbJMBbhlZEB7gHHg9wUmGbGxCq0bzlsC3DZYWfCPR1cRpTxnocI0L0/hjy8w2kqB6vIlNCCkLwPA+JFsqQ2jXQuMsmBh9jJBo/s6nCpPcBJVxik06OcB45rWG+bkRj3O6DCMD2lMg4P+8S5+u4GLlkAUI7c7zAvyrivQhRobCDwyCsFealxuhKoGvDJHFCWt9VPEyIpX8nT0qhVUlGtF7UPCb2xUV6VFAGtkYlU/WzYSf6S/DRPBvI0OvHGIw7cBlx12NnwuA7+S9Q68rBIuufbKLivjLvTYsOAOwZ4A/QOsvLDksArP/Yzep6dAHR1oNa5Gy5wG1joxr04OHn4Pg6UZym9rHG4xKGJ55xyuFKTWiFLN51x7Fjk3wPdowBMSfHyOKwCF9NfCTbHuLq88lvUTPLDxKQvah28R6X9PFDPjFtWOSut2ZW+ErRvTezcyFsvjJiq6s+UdkfjGrseFcNX2DuHvTARpB5SacWTdOQ0kbSuN2gc2wio3SoltQTyEj3A1BCCsoj6LMmijkkroc0fB7mqPzLA+NBkp3nrFZOr/N6vPRD+vQwIeGdADXwkhaHSlyelC51BKWRz4v1yrkyk6lymZdIjKfcpD2gRhe1Yt8KkcLhC/O1pYNoJea0iwpIMnYlOpF0oPIjWUjRZkjOoWa5twcBLX4UtW96+ljK3QpCqrfrHmCMrNKkISjqTb0GybavCkCuptYkRWuk1xoR+shCeWOnDuAl7gS4OyySqN1ZVz4XkocdymfgvzFE+P1jBg5YXqtmWUOtn/9nxG3VgdJiALv4aAAAAAElFTkSuQmCC)\n",
        "Here,  ![image.png](data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAkAAAAGCAYAAAARx7TFAAAAbklEQVQYGU3OsQ2CABBG4S+EBjq2oLegJ8xgQsIQllR2Fm6gFQlxBAewcgkTVwEhEO+au//du+T4V4MBH0x444VqV1pckWxgxHFfLr3A9ydlAZ5xCnm9uEeAJw6RdbgEUOIW8jrmeGB5vEaPNEoz37QNZILJlfwAAAAASUVORK5CYII=) is given by:\n",
        "\n",
        "![image.png](data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAIEAAAAaCAYAAACQAT/QAAAFJUlEQVRoBe2aV8gkRRDHf+bsqWdOmAPmnAOGAyOKGDnjgwHFLChmwYABFRVFUBQFRRD1zqwYUURREV/EJ0GffPJVfND5fVTv9TfMzs6xe/vNnFMwTPd0qq2urvpX9UJ36BrgeeCJ/pmoDB7rjgrAo11itud18hJYB7hn8tP2M3ZJAhcA+3WI4dWAg4EtOsRz61l9pvUcLmHwEOAqYE1g0ZLPfWkcCawBPDTOBFMcuwrwSbbedlm5L44hgTOBo8YYP82hxwCvAZcC5wDbTnPx5Xmtp4AVOvIDzwc+CF5XBD4HtGQ9jSGBVYEnxxg/7aFHAy9li77TISuWsd2u4snASe1iqZYbo4JXsh5fAutn9dYXNwBuAj4CPsuebeaQ86cBrUGXaC/gssAFXcEyM/LdBVDgWwNu+g/A3jWS3wj4OFOUXGny8gE1c4xqWgl4blSnvn0yEli5MLnfARtn0z0IXJTV56J4LHB2xcJHFtbhvv6ZiAwGCbjji1P/ZknY1vctfVsW1VtrsmqPD0HWuod1+2ciMjCvMUMXA3ekCrAp8F5WryrqDu5q8OxZNTi+Gf//Dlxe0ceQ0BvDJmRYdi1wXZPOS9HnEqCO/6WYatD1OOBq4OHBl7kpuMezsJY44P7gxZjW27pNpsDbPsADQ1KrhwJuQhP6qrhanh9Ypkn/pn12HWKJ6sZfWdcIfFiEvBsCzj2XJJ7zUm4WebLdFMOxtWa1LNuK6PnvslYWDD4SG1u3ui7hRODHIkFjvj4nf+DO+YfI3qn9Yh/jeccPo80LULpV1uhcWifTwPIsaK2i3KLm7a7rmr/GO09+efD2yDsDW8Y+rB39c7xW6jpTlR+BvCFqov0zPh3vXJsBWqNf2pS/kPm/gBMS5/HOEy6lpkHVTbw+4vJcCRYA3jr6w38rLNs84MC41fsWOD2sxrA1FObuxaF4K1Y6tYiWfBYX9wKCUhXvxgEXswt1SnBuZBBVhqQErnVDbHiKyFQ+17Guq/aA1l1E7QbcC6wH3Fy48oOAMwBzLFcEe1p3QaDKrdt8tU1KII/m2vOsoIBUH9+E/LdRHsWYmEl4xqjn65hkpxDOy1Gvwz26R8114mnHwC1p41XY5D5VvhwbfZrVb4+10uuU0n8iPABfFN9ML0u6NXnW6rjxiXe/fR99yi+ttsqSLJM4y3X9DW68Cid9k/W5LQ5CNLXjdSHwR8aKWq3ZakIvAiZnEp0G3BkVT4SC0AdLCuesKOu7PSXDsnnPFkmzw7L21wGVQRKwilmqxg6zBI6zTSuUSCvwQlTcdC1P4nVhnGqbddECyar1/I1pDvv617sjYs6f4i2+M9pLc4tLdJdajtaQAvg3A0uaqqZkfiOdJMcolLvjmxdPmlNdg/Q+YFZUejswh37T06RJTY9hkwkvhZeypflJNBWsJam6IaxTgjdKOEPTnCKgW4JvIx3JxF2K4Q2VVXQVT2yR+PQtRknhvf21SpLu5ueQg1lg+Tov2rQ+/kYThK0iN1NzqxnWXDWh1Qtf/25FR92JPlzfavo2gaokBIe4AQIkSavjyUuPSiH486RKmmPNbCJBXGpL39K7TglMx5fJjdB3y6vXzztEB6+hk4nXAuiCrHuCE5++VVTxg+XDS5ObbBMbKCdd0fbRLmYaxn9piulWNeH+GcPkkRo+iswYutEKsE0koCyTrseEXFOcUx7/v6lrlv/JEPmoH65pNKTtAmndPJU9jZCAPuzPSB6N6No3L88SEOUaz/c0ZQn8Bzw4CEi4NqyXAAAAAElFTkSuQmCC)\n",
        "Xavier/Glorot Initialization, too, is suitable for layers where the activation function used is Sigmoid.\n"
      ],
      "metadata": {
        "id": "2bnKH3pYsEkk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Normailzed Xavier/Glorot Uniform Initialization\n",
        "from tensorflow.keras import layers\n",
        "\n",
        "from tensorflow.keras import initializers\n",
        "\n",
        "initializer = tf.keras.initializers.GlorotNormal()\n",
        "\n",
        "layer = tf.keras.layers.Dense(3, kernel_initializer=initializer)\n",
        "\n",
        "\n",
        "#5. He Uniform Initialization\n",
        "In He Uniform weight initialization, the weights are assigned from values of a uniform distribution as follows:\n",
        "\n",
        "![image.png](data:image/png;base64,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)"
      ],
      "metadata": {
        "id": "PgKxg0WrsgCk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "He Uniform Initialization is suitable for layers where ReLU activation function is used.\n",
        "\n",
        "# He Uniform Initialization\n",
        "from tensorflow.keras import layers\n",
        "\n",
        "from tensorflow.keras import initializers\n",
        "\n",
        "initializer = tf.keras.initializers.HeUniform()\n",
        "\n",
        "layer = tf.keras.layers.Dense(3, kernel_initializer=initializer)\n",
        "\n",
        "#6. He Normal Initialization\n",
        "In He Normal weight initialization, the weights are assigned from values of a normal distribution as follows:\n",
        "\n",
        "![image.png](data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAE4AAAAPCAYAAABKrvnUAAADVElEQVRYCd2YWaiNURTHf+Z5znApFPJgTJnHQoQ8SMYMZR4fPMhYMjwpUYaUklIUXjwZUt54FR4kKS8ePBhvlAz7f1u71tnnfJ97z+e6WHXba++11t7f/u+1/nufC/+H3ArbOAR0bcTtrAGuAdMacY3CU28G7gJfgF5utlHATeBJsO1x42ecLnUmsAyYDyxIbEW6S/524LS5LcALYG+y00kBvDHJmAduEHDa2Q8CU1y/iPpPALcd2A28Bpq73a53elQ9cKeAFdEAjAWuu34RtQw4lcD+pCyG2QrtwsmvKrJaFbEjAGVWj/BdX4GFbo4NTo+qB+4RMCMagP7AB6CZG8tTB1i85oh/nSygBLi+4UQPGzj7zKEn8NL00cC35NTzFpZNvDQ9J0aA5Mk6oKU5XAZE/hJtfpPpvvHAvQUmOmMf4AfQ2Y1lqcrm58Azi3kQwLsPCANJCXC6LdoASvG15iBivWq6Gt0mUcQviskSbewecAS4AnRMHLsDi5KxtLvRDUwGvlvmjLPSc+Y61QP3OQA9wTkoCQScEiRPdFgX3IFJX54ElAAnm07yFaBNSc4C20xX43mlQ85H6FR3uThl3g1AHx9FoPeOnYx2azKuW/Q4sDMjiz1wKsupLr6fAZf3VOkS9vvGqCGGqgp3xI61ZcCNtyyJfo8DoQ63jkom8or4bmR0qtAqO2JaR/NAK7Wj9pTwwEYf38p/lh+w8nxvl0Viqut64J4mTxBx9bsMwONcc0N5344da1U1uli8lAGnlDxhHsq+WrfQbMswgbYYuBjKupufzeki0dauH1VRgR6OvyoX+etbtJYXZfkn4IAfdLoH7iTgS11vukvOdzDQ3vWl6rly3o0NSRIpmsqA04buBF5qASw1bhpqpSuwJEp5LfjQ+r+7ETjKNM2vB7DA9qK3mS6cSuKB06GKn6IIbH27REnxMaETjeuwxeNtjUsVr9s4lTLg5CBHcVmNEaSAm5dEKvuOOS5MzIW6+vh4/atNgdNN3CpjBQ+cXMSp+tUwB1CGeVE2VbqcxM/i1ryfVBWB85Nn6efs1R45L8vvT4+nwOWtL/ArAZcXE21VA6dMWJ3cknHSpmwbAtzKDB6uz/dXDVx9Jm8Kn4b8d0RcWo2U/HfkJ7wjc5xlVQVpAAAAAElFTkSuQmCC)\n"
      ],
      "metadata": {
        "id": "4UqoyQXissQL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Here, sigma is given by:\n",
        "\n",
        "![image.png](data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAFAAAAAaCAYAAAAg0tunAAADfElEQVRoBe2Y2avNURTHP+YMIfM8j5lShAwhYxfJVKSMRSFkCmWIDIWICJEn4oFCGRLiTYR48eB/8MoL+1tr3/b59Tvn/M69v3Pv79xr1T57Wnudtddvr7W+e0Pl0G3gcsbKpUoxX0vgfKUom0U9q4A5WVSsUnS6CDRLSdkOwOiUZFWEGBkurVizEOgDjAKeAD0rwgK1VHIWsKyWMvzyry4JdbbOYUClwdMFoHVKu+wYyLkFbAn6DbZ5vQw7mwI8TTGulkHFdEROAtalI6paygBgHyBo1LV6tIE2TgPtU9ybjHcUmGllU4qy6QIcAF454W+D0i3NPylR1p0S+Yux3wj2pT1OL7Yg6bxw0TVL8YOAb8DQAovF8yaiTGh0tV8DfQvIKDY1BthRjCkL882BL0F6l05XgJX1rNyxPDhtg4tfpzJQJnr7CFw+8B2rXwDDImNpd5sANwHVcSSYEUdtLC4qNtZnaeGV2wwc9B2gP/Ao6Mc1FYx1QooVof58tAf4AyjTRkkhIinIPWIvNOOiQmrRl1eeS7pexjhpzG1NmU5JF9eQT/fRfsBzdwKPx8jYC4yMGY8ODbFTLG9JM1vr+ljSB+nugOUEQK8eaaH+6Gbj+juBjzET92PGokPeC67GhJuBQHgIFCZGmAAlTAHpQqT45h8v2gG9gKYOoUwrklwLySzLnDL93wig7eE+4tkE/yYD3gN2u3p4wH8IGAsstgcDTSkh7nKoQHFV2V1AekGwJmyucShkObDeBrX2ISCvEPB+7NxbRs0M/QyUlVLb88TFOIWfOfgl7/G0xLCs+vPcj2K0SB9Kd+pF1pcBV1s7Wim06PVHLza6rSgnfAYUdkTCyeHptuH6q6RsiALulqDKpwivgPd4GzvjsOgMB8l0QRAJqvnM+R7QBSHOEDLUBzOYXF9PXorVIp3Ad3nWGUvdV/Ode/2ymKMNCYMmIRlADwIhnTADaqPfASUZyVeCeWmMassNdcKUNP37oPo6bXOB/ZYTtGQVIMQgWgFsK8FDbFl5K7nJbzstG20DSf5RMUzxLyTBD70fymiTbcM6RXLz2QHjYDOuhpQY1loRTyuLgf4KO9UQg3hlcPFk7hFCJ0IPB0oKPvsF+81pyuByT+FEv8kchsbY2eqC+g/Lkkn2v9TcLQlvo+DpbXBG8OE/1dACyqh1CeJrqGbusn9uB5UJfCFq8wAAAABJRU5ErkJggg==)"
      ],
      "metadata": {
        "id": "N0Jv3uADs3d4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "He Uniform Initialization, too, is suitable for layers where ReLU activation function is used.\n",
        "\n",
        "# He Normal Initialization\n",
        "from tensorflow.keras import layers\n",
        "\n",
        "from tensorflow.keras import initializers\n",
        "\n",
        "initializer = tf.keras.initializers.HeNormal()\n",
        "\n",
        "layer = tf.keras.layers.Dense(3, kernel_initializer=initializer)\n"
      ],
      "metadata": {
        "id": "AQuFHHrNtDzA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Case1: default way to check weight initialization.\n",
        "\n",
        "##Mind it each time the algorithim apply different weight and your model outputs are different."
      ],
      "metadata": {
        "id": "HVziupbeWUjn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt"
      ],
      "metadata": {
        "id": "xKDnfkPLRE_J"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv('/content/test.csv')"
      ],
      "metadata": {
        "id": "6w6o6aNeRFVV"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "SE5vo7DATI7N",
        "outputId": "fcfa957b-3fa0-4610-8174-b3f54586b460"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   LongestShell  Diameter  Height  WholeWeight  ShuckedWeight  VisceraWeight  \\\n",
              "0         0.455     0.365   0.095       0.5140         0.2245         0.1010   \n",
              "1         0.350     0.265   0.090       0.2255         0.0995         0.0485   \n",
              "2         0.530     0.420   0.135       0.6770         0.2565         0.1415   \n",
              "3         0.440     0.365   0.125       0.5160         0.2155         0.1140   \n",
              "4         0.330     0.255   0.080       0.2050         0.0895         0.0395   \n",
              "\n",
              "   ShellWeight  Rings  Type  \n",
              "0        0.150     15     1  \n",
              "1        0.070      7     1  \n",
              "2        0.210      9     0  \n",
              "3        0.155     10     1  \n",
              "4        0.055      7     1  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-08c346c8-ba66-4d2c-a4a8-e8e0d26f863c\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>LongestShell</th>\n",
              "      <th>Diameter</th>\n",
              "      <th>Height</th>\n",
              "      <th>WholeWeight</th>\n",
              "      <th>ShuckedWeight</th>\n",
              "      <th>VisceraWeight</th>\n",
              "      <th>ShellWeight</th>\n",
              "      <th>Rings</th>\n",
              "      <th>Type</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.455</td>\n",
              "      <td>0.365</td>\n",
              "      <td>0.095</td>\n",
              "      <td>0.5140</td>\n",
              "      <td>0.2245</td>\n",
              "      <td>0.1010</td>\n",
              "      <td>0.150</td>\n",
              "      <td>15</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.350</td>\n",
              "      <td>0.265</td>\n",
              "      <td>0.090</td>\n",
              "      <td>0.2255</td>\n",
              "      <td>0.0995</td>\n",
              "      <td>0.0485</td>\n",
              "      <td>0.070</td>\n",
              "      <td>7</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.530</td>\n",
              "      <td>0.420</td>\n",
              "      <td>0.135</td>\n",
              "      <td>0.6770</td>\n",
              "      <td>0.2565</td>\n",
              "      <td>0.1415</td>\n",
              "      <td>0.210</td>\n",
              "      <td>9</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.440</td>\n",
              "      <td>0.365</td>\n",
              "      <td>0.125</td>\n",
              "      <td>0.5160</td>\n",
              "      <td>0.2155</td>\n",
              "      <td>0.1140</td>\n",
              "      <td>0.155</td>\n",
              "      <td>10</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.330</td>\n",
              "      <td>0.255</td>\n",
              "      <td>0.080</td>\n",
              "      <td>0.2050</td>\n",
              "      <td>0.0895</td>\n",
              "      <td>0.0395</td>\n",
              "      <td>0.055</td>\n",
              "      <td>7</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-08c346c8-ba66-4d2c-a4a8-e8e0d26f863c')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-08c346c8-ba66-4d2c-a4a8-e8e0d26f863c button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-08c346c8-ba66-4d2c-a4a8-e8e0d26f863c');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-0e1876d1-9737-45d9-a2c0-edfd5e566e70\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-0e1876d1-9737-45d9-a2c0-edfd5e566e70')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-0e1876d1-9737-45d9-a2c0-edfd5e566e70 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X = df.iloc[:,0:-1].values\n",
        "X"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KeMTduudTJB2",
        "outputId": "0d65ae6e-00b2-4e93-a75d-56074eb2f4dc"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[ 0.455 ,  0.365 ,  0.095 , ...,  0.101 ,  0.15  , 15.    ],\n",
              "       [ 0.35  ,  0.265 ,  0.09  , ...,  0.0485,  0.07  ,  7.    ],\n",
              "       [ 0.53  ,  0.42  ,  0.135 , ...,  0.1415,  0.21  ,  9.    ],\n",
              "       ...,\n",
              "       [ 0.6   ,  0.475 ,  0.205 , ...,  0.2875,  0.308 ,  9.    ],\n",
              "       [ 0.625 ,  0.485 ,  0.15  , ...,  0.261 ,  0.296 , 10.    ],\n",
              "       [ 0.71  ,  0.555 ,  0.195 , ...,  0.3765,  0.495 , 12.    ]])"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y = df.iloc[:,-1].values.astype(float)\n",
        "y"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pNzVcJ2kTJFQ",
        "outputId": "adff585c-2e5a-446b-fee1-f81c711f5838"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([1., 1., 0., ..., 1., 0., 1.])"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.columns"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CKQDlcQ5TkKY",
        "outputId": "d8947e3e-cdd6-4906-b4f7-4a82e1f211d8"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Index(['LongestShell', 'Diameter', 'Height', 'WholeWeight', 'ShuckedWeight',\n",
              "       'VisceraWeight', 'ShellWeight', 'Rings', 'Type'],\n",
              "      dtype='object')"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X.shape, y.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s31CGyqRUIpQ",
        "outputId": "c24e0d36-e998-47be-90ef-57aa8eb6195e"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((4177, 8), (4177,))"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow\n",
        "from tensorflow import keras\n",
        "from keras import Sequential\n",
        "from keras.layers import Dense"
      ],
      "metadata": {
        "id": "yxzFpO4kTkQx"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = Sequential()\n",
        "\n",
        "model.add(Dense(2,activation='sigmoid',input_dim=8))\n",
        "model.add(Dense(1,activation='sigmoid'))\n",
        "\n",
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HGE7PmBUUESm",
        "outputId": "9b1be1e2-b2ca-46ba-ab47-d2c4a28804cc"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense (Dense)               (None, 2)                 18        \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 1)                 3         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 21 (84.00 Byte)\n",
            "Trainable params: 21 (84.00 Byte)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.get_weights()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7PGO8hwUUXmP",
        "outputId": "e292ff57-9da6-421d-e677-1f6b01b1bc2a"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[array([[-0.00562197,  0.35664117],\n",
              "        [ 0.5487542 ,  0.46310878],\n",
              "        [-0.20755953,  0.64193475],\n",
              "        [ 0.00782257,  0.3557036 ],\n",
              "        [ 0.18902463,  0.6447252 ],\n",
              "        [ 0.43302703,  0.31256735],\n",
              "        [ 0.48586118,  0.22579181],\n",
              "        [ 0.20378137,  0.5688585 ]], dtype=float32),\n",
              " array([0., 0.], dtype=float32),\n",
              " array([[ 1.2667373],\n",
              "        [-0.934723 ]], dtype=float32),\n",
              " array([0.], dtype=float32)]"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(loss='binary_crossentropy',optimizer='adam',metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "iSxheiIHVwoe"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "history = model.fit(X,y,epochs=100,validation_split=0.2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Et2cAWLhVwr_",
        "outputId": "46807062-6006-4f54-a8b8-94458a42a928"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "105/105 [==============================] - 1s 3ms/step - loss: 0.6503 - accuracy: 0.6800 - val_loss: 0.6192 - val_accuracy: 0.7153\n",
            "Epoch 2/100\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.6327 - accuracy: 0.6800 - val_loss: 0.6043 - val_accuracy: 0.7153\n",
            "Epoch 3/100\n",
            "105/105 [==============================] - 0s 1ms/step - loss: 0.6250 - accuracy: 0.6800 - val_loss: 0.5958 - val_accuracy: 0.7153\n",
            "Epoch 4/100\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.6204 - accuracy: 0.6800 - val_loss: 0.5917 - val_accuracy: 0.7153\n",
            "Epoch 5/100\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.6178 - accuracy: 0.6800 - val_loss: 0.5890 - val_accuracy: 0.7153\n",
            "Epoch 6/100\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.6156 - accuracy: 0.6800 - val_loss: 0.5874 - val_accuracy: 0.7153\n",
            "Epoch 7/100\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.6138 - accuracy: 0.6800 - val_loss: 0.5862 - val_accuracy: 0.7153\n",
            "Epoch 8/100\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.6119 - accuracy: 0.6800 - val_loss: 0.5843 - val_accuracy: 0.7153\n",
            "Epoch 9/100\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.6103 - accuracy: 0.6800 - val_loss: 0.5825 - val_accuracy: 0.7153\n",
            "Epoch 10/100\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.6087 - accuracy: 0.6800 - val_loss: 0.5811 - val_accuracy: 0.7153\n",
            "Epoch 11/100\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.6073 - accuracy: 0.6800 - val_loss: 0.5791 - val_accuracy: 0.7153\n",
            "Epoch 12/100\n",
            "105/105 [==============================] - 0s 1ms/step - loss: 0.6060 - accuracy: 0.6800 - val_loss: 0.5785 - val_accuracy: 0.7153\n",
            "Epoch 13/100\n",
            "105/105 [==============================] - 0s 1ms/step - loss: 0.6047 - accuracy: 0.6800 - val_loss: 0.5773 - val_accuracy: 0.7153\n",
            "Epoch 14/100\n",
            "105/105 [==============================] - 0s 1ms/step - loss: 0.6034 - accuracy: 0.6800 - val_loss: 0.5750 - val_accuracy: 0.7153\n",
            "Epoch 15/100\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.6021 - accuracy: 0.6800 - val_loss: 0.5750 - val_accuracy: 0.7153\n",
            "Epoch 16/100\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.6010 - accuracy: 0.6800 - val_loss: 0.5730 - val_accuracy: 0.7153\n",
            "Epoch 17/100\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.5998 - accuracy: 0.6800 - val_loss: 0.5714 - val_accuracy: 0.7153\n",
            "Epoch 18/100\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.5986 - accuracy: 0.6800 - val_loss: 0.5703 - val_accuracy: 0.7153\n",
            "Epoch 19/100\n",
            "105/105 [==============================] - 0s 1ms/step - loss: 0.5976 - accuracy: 0.6800 - val_loss: 0.5691 - val_accuracy: 0.7153\n",
            "Epoch 20/100\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.5965 - accuracy: 0.6800 - val_loss: 0.5683 - val_accuracy: 0.7153\n",
            "Epoch 21/100\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.5954 - accuracy: 0.6800 - val_loss: 0.5667 - val_accuracy: 0.7153\n",
            "Epoch 22/100\n",
            "105/105 [==============================] - 0s 1ms/step - loss: 0.5945 - accuracy: 0.6800 - val_loss: 0.5673 - val_accuracy: 0.7153\n",
            "Epoch 23/100\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.5935 - accuracy: 0.6800 - val_loss: 0.5652 - val_accuracy: 0.7153\n",
            "Epoch 24/100\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.5924 - accuracy: 0.6800 - val_loss: 0.5639 - val_accuracy: 0.7153\n",
            "Epoch 25/100\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.5915 - accuracy: 0.6800 - val_loss: 0.5630 - val_accuracy: 0.7153\n",
            "Epoch 26/100\n",
            "105/105 [==============================] - 0s 1ms/step - loss: 0.5905 - accuracy: 0.6800 - val_loss: 0.5615 - val_accuracy: 0.7153\n",
            "Epoch 27/100\n",
            "105/105 [==============================] - 0s 1ms/step - loss: 0.5899 - accuracy: 0.6800 - val_loss: 0.5614 - val_accuracy: 0.7153\n",
            "Epoch 28/100\n",
            "105/105 [==============================] - 0s 1ms/step - loss: 0.5887 - accuracy: 0.6800 - val_loss: 0.5592 - val_accuracy: 0.7153\n",
            "Epoch 29/100\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.5879 - accuracy: 0.6800 - val_loss: 0.5585 - val_accuracy: 0.7153\n",
            "Epoch 30/100\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.5872 - accuracy: 0.6800 - val_loss: 0.5573 - val_accuracy: 0.7153\n",
            "Epoch 31/100\n",
            "105/105 [==============================] - 0s 1ms/step - loss: 0.5864 - accuracy: 0.6800 - val_loss: 0.5565 - val_accuracy: 0.7153\n",
            "Epoch 32/100\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.5855 - accuracy: 0.6800 - val_loss: 0.5563 - val_accuracy: 0.7153\n",
            "Epoch 33/100\n",
            "105/105 [==============================] - 0s 1ms/step - loss: 0.5848 - accuracy: 0.6800 - val_loss: 0.5549 - val_accuracy: 0.7153\n",
            "Epoch 34/100\n",
            "105/105 [==============================] - 0s 1ms/step - loss: 0.5842 - accuracy: 0.6800 - val_loss: 0.5541 - val_accuracy: 0.7153\n",
            "Epoch 35/100\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.5835 - accuracy: 0.6800 - val_loss: 0.5538 - val_accuracy: 0.7153\n",
            "Epoch 36/100\n",
            "105/105 [==============================] - 0s 1ms/step - loss: 0.5827 - accuracy: 0.6800 - val_loss: 0.5520 - val_accuracy: 0.7153\n",
            "Epoch 37/100\n",
            "105/105 [==============================] - 0s 1ms/step - loss: 0.5821 - accuracy: 0.6800 - val_loss: 0.5513 - val_accuracy: 0.7153\n",
            "Epoch 38/100\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.5814 - accuracy: 0.6800 - val_loss: 0.5512 - val_accuracy: 0.7153\n",
            "Epoch 39/100\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.5808 - accuracy: 0.6800 - val_loss: 0.5499 - val_accuracy: 0.7153\n",
            "Epoch 40/100\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.5801 - accuracy: 0.6800 - val_loss: 0.5509 - val_accuracy: 0.7153\n",
            "Epoch 41/100\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.5797 - accuracy: 0.6800 - val_loss: 0.5485 - val_accuracy: 0.7153\n",
            "Epoch 42/100\n",
            "105/105 [==============================] - 0s 1ms/step - loss: 0.5791 - accuracy: 0.6800 - val_loss: 0.5487 - val_accuracy: 0.7153\n",
            "Epoch 43/100\n",
            "105/105 [==============================] - 0s 1ms/step - loss: 0.5785 - accuracy: 0.6800 - val_loss: 0.5471 - val_accuracy: 0.7153\n",
            "Epoch 44/100\n",
            "105/105 [==============================] - 0s 1ms/step - loss: 0.5779 - accuracy: 0.6800 - val_loss: 0.5470 - val_accuracy: 0.7153\n",
            "Epoch 45/100\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.5774 - accuracy: 0.6800 - val_loss: 0.5463 - val_accuracy: 0.7153\n",
            "Epoch 46/100\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.5768 - accuracy: 0.6800 - val_loss: 0.5468 - val_accuracy: 0.7153\n",
            "Epoch 47/100\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.5764 - accuracy: 0.6800 - val_loss: 0.5455 - val_accuracy: 0.7153\n",
            "Epoch 48/100\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.5759 - accuracy: 0.6800 - val_loss: 0.5442 - val_accuracy: 0.7153\n",
            "Epoch 49/100\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.5754 - accuracy: 0.6800 - val_loss: 0.5441 - val_accuracy: 0.7153\n",
            "Epoch 50/100\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.5750 - accuracy: 0.6800 - val_loss: 0.5437 - val_accuracy: 0.7153\n",
            "Epoch 51/100\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.5746 - accuracy: 0.6800 - val_loss: 0.5439 - val_accuracy: 0.7153\n",
            "Epoch 52/100\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.5741 - accuracy: 0.6800 - val_loss: 0.5429 - val_accuracy: 0.7153\n",
            "Epoch 53/100\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.5738 - accuracy: 0.6800 - val_loss: 0.5436 - val_accuracy: 0.7153\n",
            "Epoch 54/100\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.5734 - accuracy: 0.6800 - val_loss: 0.5416 - val_accuracy: 0.7153\n",
            "Epoch 55/100\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.5730 - accuracy: 0.6800 - val_loss: 0.5413 - val_accuracy: 0.7153\n",
            "Epoch 56/100\n",
            "105/105 [==============================] - 0s 1ms/step - loss: 0.5726 - accuracy: 0.6800 - val_loss: 0.5414 - val_accuracy: 0.7153\n",
            "Epoch 57/100\n",
            "105/105 [==============================] - 0s 1ms/step - loss: 0.5723 - accuracy: 0.6800 - val_loss: 0.5407 - val_accuracy: 0.7153\n",
            "Epoch 58/100\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.5719 - accuracy: 0.6800 - val_loss: 0.5405 - val_accuracy: 0.7153\n",
            "Epoch 59/100\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.5715 - accuracy: 0.6800 - val_loss: 0.5395 - val_accuracy: 0.7153\n",
            "Epoch 60/100\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.5713 - accuracy: 0.6800 - val_loss: 0.5395 - val_accuracy: 0.7153\n",
            "Epoch 61/100\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.5709 - accuracy: 0.6800 - val_loss: 0.5399 - val_accuracy: 0.7153\n",
            "Epoch 62/100\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.5706 - accuracy: 0.6800 - val_loss: 0.5383 - val_accuracy: 0.7153\n",
            "Epoch 63/100\n",
            "105/105 [==============================] - 0s 1ms/step - loss: 0.5704 - accuracy: 0.6800 - val_loss: 0.5381 - val_accuracy: 0.7153\n",
            "Epoch 64/100\n",
            "105/105 [==============================] - 0s 1ms/step - loss: 0.5700 - accuracy: 0.6800 - val_loss: 0.5378 - val_accuracy: 0.7153\n",
            "Epoch 65/100\n",
            "105/105 [==============================] - 0s 1ms/step - loss: 0.5697 - accuracy: 0.6800 - val_loss: 0.5385 - val_accuracy: 0.7153\n",
            "Epoch 66/100\n",
            "105/105 [==============================] - 0s 1ms/step - loss: 0.5695 - accuracy: 0.6800 - val_loss: 0.5374 - val_accuracy: 0.7153\n",
            "Epoch 67/100\n",
            "105/105 [==============================] - 0s 1ms/step - loss: 0.5692 - accuracy: 0.6800 - val_loss: 0.5366 - val_accuracy: 0.7153\n",
            "Epoch 68/100\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.5690 - accuracy: 0.6800 - val_loss: 0.5374 - val_accuracy: 0.7153\n",
            "Epoch 69/100\n",
            "105/105 [==============================] - 0s 1ms/step - loss: 0.5686 - accuracy: 0.6800 - val_loss: 0.5357 - val_accuracy: 0.7153\n",
            "Epoch 70/100\n",
            "105/105 [==============================] - 0s 1ms/step - loss: 0.5685 - accuracy: 0.6800 - val_loss: 0.5354 - val_accuracy: 0.7153\n",
            "Epoch 71/100\n",
            "105/105 [==============================] - 0s 1ms/step - loss: 0.5684 - accuracy: 0.6800 - val_loss: 0.5362 - val_accuracy: 0.7153\n",
            "Epoch 72/100\n",
            "105/105 [==============================] - 0s 1ms/step - loss: 0.5681 - accuracy: 0.6800 - val_loss: 0.5365 - val_accuracy: 0.7153\n",
            "Epoch 73/100\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.5678 - accuracy: 0.6800 - val_loss: 0.5347 - val_accuracy: 0.7153\n",
            "Epoch 74/100\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.5676 - accuracy: 0.6800 - val_loss: 0.5358 - val_accuracy: 0.7153\n",
            "Epoch 75/100\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.5674 - accuracy: 0.6800 - val_loss: 0.5355 - val_accuracy: 0.7153\n",
            "Epoch 76/100\n",
            "105/105 [==============================] - 0s 1ms/step - loss: 0.5670 - accuracy: 0.6800 - val_loss: 0.5341 - val_accuracy: 0.7153\n",
            "Epoch 77/100\n",
            "105/105 [==============================] - 0s 1ms/step - loss: 0.5669 - accuracy: 0.6800 - val_loss: 0.5342 - val_accuracy: 0.7153\n",
            "Epoch 78/100\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.5667 - accuracy: 0.6800 - val_loss: 0.5339 - val_accuracy: 0.7153\n",
            "Epoch 79/100\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.5665 - accuracy: 0.6800 - val_loss: 0.5335 - val_accuracy: 0.7153\n",
            "Epoch 80/100\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.5664 - accuracy: 0.6800 - val_loss: 0.5327 - val_accuracy: 0.7153\n",
            "Epoch 81/100\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.5661 - accuracy: 0.6800 - val_loss: 0.5336 - val_accuracy: 0.7153\n",
            "Epoch 82/100\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.5659 - accuracy: 0.6800 - val_loss: 0.5331 - val_accuracy: 0.7153\n",
            "Epoch 83/100\n",
            "105/105 [==============================] - 0s 1ms/step - loss: 0.5658 - accuracy: 0.6800 - val_loss: 0.5341 - val_accuracy: 0.7153\n",
            "Epoch 84/100\n",
            "105/105 [==============================] - 0s 1ms/step - loss: 0.5657 - accuracy: 0.6800 - val_loss: 0.5334 - val_accuracy: 0.7153\n",
            "Epoch 85/100\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.5654 - accuracy: 0.6800 - val_loss: 0.5336 - val_accuracy: 0.7153\n",
            "Epoch 86/100\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.5652 - accuracy: 0.6800 - val_loss: 0.5322 - val_accuracy: 0.7153\n",
            "Epoch 87/100\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.5651 - accuracy: 0.6800 - val_loss: 0.5326 - val_accuracy: 0.7153\n",
            "Epoch 88/100\n",
            "105/105 [==============================] - 0s 1ms/step - loss: 0.5649 - accuracy: 0.6800 - val_loss: 0.5324 - val_accuracy: 0.7153\n",
            "Epoch 89/100\n",
            "105/105 [==============================] - 0s 1ms/step - loss: 0.5648 - accuracy: 0.6800 - val_loss: 0.5316 - val_accuracy: 0.7153\n",
            "Epoch 90/100\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.5646 - accuracy: 0.6800 - val_loss: 0.5323 - val_accuracy: 0.7153\n",
            "Epoch 91/100\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.5644 - accuracy: 0.6800 - val_loss: 0.5310 - val_accuracy: 0.7153\n",
            "Epoch 92/100\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.5643 - accuracy: 0.6800 - val_loss: 0.5314 - val_accuracy: 0.7153\n",
            "Epoch 93/100\n",
            "105/105 [==============================] - 0s 1ms/step - loss: 0.5642 - accuracy: 0.6800 - val_loss: 0.5309 - val_accuracy: 0.7153\n",
            "Epoch 94/100\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.5641 - accuracy: 0.6800 - val_loss: 0.5306 - val_accuracy: 0.7153\n",
            "Epoch 95/100\n",
            "105/105 [==============================] - 0s 1ms/step - loss: 0.5642 - accuracy: 0.6800 - val_loss: 0.5294 - val_accuracy: 0.7153\n",
            "Epoch 96/100\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.5639 - accuracy: 0.6800 - val_loss: 0.5299 - val_accuracy: 0.7153\n",
            "Epoch 97/100\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.5638 - accuracy: 0.6800 - val_loss: 0.5313 - val_accuracy: 0.7153\n",
            "Epoch 98/100\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.5635 - accuracy: 0.6800 - val_loss: 0.5300 - val_accuracy: 0.7153\n",
            "Epoch 99/100\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.5634 - accuracy: 0.6800 - val_loss: 0.5305 - val_accuracy: 0.7153\n",
            "Epoch 100/100\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.5635 - accuracy: 0.6800 - val_loss: 0.5307 - val_accuracy: 0.7153\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.get_weights()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0z9dmZp1VwxY",
        "outputId": "44f7dc44-2cc3-4720-bdcf-ccfae359dd4b"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[array([[ 1.1074871 , -0.9244331 ],\n",
              "        [ 1.640391  , -0.6088128 ],\n",
              "        [ 0.8371327 ,  0.44399032],\n",
              "        [ 0.54266995,  1.8596315 ],\n",
              "        [ 0.73149246,  1.4441768 ],\n",
              "        [ 0.95807856,  2.358077  ],\n",
              "        [ 1.0482508 ,  1.7799335 ],\n",
              "        [ 1.3199273 ,  0.21311226]], dtype=float32),\n",
              " array([ 1.5319039, -2.8785408], dtype=float32),\n",
              " array([[ 1.9185447],\n",
              "        [-2.5467634]], dtype=float32),\n",
              " array([0.6867046], dtype=float32)]"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Case-2: Initialize weight with Zero.(relu)\n"
      ],
      "metadata": {
        "id": "_F-HgPgDW9lV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = Sequential()\n",
        "\n",
        "model.add(Dense(2,activation='relu',input_dim=8))\n",
        "model.add(Dense(1,activation='sigmoid'))\n",
        "\n",
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sd19RrLoYrar",
        "outputId": "c3774178-228c-4880-dc45-203bc7f504c4"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_2 (Dense)             (None, 2)                 18        \n",
            "                                                                 \n",
            " dense_3 (Dense)             (None, 1)                 3         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 21 (84.00 Byte)\n",
            "Trainable params: 21 (84.00 Byte)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "initial_weights = model.get_weights()"
      ],
      "metadata": {
        "id": "JAj5gk0zVw2L"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "initial_weights[0] = np.zeros(model.get_weights()[0].shape)\n",
        "initial_weights[1] = np.zeros(model.get_weights()[1].shape)\n",
        "initial_weights[2] = np.zeros(model.get_weights()[2].shape)\n",
        "initial_weights[3] = np.zeros(model.get_weights()[3].shape)"
      ],
      "metadata": {
        "id": "GTvQIblFVw3x"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.set_weights(initial_weights)"
      ],
      "metadata": {
        "id": "6JORShF7XvjC"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.get_weights()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yMAFY92KXvmO",
        "outputId": "a9861e26-a08d-4493-a40c-4c5fe75961a0"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[array([[0., 0.],\n",
              "        [0., 0.],\n",
              "        [0., 0.],\n",
              "        [0., 0.],\n",
              "        [0., 0.],\n",
              "        [0., 0.],\n",
              "        [0., 0.],\n",
              "        [0., 0.]], dtype=float32),\n",
              " array([0., 0.], dtype=float32),\n",
              " array([[0.],\n",
              "        [0.]], dtype=float32),\n",
              " array([0.], dtype=float32)]"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(loss='binary_crossentropy',optimizer='adam',metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "Y877qCUCXvpQ"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "history = model.fit(X,y,epochs=100,validation_split=0.2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sNf3E8Y5XvvA",
        "outputId": "e9ae72e9-5e18-4146-bcf9-83471966a059"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "105/105 [==============================] - 1s 3ms/step - loss: 0.6862 - accuracy: 0.6735 - val_loss: 0.6758 - val_accuracy: 0.7153\n",
            "Epoch 2/100\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.6728 - accuracy: 0.6800 - val_loss: 0.6609 - val_accuracy: 0.7153\n",
            "Epoch 3/100\n",
            "105/105 [==============================] - 0s 3ms/step - loss: 0.6617 - accuracy: 0.6800 - val_loss: 0.6482 - val_accuracy: 0.7153\n",
            "Epoch 4/100\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.6529 - accuracy: 0.6800 - val_loss: 0.6381 - val_accuracy: 0.7153\n",
            "Epoch 5/100\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.6460 - accuracy: 0.6800 - val_loss: 0.6298 - val_accuracy: 0.7153\n",
            "Epoch 6/100\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.6406 - accuracy: 0.6800 - val_loss: 0.6231 - val_accuracy: 0.7153\n",
            "Epoch 7/100\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.6367 - accuracy: 0.6800 - val_loss: 0.6180 - val_accuracy: 0.7153\n",
            "Epoch 8/100\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.6337 - accuracy: 0.6800 - val_loss: 0.6139 - val_accuracy: 0.7153\n",
            "Epoch 9/100\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.6316 - accuracy: 0.6800 - val_loss: 0.6108 - val_accuracy: 0.7153\n",
            "Epoch 10/100\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.6302 - accuracy: 0.6800 - val_loss: 0.6084 - val_accuracy: 0.7153\n",
            "Epoch 11/100\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.6291 - accuracy: 0.6800 - val_loss: 0.6067 - val_accuracy: 0.7153\n",
            "Epoch 12/100\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.6284 - accuracy: 0.6800 - val_loss: 0.6051 - val_accuracy: 0.7153\n",
            "Epoch 13/100\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.6279 - accuracy: 0.6800 - val_loss: 0.6041 - val_accuracy: 0.7153\n",
            "Epoch 14/100\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.6275 - accuracy: 0.6800 - val_loss: 0.6032 - val_accuracy: 0.7153\n",
            "Epoch 15/100\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.6273 - accuracy: 0.6800 - val_loss: 0.6025 - val_accuracy: 0.7153\n",
            "Epoch 16/100\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.6272 - accuracy: 0.6800 - val_loss: 0.6020 - val_accuracy: 0.7153\n",
            "Epoch 17/100\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.6270 - accuracy: 0.6800 - val_loss: 0.6016 - val_accuracy: 0.7153\n",
            "Epoch 18/100\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.6270 - accuracy: 0.6800 - val_loss: 0.6013 - val_accuracy: 0.7153\n",
            "Epoch 19/100\n",
            "105/105 [==============================] - 0s 1ms/step - loss: 0.6269 - accuracy: 0.6800 - val_loss: 0.6010 - val_accuracy: 0.7153\n",
            "Epoch 20/100\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.6269 - accuracy: 0.6800 - val_loss: 0.6009 - val_accuracy: 0.7153\n",
            "Epoch 21/100\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.6269 - accuracy: 0.6800 - val_loss: 0.6008 - val_accuracy: 0.7153\n",
            "Epoch 22/100\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.6269 - accuracy: 0.6800 - val_loss: 0.6007 - val_accuracy: 0.7153\n",
            "Epoch 23/100\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.6269 - accuracy: 0.6800 - val_loss: 0.6006 - val_accuracy: 0.7153\n",
            "Epoch 24/100\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.6269 - accuracy: 0.6800 - val_loss: 0.6004 - val_accuracy: 0.7153\n",
            "Epoch 25/100\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.6269 - accuracy: 0.6800 - val_loss: 0.6003 - val_accuracy: 0.7153\n",
            "Epoch 26/100\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.6269 - accuracy: 0.6800 - val_loss: 0.6004 - val_accuracy: 0.7153\n",
            "Epoch 27/100\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.6269 - accuracy: 0.6800 - val_loss: 0.6003 - val_accuracy: 0.7153\n",
            "Epoch 28/100\n",
            "105/105 [==============================] - 0s 1ms/step - loss: 0.6269 - accuracy: 0.6800 - val_loss: 0.6004 - val_accuracy: 0.7153\n",
            "Epoch 29/100\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.6269 - accuracy: 0.6800 - val_loss: 0.6002 - val_accuracy: 0.7153\n",
            "Epoch 30/100\n",
            "105/105 [==============================] - 0s 1ms/step - loss: 0.6269 - accuracy: 0.6800 - val_loss: 0.6003 - val_accuracy: 0.7153\n",
            "Epoch 31/100\n",
            "105/105 [==============================] - 0s 1ms/step - loss: 0.6269 - accuracy: 0.6800 - val_loss: 0.6002 - val_accuracy: 0.7153\n",
            "Epoch 32/100\n",
            "105/105 [==============================] - 0s 1ms/step - loss: 0.6269 - accuracy: 0.6800 - val_loss: 0.6002 - val_accuracy: 0.7153\n",
            "Epoch 33/100\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.6269 - accuracy: 0.6800 - val_loss: 0.6002 - val_accuracy: 0.7153\n",
            "Epoch 34/100\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.6269 - accuracy: 0.6800 - val_loss: 0.6002 - val_accuracy: 0.7153\n",
            "Epoch 35/100\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.6269 - accuracy: 0.6800 - val_loss: 0.6001 - val_accuracy: 0.7153\n",
            "Epoch 36/100\n",
            "105/105 [==============================] - 0s 1ms/step - loss: 0.6269 - accuracy: 0.6800 - val_loss: 0.6001 - val_accuracy: 0.7153\n",
            "Epoch 37/100\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.6269 - accuracy: 0.6800 - val_loss: 0.6003 - val_accuracy: 0.7153\n",
            "Epoch 38/100\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.6269 - accuracy: 0.6800 - val_loss: 0.6002 - val_accuracy: 0.7153\n",
            "Epoch 39/100\n",
            "105/105 [==============================] - 0s 1ms/step - loss: 0.6269 - accuracy: 0.6800 - val_loss: 0.6002 - val_accuracy: 0.7153\n",
            "Epoch 40/100\n",
            "105/105 [==============================] - 0s 1ms/step - loss: 0.6269 - accuracy: 0.6800 - val_loss: 0.6002 - val_accuracy: 0.7153\n",
            "Epoch 41/100\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.6269 - accuracy: 0.6800 - val_loss: 0.6002 - val_accuracy: 0.7153\n",
            "Epoch 42/100\n",
            "105/105 [==============================] - 0s 1ms/step - loss: 0.6269 - accuracy: 0.6800 - val_loss: 0.6001 - val_accuracy: 0.7153\n",
            "Epoch 43/100\n",
            "105/105 [==============================] - 0s 1ms/step - loss: 0.6269 - accuracy: 0.6800 - val_loss: 0.6003 - val_accuracy: 0.7153\n",
            "Epoch 44/100\n",
            "105/105 [==============================] - 0s 1ms/step - loss: 0.6269 - accuracy: 0.6800 - val_loss: 0.6002 - val_accuracy: 0.7153\n",
            "Epoch 45/100\n",
            "105/105 [==============================] - 0s 1ms/step - loss: 0.6269 - accuracy: 0.6800 - val_loss: 0.6002 - val_accuracy: 0.7153\n",
            "Epoch 46/100\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.6269 - accuracy: 0.6800 - val_loss: 0.6003 - val_accuracy: 0.7153\n",
            "Epoch 47/100\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.6269 - accuracy: 0.6800 - val_loss: 0.6003 - val_accuracy: 0.7153\n",
            "Epoch 48/100\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.6269 - accuracy: 0.6800 - val_loss: 0.6002 - val_accuracy: 0.7153\n",
            "Epoch 49/100\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.6269 - accuracy: 0.6800 - val_loss: 0.6002 - val_accuracy: 0.7153\n",
            "Epoch 50/100\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.6269 - accuracy: 0.6800 - val_loss: 0.6002 - val_accuracy: 0.7153\n",
            "Epoch 51/100\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.6269 - accuracy: 0.6800 - val_loss: 0.6003 - val_accuracy: 0.7153\n",
            "Epoch 52/100\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.6269 - accuracy: 0.6800 - val_loss: 0.6003 - val_accuracy: 0.7153\n",
            "Epoch 53/100\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.6269 - accuracy: 0.6800 - val_loss: 0.6002 - val_accuracy: 0.7153\n",
            "Epoch 54/100\n",
            "105/105 [==============================] - 0s 1ms/step - loss: 0.6269 - accuracy: 0.6800 - val_loss: 0.6002 - val_accuracy: 0.7153\n",
            "Epoch 55/100\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.6269 - accuracy: 0.6800 - val_loss: 0.6003 - val_accuracy: 0.7153\n",
            "Epoch 56/100\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.6269 - accuracy: 0.6800 - val_loss: 0.6001 - val_accuracy: 0.7153\n",
            "Epoch 57/100\n",
            "105/105 [==============================] - 0s 1ms/step - loss: 0.6269 - accuracy: 0.6800 - val_loss: 0.6002 - val_accuracy: 0.7153\n",
            "Epoch 58/100\n",
            "105/105 [==============================] - 0s 1ms/step - loss: 0.6269 - accuracy: 0.6800 - val_loss: 0.6001 - val_accuracy: 0.7153\n",
            "Epoch 59/100\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.6269 - accuracy: 0.6800 - val_loss: 0.6002 - val_accuracy: 0.7153\n",
            "Epoch 60/100\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.6269 - accuracy: 0.6800 - val_loss: 0.6002 - val_accuracy: 0.7153\n",
            "Epoch 61/100\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.6269 - accuracy: 0.6800 - val_loss: 0.6002 - val_accuracy: 0.7153\n",
            "Epoch 62/100\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.6269 - accuracy: 0.6800 - val_loss: 0.6003 - val_accuracy: 0.7153\n",
            "Epoch 63/100\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.6269 - accuracy: 0.6800 - val_loss: 0.6002 - val_accuracy: 0.7153\n",
            "Epoch 64/100\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.6269 - accuracy: 0.6800 - val_loss: 0.6003 - val_accuracy: 0.7153\n",
            "Epoch 65/100\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.6269 - accuracy: 0.6800 - val_loss: 0.6004 - val_accuracy: 0.7153\n",
            "Epoch 66/100\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.6269 - accuracy: 0.6800 - val_loss: 0.6003 - val_accuracy: 0.7153\n",
            "Epoch 67/100\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.6269 - accuracy: 0.6800 - val_loss: 0.6002 - val_accuracy: 0.7153\n",
            "Epoch 68/100\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.6269 - accuracy: 0.6800 - val_loss: 0.6002 - val_accuracy: 0.7153\n",
            "Epoch 69/100\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.6269 - accuracy: 0.6800 - val_loss: 0.6002 - val_accuracy: 0.7153\n",
            "Epoch 70/100\n",
            "105/105 [==============================] - 0s 1ms/step - loss: 0.6269 - accuracy: 0.6800 - val_loss: 0.6002 - val_accuracy: 0.7153\n",
            "Epoch 71/100\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.6269 - accuracy: 0.6800 - val_loss: 0.6002 - val_accuracy: 0.7153\n",
            "Epoch 72/100\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.6269 - accuracy: 0.6800 - val_loss: 0.6001 - val_accuracy: 0.7153\n",
            "Epoch 73/100\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.6269 - accuracy: 0.6800 - val_loss: 0.6002 - val_accuracy: 0.7153\n",
            "Epoch 74/100\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.6269 - accuracy: 0.6800 - val_loss: 0.6002 - val_accuracy: 0.7153\n",
            "Epoch 75/100\n",
            "105/105 [==============================] - 0s 1ms/step - loss: 0.6269 - accuracy: 0.6800 - val_loss: 0.6003 - val_accuracy: 0.7153\n",
            "Epoch 76/100\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.6269 - accuracy: 0.6800 - val_loss: 0.6002 - val_accuracy: 0.7153\n",
            "Epoch 77/100\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.6269 - accuracy: 0.6800 - val_loss: 0.6002 - val_accuracy: 0.7153\n",
            "Epoch 78/100\n",
            "105/105 [==============================] - 0s 1ms/step - loss: 0.6269 - accuracy: 0.6800 - val_loss: 0.6003 - val_accuracy: 0.7153\n",
            "Epoch 79/100\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.6269 - accuracy: 0.6800 - val_loss: 0.6004 - val_accuracy: 0.7153\n",
            "Epoch 80/100\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.6269 - accuracy: 0.6800 - val_loss: 0.6003 - val_accuracy: 0.7153\n",
            "Epoch 81/100\n",
            "105/105 [==============================] - 0s 3ms/step - loss: 0.6269 - accuracy: 0.6800 - val_loss: 0.6004 - val_accuracy: 0.7153\n",
            "Epoch 82/100\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.6269 - accuracy: 0.6800 - val_loss: 0.6004 - val_accuracy: 0.7153\n",
            "Epoch 83/100\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.6269 - accuracy: 0.6800 - val_loss: 0.6003 - val_accuracy: 0.7153\n",
            "Epoch 84/100\n",
            "105/105 [==============================] - 0s 1ms/step - loss: 0.6269 - accuracy: 0.6800 - val_loss: 0.6002 - val_accuracy: 0.7153\n",
            "Epoch 85/100\n",
            "105/105 [==============================] - 0s 3ms/step - loss: 0.6269 - accuracy: 0.6800 - val_loss: 0.6002 - val_accuracy: 0.7153\n",
            "Epoch 86/100\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.6269 - accuracy: 0.6800 - val_loss: 0.6003 - val_accuracy: 0.7153\n",
            "Epoch 87/100\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.6269 - accuracy: 0.6800 - val_loss: 0.6004 - val_accuracy: 0.7153\n",
            "Epoch 88/100\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.6269 - accuracy: 0.6800 - val_loss: 0.6004 - val_accuracy: 0.7153\n",
            "Epoch 89/100\n",
            "105/105 [==============================] - 0s 3ms/step - loss: 0.6269 - accuracy: 0.6800 - val_loss: 0.6003 - val_accuracy: 0.7153\n",
            "Epoch 90/100\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.6269 - accuracy: 0.6800 - val_loss: 0.6003 - val_accuracy: 0.7153\n",
            "Epoch 91/100\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.6269 - accuracy: 0.6800 - val_loss: 0.6002 - val_accuracy: 0.7153\n",
            "Epoch 92/100\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.6269 - accuracy: 0.6800 - val_loss: 0.6001 - val_accuracy: 0.7153\n",
            "Epoch 93/100\n",
            "105/105 [==============================] - 0s 1ms/step - loss: 0.6269 - accuracy: 0.6800 - val_loss: 0.6002 - val_accuracy: 0.7153\n",
            "Epoch 94/100\n",
            "105/105 [==============================] - 0s 1ms/step - loss: 0.6269 - accuracy: 0.6800 - val_loss: 0.6002 - val_accuracy: 0.7153\n",
            "Epoch 95/100\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.6269 - accuracy: 0.6800 - val_loss: 0.6002 - val_accuracy: 0.7153\n",
            "Epoch 96/100\n",
            "105/105 [==============================] - 0s 1ms/step - loss: 0.6269 - accuracy: 0.6800 - val_loss: 0.6003 - val_accuracy: 0.7153\n",
            "Epoch 97/100\n",
            "105/105 [==============================] - 0s 1ms/step - loss: 0.6269 - accuracy: 0.6800 - val_loss: 0.6003 - val_accuracy: 0.7153\n",
            "Epoch 98/100\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.6269 - accuracy: 0.6800 - val_loss: 0.6004 - val_accuracy: 0.7153\n",
            "Epoch 99/100\n",
            "105/105 [==============================] - 0s 1ms/step - loss: 0.6269 - accuracy: 0.6800 - val_loss: 0.6002 - val_accuracy: 0.7153\n",
            "Epoch 100/100\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.6269 - accuracy: 0.6800 - val_loss: 0.6002 - val_accuracy: 0.7153\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.get_weights()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0JXvkkt2XvyB",
        "outputId": "bb92dbd3-f97b-424d-b681-fcbf5f360378"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[array([[0., 0.],\n",
              "        [0., 0.],\n",
              "        [0., 0.],\n",
              "        [0., 0.],\n",
              "        [0., 0.],\n",
              "        [0., 0.],\n",
              "        [0., 0.],\n",
              "        [0., 0.]], dtype=float32),\n",
              " array([0., 0.], dtype=float32),\n",
              " array([[0.],\n",
              "        [0.]], dtype=float32),\n",
              " array([0.7545951], dtype=float32)]"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "aa7EEpSaZ-dV"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Case-3: Initialize weight with Zero.(tanh)\n"
      ],
      "metadata": {
        "id": "uknUWcqRZOGs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = Sequential()\n",
        "\n",
        "model.add(Dense(2,activation='tanh',input_dim=8))\n",
        "model.add(Dense(1,activation='sigmoid'))\n",
        "\n",
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DhMZtPnKZRRi",
        "outputId": "8bb34030-68f1-4224-e043-1f1b8cfd3353"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_2\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_4 (Dense)             (None, 2)                 18        \n",
            "                                                                 \n",
            " dense_5 (Dense)             (None, 1)                 3         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 21 (84.00 Byte)\n",
            "Trainable params: 21 (84.00 Byte)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.get_weights()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DTG1FjPCZYWc",
        "outputId": "1fb6798e-3097-43e5-968b-8e8cbb893210"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[array([[ 0.70410395,  0.7308798 ],\n",
              "        [ 0.24718797, -0.2575944 ],\n",
              "        [-0.3102408 ,  0.6910924 ],\n",
              "        [-0.42800623,  0.10024166],\n",
              "        [-0.5448965 ,  0.04366368],\n",
              "        [ 0.0672729 ,  0.20940608],\n",
              "        [ 0.6595715 ,  0.5647762 ],\n",
              "        [-0.02484697, -0.73239326]], dtype=float32),\n",
              " array([0., 0.], dtype=float32),\n",
              " array([[-0.6498825],\n",
              "        [ 1.1237952]], dtype=float32),\n",
              " array([0.], dtype=float32)]"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "initial_weights = model.get_weights()"
      ],
      "metadata": {
        "id": "8eIoBCH8ZYZa"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "initial_weights[0] = np.zeros(model.get_weights()[0].shape)\n",
        "initial_weights[1] = np.zeros(model.get_weights()[1].shape)\n",
        "initial_weights[2] = np.zeros(model.get_weights()[2].shape)\n",
        "initial_weights[3] = np.zeros(model.get_weights()[3].shape)"
      ],
      "metadata": {
        "id": "40Q5kw9LZYbk"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.set_weights(initial_weights)"
      ],
      "metadata": {
        "id": "Alga2ytgZYdl"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.get_weights()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zKXXZfZqZYfv",
        "outputId": "5f248401-871d-42c5-ed72-ad92e0714b89"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[array([[0., 0.],\n",
              "        [0., 0.],\n",
              "        [0., 0.],\n",
              "        [0., 0.],\n",
              "        [0., 0.],\n",
              "        [0., 0.],\n",
              "        [0., 0.],\n",
              "        [0., 0.]], dtype=float32),\n",
              " array([0., 0.], dtype=float32),\n",
              " array([[0.],\n",
              "        [0.]], dtype=float32),\n",
              " array([0.], dtype=float32)]"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(loss='binary_crossentropy',optimizer='adam',metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "snoioRnwZYh8"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "history = model.fit(X,y,epochs=100,validation_split=0.2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P0WFCc1aZYkI",
        "outputId": "904de71a-6d8a-480e-d4da-ca12f47b117f"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "105/105 [==============================] - 1s 2ms/step - loss: 0.6846 - accuracy: 0.6770 - val_loss: 0.6733 - val_accuracy: 0.7153\n",
            "Epoch 2/100\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.6704 - accuracy: 0.6800 - val_loss: 0.6579 - val_accuracy: 0.7153\n",
            "Epoch 3/100\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.6594 - accuracy: 0.6800 - val_loss: 0.6453 - val_accuracy: 0.7153\n",
            "Epoch 4/100\n",
            "105/105 [==============================] - 0s 1ms/step - loss: 0.6509 - accuracy: 0.6800 - val_loss: 0.6356 - val_accuracy: 0.7153\n",
            "Epoch 5/100\n",
            "105/105 [==============================] - 0s 1ms/step - loss: 0.6444 - accuracy: 0.6800 - val_loss: 0.6277 - val_accuracy: 0.7153\n",
            "Epoch 6/100\n",
            "105/105 [==============================] - 0s 1ms/step - loss: 0.6395 - accuracy: 0.6800 - val_loss: 0.6215 - val_accuracy: 0.7153\n",
            "Epoch 7/100\n",
            "105/105 [==============================] - 0s 1ms/step - loss: 0.6358 - accuracy: 0.6800 - val_loss: 0.6170 - val_accuracy: 0.7153\n",
            "Epoch 8/100\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.6332 - accuracy: 0.6800 - val_loss: 0.6131 - val_accuracy: 0.7153\n",
            "Epoch 9/100\n",
            "105/105 [==============================] - 0s 1ms/step - loss: 0.6312 - accuracy: 0.6800 - val_loss: 0.6101 - val_accuracy: 0.7153\n",
            "Epoch 10/100\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.6298 - accuracy: 0.6800 - val_loss: 0.6080 - val_accuracy: 0.7153\n",
            "Epoch 11/100\n",
            "105/105 [==============================] - 0s 1ms/step - loss: 0.6288 - accuracy: 0.6800 - val_loss: 0.6061 - val_accuracy: 0.7153\n",
            "Epoch 12/100\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.6282 - accuracy: 0.6800 - val_loss: 0.6047 - val_accuracy: 0.7153\n",
            "Epoch 13/100\n",
            "105/105 [==============================] - 0s 1ms/step - loss: 0.6278 - accuracy: 0.6800 - val_loss: 0.6039 - val_accuracy: 0.7153\n",
            "Epoch 14/100\n",
            "105/105 [==============================] - 0s 1ms/step - loss: 0.6275 - accuracy: 0.6800 - val_loss: 0.6032 - val_accuracy: 0.7153\n",
            "Epoch 15/100\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.6273 - accuracy: 0.6800 - val_loss: 0.6023 - val_accuracy: 0.7153\n",
            "Epoch 16/100\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.6271 - accuracy: 0.6800 - val_loss: 0.6019 - val_accuracy: 0.7153\n",
            "Epoch 17/100\n",
            "105/105 [==============================] - 0s 1ms/step - loss: 0.6270 - accuracy: 0.6800 - val_loss: 0.6016 - val_accuracy: 0.7153\n",
            "Epoch 18/100\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.6270 - accuracy: 0.6800 - val_loss: 0.6012 - val_accuracy: 0.7153\n",
            "Epoch 19/100\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.6269 - accuracy: 0.6800 - val_loss: 0.6010 - val_accuracy: 0.7153\n",
            "Epoch 20/100\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.6269 - accuracy: 0.6800 - val_loss: 0.6008 - val_accuracy: 0.7153\n",
            "Epoch 21/100\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.6269 - accuracy: 0.6800 - val_loss: 0.6008 - val_accuracy: 0.7153\n",
            "Epoch 22/100\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.6269 - accuracy: 0.6800 - val_loss: 0.6007 - val_accuracy: 0.7153\n",
            "Epoch 23/100\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.6269 - accuracy: 0.6800 - val_loss: 0.6005 - val_accuracy: 0.7153\n",
            "Epoch 24/100\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.6269 - accuracy: 0.6800 - val_loss: 0.6004 - val_accuracy: 0.7153\n",
            "Epoch 25/100\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.6269 - accuracy: 0.6800 - val_loss: 0.6004 - val_accuracy: 0.7153\n",
            "Epoch 26/100\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.6269 - accuracy: 0.6800 - val_loss: 0.6004 - val_accuracy: 0.7153\n",
            "Epoch 27/100\n",
            "105/105 [==============================] - 0s 1ms/step - loss: 0.6269 - accuracy: 0.6800 - val_loss: 0.6004 - val_accuracy: 0.7153\n",
            "Epoch 28/100\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.6269 - accuracy: 0.6800 - val_loss: 0.6003 - val_accuracy: 0.7153\n",
            "Epoch 29/100\n",
            "105/105 [==============================] - 0s 1ms/step - loss: 0.6269 - accuracy: 0.6800 - val_loss: 0.6003 - val_accuracy: 0.7153\n",
            "Epoch 30/100\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.6269 - accuracy: 0.6800 - val_loss: 0.6003 - val_accuracy: 0.7153\n",
            "Epoch 31/100\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.6269 - accuracy: 0.6800 - val_loss: 0.6004 - val_accuracy: 0.7153\n",
            "Epoch 32/100\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.6269 - accuracy: 0.6800 - val_loss: 0.6004 - val_accuracy: 0.7153\n",
            "Epoch 33/100\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.6269 - accuracy: 0.6800 - val_loss: 0.6004 - val_accuracy: 0.7153\n",
            "Epoch 34/100\n",
            "105/105 [==============================] - 0s 1ms/step - loss: 0.6269 - accuracy: 0.6800 - val_loss: 0.6003 - val_accuracy: 0.7153\n",
            "Epoch 35/100\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.6269 - accuracy: 0.6800 - val_loss: 0.6003 - val_accuracy: 0.7153\n",
            "Epoch 36/100\n",
            "105/105 [==============================] - 0s 1ms/step - loss: 0.6269 - accuracy: 0.6800 - val_loss: 0.6003 - val_accuracy: 0.7153\n",
            "Epoch 37/100\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.6269 - accuracy: 0.6800 - val_loss: 0.6001 - val_accuracy: 0.7153\n",
            "Epoch 38/100\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.6269 - accuracy: 0.6800 - val_loss: 0.6003 - val_accuracy: 0.7153\n",
            "Epoch 39/100\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.6269 - accuracy: 0.6800 - val_loss: 0.6002 - val_accuracy: 0.7153\n",
            "Epoch 40/100\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.6269 - accuracy: 0.6800 - val_loss: 0.6000 - val_accuracy: 0.7153\n",
            "Epoch 41/100\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.6269 - accuracy: 0.6800 - val_loss: 0.6002 - val_accuracy: 0.7153\n",
            "Epoch 42/100\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.6269 - accuracy: 0.6800 - val_loss: 0.6002 - val_accuracy: 0.7153\n",
            "Epoch 43/100\n",
            "105/105 [==============================] - 0s 1ms/step - loss: 0.6269 - accuracy: 0.6800 - val_loss: 0.6001 - val_accuracy: 0.7153\n",
            "Epoch 44/100\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.6269 - accuracy: 0.6800 - val_loss: 0.6003 - val_accuracy: 0.7153\n",
            "Epoch 45/100\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.6269 - accuracy: 0.6800 - val_loss: 0.6003 - val_accuracy: 0.7153\n",
            "Epoch 46/100\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.6269 - accuracy: 0.6800 - val_loss: 0.6003 - val_accuracy: 0.7153\n",
            "Epoch 47/100\n",
            "105/105 [==============================] - 0s 1ms/step - loss: 0.6269 - accuracy: 0.6800 - val_loss: 0.6003 - val_accuracy: 0.7153\n",
            "Epoch 48/100\n",
            "105/105 [==============================] - 0s 1ms/step - loss: 0.6269 - accuracy: 0.6800 - val_loss: 0.6003 - val_accuracy: 0.7153\n",
            "Epoch 49/100\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.6269 - accuracy: 0.6800 - val_loss: 0.6003 - val_accuracy: 0.7153\n",
            "Epoch 50/100\n",
            "105/105 [==============================] - 0s 1ms/step - loss: 0.6269 - accuracy: 0.6800 - val_loss: 0.6002 - val_accuracy: 0.7153\n",
            "Epoch 51/100\n",
            "105/105 [==============================] - 0s 1ms/step - loss: 0.6269 - accuracy: 0.6800 - val_loss: 0.6003 - val_accuracy: 0.7153\n",
            "Epoch 52/100\n",
            "105/105 [==============================] - 0s 1ms/step - loss: 0.6269 - accuracy: 0.6800 - val_loss: 0.6002 - val_accuracy: 0.7153\n",
            "Epoch 53/100\n",
            "105/105 [==============================] - 0s 1ms/step - loss: 0.6269 - accuracy: 0.6800 - val_loss: 0.6002 - val_accuracy: 0.7153\n",
            "Epoch 54/100\n",
            "105/105 [==============================] - 0s 1ms/step - loss: 0.6269 - accuracy: 0.6800 - val_loss: 0.6000 - val_accuracy: 0.7153\n",
            "Epoch 55/100\n",
            "105/105 [==============================] - 0s 1ms/step - loss: 0.6269 - accuracy: 0.6800 - val_loss: 0.6001 - val_accuracy: 0.7153\n",
            "Epoch 56/100\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.6269 - accuracy: 0.6800 - val_loss: 0.6003 - val_accuracy: 0.7153\n",
            "Epoch 57/100\n",
            "105/105 [==============================] - 0s 1ms/step - loss: 0.6269 - accuracy: 0.6800 - val_loss: 0.6002 - val_accuracy: 0.7153\n",
            "Epoch 58/100\n",
            "105/105 [==============================] - 0s 1ms/step - loss: 0.6269 - accuracy: 0.6800 - val_loss: 0.6001 - val_accuracy: 0.7153\n",
            "Epoch 59/100\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.6269 - accuracy: 0.6800 - val_loss: 0.6002 - val_accuracy: 0.7153\n",
            "Epoch 60/100\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.6269 - accuracy: 0.6800 - val_loss: 0.6003 - val_accuracy: 0.7153\n",
            "Epoch 61/100\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.6269 - accuracy: 0.6800 - val_loss: 0.6004 - val_accuracy: 0.7153\n",
            "Epoch 62/100\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.6269 - accuracy: 0.6800 - val_loss: 0.6002 - val_accuracy: 0.7153\n",
            "Epoch 63/100\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.6269 - accuracy: 0.6800 - val_loss: 0.6002 - val_accuracy: 0.7153\n",
            "Epoch 64/100\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.6269 - accuracy: 0.6800 - val_loss: 0.6002 - val_accuracy: 0.7153\n",
            "Epoch 65/100\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.6269 - accuracy: 0.6800 - val_loss: 0.6002 - val_accuracy: 0.7153\n",
            "Epoch 66/100\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.6269 - accuracy: 0.6800 - val_loss: 0.6001 - val_accuracy: 0.7153\n",
            "Epoch 67/100\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.6269 - accuracy: 0.6800 - val_loss: 0.6002 - val_accuracy: 0.7153\n",
            "Epoch 68/100\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.6269 - accuracy: 0.6800 - val_loss: 0.6002 - val_accuracy: 0.7153\n",
            "Epoch 69/100\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.6269 - accuracy: 0.6800 - val_loss: 0.6002 - val_accuracy: 0.7153\n",
            "Epoch 70/100\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.6269 - accuracy: 0.6800 - val_loss: 0.6002 - val_accuracy: 0.7153\n",
            "Epoch 71/100\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.6269 - accuracy: 0.6800 - val_loss: 0.6002 - val_accuracy: 0.7153\n",
            "Epoch 72/100\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.6269 - accuracy: 0.6800 - val_loss: 0.6002 - val_accuracy: 0.7153\n",
            "Epoch 73/100\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.6269 - accuracy: 0.6800 - val_loss: 0.6001 - val_accuracy: 0.7153\n",
            "Epoch 74/100\n",
            "105/105 [==============================] - 0s 1ms/step - loss: 0.6269 - accuracy: 0.6800 - val_loss: 0.6002 - val_accuracy: 0.7153\n",
            "Epoch 75/100\n",
            "105/105 [==============================] - 0s 1ms/step - loss: 0.6269 - accuracy: 0.6800 - val_loss: 0.6003 - val_accuracy: 0.7153\n",
            "Epoch 76/100\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.6269 - accuracy: 0.6800 - val_loss: 0.6002 - val_accuracy: 0.7153\n",
            "Epoch 77/100\n",
            "105/105 [==============================] - 0s 1ms/step - loss: 0.6269 - accuracy: 0.6800 - val_loss: 0.6003 - val_accuracy: 0.7153\n",
            "Epoch 78/100\n",
            "105/105 [==============================] - 0s 1ms/step - loss: 0.6269 - accuracy: 0.6800 - val_loss: 0.6002 - val_accuracy: 0.7153\n",
            "Epoch 79/100\n",
            "105/105 [==============================] - 0s 1ms/step - loss: 0.6269 - accuracy: 0.6800 - val_loss: 0.6003 - val_accuracy: 0.7153\n",
            "Epoch 80/100\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.6269 - accuracy: 0.6800 - val_loss: 0.6002 - val_accuracy: 0.7153\n",
            "Epoch 81/100\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.6269 - accuracy: 0.6800 - val_loss: 0.6002 - val_accuracy: 0.7153\n",
            "Epoch 82/100\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.6269 - accuracy: 0.6800 - val_loss: 0.6003 - val_accuracy: 0.7153\n",
            "Epoch 83/100\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.6269 - accuracy: 0.6800 - val_loss: 0.6002 - val_accuracy: 0.7153\n",
            "Epoch 84/100\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.6269 - accuracy: 0.6800 - val_loss: 0.6001 - val_accuracy: 0.7153\n",
            "Epoch 85/100\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.6269 - accuracy: 0.6800 - val_loss: 0.6002 - val_accuracy: 0.7153\n",
            "Epoch 86/100\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.6269 - accuracy: 0.6800 - val_loss: 0.6002 - val_accuracy: 0.7153\n",
            "Epoch 87/100\n",
            "105/105 [==============================] - 0s 1ms/step - loss: 0.6269 - accuracy: 0.6800 - val_loss: 0.6002 - val_accuracy: 0.7153\n",
            "Epoch 88/100\n",
            "105/105 [==============================] - 0s 1ms/step - loss: 0.6269 - accuracy: 0.6800 - val_loss: 0.6001 - val_accuracy: 0.7153\n",
            "Epoch 89/100\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.6269 - accuracy: 0.6800 - val_loss: 0.6003 - val_accuracy: 0.7153\n",
            "Epoch 90/100\n",
            "105/105 [==============================] - 0s 1ms/step - loss: 0.6269 - accuracy: 0.6800 - val_loss: 0.6002 - val_accuracy: 0.7153\n",
            "Epoch 91/100\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.6269 - accuracy: 0.6800 - val_loss: 0.6002 - val_accuracy: 0.7153\n",
            "Epoch 92/100\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.6269 - accuracy: 0.6800 - val_loss: 0.6003 - val_accuracy: 0.7153\n",
            "Epoch 93/100\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.6269 - accuracy: 0.6800 - val_loss: 0.6003 - val_accuracy: 0.7153\n",
            "Epoch 94/100\n",
            "105/105 [==============================] - 0s 1ms/step - loss: 0.6269 - accuracy: 0.6800 - val_loss: 0.6004 - val_accuracy: 0.7153\n",
            "Epoch 95/100\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.6269 - accuracy: 0.6800 - val_loss: 0.6004 - val_accuracy: 0.7153\n",
            "Epoch 96/100\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.6269 - accuracy: 0.6800 - val_loss: 0.6003 - val_accuracy: 0.7153\n",
            "Epoch 97/100\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.6269 - accuracy: 0.6800 - val_loss: 0.6003 - val_accuracy: 0.7153\n",
            "Epoch 98/100\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.6269 - accuracy: 0.6800 - val_loss: 0.6003 - val_accuracy: 0.7153\n",
            "Epoch 99/100\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.6269 - accuracy: 0.6800 - val_loss: 0.6002 - val_accuracy: 0.7153\n",
            "Epoch 100/100\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.6269 - accuracy: 0.6800 - val_loss: 0.6003 - val_accuracy: 0.7153\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.get_weights()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iadYI8RDaFRf",
        "outputId": "fecfde60-8ee2-40b0-b7fe-90c5d7b6c2f3"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[array([[0., 0.],\n",
              "        [0., 0.],\n",
              "        [0., 0.],\n",
              "        [0., 0.],\n",
              "        [0., 0.],\n",
              "        [0., 0.],\n",
              "        [0., 0.],\n",
              "        [0., 0.]], dtype=float32),\n",
              " array([0., 0.], dtype=float32),\n",
              " array([[0.],\n",
              "        [0.]], dtype=float32),\n",
              " array([0.75348073], dtype=float32)]"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Case-4: Initialize weight with Zero.(Sigmoid)\n",
        "\n",
        "##LINEAR working...checked with increase of neurons.\n"
      ],
      "metadata": {
        "id": "UKcfzhvZaNAG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = Sequential()\n",
        "\n",
        "model.add(Dense(2,activation='sigmoid',input_dim=8))\n",
        "model.add(Dense(1,activation='sigmoid'))\n",
        "\n",
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T-IUjAizaHDu",
        "outputId": "81731037-0a2b-434e-d7df-0084fa49fc3c"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_3\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_6 (Dense)             (None, 2)                 18        \n",
            "                                                                 \n",
            " dense_7 (Dense)             (None, 1)                 3         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 21 (84.00 Byte)\n",
            "Trainable params: 21 (84.00 Byte)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.get_weights()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CQiN63MSqlrI",
        "outputId": "d488edd3-ca78-4c38-ded6-98945d9b0dcf"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[array([[-0.04517597,  0.14111209],\n",
              "        [ 0.05307651, -0.05856293],\n",
              "        [-0.2934722 , -0.509092  ],\n",
              "        [ 0.16798848, -0.43931   ],\n",
              "        [-0.3233633 ,  0.2489537 ],\n",
              "        [-0.0589214 ,  0.73189723],\n",
              "        [ 0.5511981 ,  0.74297917],\n",
              "        [-0.02833664, -0.6219653 ]], dtype=float32),\n",
              " array([0., 0.], dtype=float32),\n",
              " array([[-0.8153476],\n",
              "        [-1.3690217]], dtype=float32),\n",
              " array([0.], dtype=float32)]"
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "initial_weights = model.get_weights()"
      ],
      "metadata": {
        "id": "AugRo3KMaHJ3"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "initial_weights[0] = np.zeros(model.get_weights()[0].shape)\n",
        "initial_weights[1] = np.zeros(model.get_weights()[1].shape)\n",
        "initial_weights[2] = np.zeros(model.get_weights()[2].shape)\n",
        "initial_weights[3] = np.zeros(model.get_weights()[3].shape)"
      ],
      "metadata": {
        "id": "IXY4S1IWaHPZ"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.set_weights(initial_weights)"
      ],
      "metadata": {
        "id": "qM9z7b2OaHSK"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.get_weights()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Vu1GK2WSaHWG",
        "outputId": "82c5109a-7247-40af-bd5b-a7cf94fc7753"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[array([[0., 0.],\n",
              "        [0., 0.],\n",
              "        [0., 0.],\n",
              "        [0., 0.],\n",
              "        [0., 0.],\n",
              "        [0., 0.],\n",
              "        [0., 0.],\n",
              "        [0., 0.]], dtype=float32),\n",
              " array([0., 0.], dtype=float32),\n",
              " array([[0.],\n",
              "        [0.]], dtype=float32),\n",
              " array([0.], dtype=float32)]"
            ]
          },
          "metadata": {},
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(loss='binary_crossentropy',optimizer='adam',metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "mrq0vOLNaHir"
      },
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "history = model.fit(X,y,epochs=100,validation_split=0.2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DaATfBpMpqYm",
        "outputId": "5e533ae3-2ed6-4191-ebe2-207da6383cc9"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "105/105 [==============================] - 1s 3ms/step - loss: 0.6768 - accuracy: 0.6764 - val_loss: 0.6521 - val_accuracy: 0.7153\n",
            "Epoch 2/100\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.6485 - accuracy: 0.6800 - val_loss: 0.6238 - val_accuracy: 0.7153\n",
            "Epoch 3/100\n",
            "105/105 [==============================] - 0s 1ms/step - loss: 0.6353 - accuracy: 0.6800 - val_loss: 0.6114 - val_accuracy: 0.7153\n",
            "Epoch 4/100\n",
            "105/105 [==============================] - 0s 1ms/step - loss: 0.6309 - accuracy: 0.6800 - val_loss: 0.6063 - val_accuracy: 0.7153\n",
            "Epoch 5/100\n",
            "105/105 [==============================] - 0s 1ms/step - loss: 0.6291 - accuracy: 0.6800 - val_loss: 0.6037 - val_accuracy: 0.7153\n",
            "Epoch 6/100\n",
            "105/105 [==============================] - 0s 1ms/step - loss: 0.6284 - accuracy: 0.6800 - val_loss: 0.6023 - val_accuracy: 0.7153\n",
            "Epoch 7/100\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.6281 - accuracy: 0.6800 - val_loss: 0.6019 - val_accuracy: 0.7153\n",
            "Epoch 8/100\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.6278 - accuracy: 0.6800 - val_loss: 0.6016 - val_accuracy: 0.7153\n",
            "Epoch 9/100\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.6277 - accuracy: 0.6800 - val_loss: 0.6014 - val_accuracy: 0.7153\n",
            "Epoch 10/100\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.6276 - accuracy: 0.6800 - val_loss: 0.6011 - val_accuracy: 0.7153\n",
            "Epoch 11/100\n",
            "105/105 [==============================] - 0s 1ms/step - loss: 0.6274 - accuracy: 0.6800 - val_loss: 0.6009 - val_accuracy: 0.7153\n",
            "Epoch 12/100\n",
            "105/105 [==============================] - 0s 1ms/step - loss: 0.6274 - accuracy: 0.6800 - val_loss: 0.6008 - val_accuracy: 0.7153\n",
            "Epoch 13/100\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.6274 - accuracy: 0.6800 - val_loss: 0.6005 - val_accuracy: 0.7153\n",
            "Epoch 14/100\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.6274 - accuracy: 0.6800 - val_loss: 0.6004 - val_accuracy: 0.7153\n",
            "Epoch 15/100\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.6272 - accuracy: 0.6800 - val_loss: 0.6006 - val_accuracy: 0.7153\n",
            "Epoch 16/100\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.6273 - accuracy: 0.6800 - val_loss: 0.6006 - val_accuracy: 0.7153\n",
            "Epoch 17/100\n",
            "105/105 [==============================] - 0s 1ms/step - loss: 0.6272 - accuracy: 0.6800 - val_loss: 0.6007 - val_accuracy: 0.7153\n",
            "Epoch 18/100\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.6272 - accuracy: 0.6800 - val_loss: 0.6005 - val_accuracy: 0.7153\n",
            "Epoch 19/100\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.6272 - accuracy: 0.6800 - val_loss: 0.6006 - val_accuracy: 0.7153\n",
            "Epoch 20/100\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.6272 - accuracy: 0.6800 - val_loss: 0.6002 - val_accuracy: 0.7153\n",
            "Epoch 21/100\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.6271 - accuracy: 0.6800 - val_loss: 0.6006 - val_accuracy: 0.7153\n",
            "Epoch 22/100\n",
            "105/105 [==============================] - 0s 1ms/step - loss: 0.6271 - accuracy: 0.6800 - val_loss: 0.6006 - val_accuracy: 0.7153\n",
            "Epoch 23/100\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.6271 - accuracy: 0.6800 - val_loss: 0.6007 - val_accuracy: 0.7153\n",
            "Epoch 24/100\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.6271 - accuracy: 0.6800 - val_loss: 0.6006 - val_accuracy: 0.7153\n",
            "Epoch 25/100\n",
            "105/105 [==============================] - 0s 1ms/step - loss: 0.6271 - accuracy: 0.6800 - val_loss: 0.6006 - val_accuracy: 0.7153\n",
            "Epoch 26/100\n",
            "105/105 [==============================] - 0s 1ms/step - loss: 0.6271 - accuracy: 0.6800 - val_loss: 0.6003 - val_accuracy: 0.7153\n",
            "Epoch 27/100\n",
            "105/105 [==============================] - 0s 1ms/step - loss: 0.6271 - accuracy: 0.6800 - val_loss: 0.6003 - val_accuracy: 0.7153\n",
            "Epoch 28/100\n",
            "105/105 [==============================] - 0s 1ms/step - loss: 0.6270 - accuracy: 0.6800 - val_loss: 0.6005 - val_accuracy: 0.7153\n",
            "Epoch 29/100\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.6271 - accuracy: 0.6800 - val_loss: 0.6001 - val_accuracy: 0.7153\n",
            "Epoch 30/100\n",
            "105/105 [==============================] - 0s 1ms/step - loss: 0.6270 - accuracy: 0.6800 - val_loss: 0.6003 - val_accuracy: 0.7153\n",
            "Epoch 31/100\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.6270 - accuracy: 0.6800 - val_loss: 0.6002 - val_accuracy: 0.7153\n",
            "Epoch 32/100\n",
            "105/105 [==============================] - 0s 1ms/step - loss: 0.6270 - accuracy: 0.6800 - val_loss: 0.6006 - val_accuracy: 0.7153\n",
            "Epoch 33/100\n",
            "105/105 [==============================] - 0s 1ms/step - loss: 0.6270 - accuracy: 0.6800 - val_loss: 0.6003 - val_accuracy: 0.7153\n",
            "Epoch 34/100\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.6271 - accuracy: 0.6800 - val_loss: 0.6003 - val_accuracy: 0.7153\n",
            "Epoch 35/100\n",
            "105/105 [==============================] - 0s 1ms/step - loss: 0.6271 - accuracy: 0.6800 - val_loss: 0.6000 - val_accuracy: 0.7153\n",
            "Epoch 36/100\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.6271 - accuracy: 0.6800 - val_loss: 0.6004 - val_accuracy: 0.7153\n",
            "Epoch 37/100\n",
            "105/105 [==============================] - 0s 1ms/step - loss: 0.6270 - accuracy: 0.6800 - val_loss: 0.6004 - val_accuracy: 0.7153\n",
            "Epoch 38/100\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.6270 - accuracy: 0.6800 - val_loss: 0.6003 - val_accuracy: 0.7153\n",
            "Epoch 39/100\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.6270 - accuracy: 0.6800 - val_loss: 0.6001 - val_accuracy: 0.7153\n",
            "Epoch 40/100\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.6270 - accuracy: 0.6800 - val_loss: 0.6003 - val_accuracy: 0.7153\n",
            "Epoch 41/100\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.6270 - accuracy: 0.6800 - val_loss: 0.6002 - val_accuracy: 0.7153\n",
            "Epoch 42/100\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.6270 - accuracy: 0.6800 - val_loss: 0.6000 - val_accuracy: 0.7153\n",
            "Epoch 43/100\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.6271 - accuracy: 0.6800 - val_loss: 0.5999 - val_accuracy: 0.7153\n",
            "Epoch 44/100\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.6270 - accuracy: 0.6800 - val_loss: 0.6005 - val_accuracy: 0.7153\n",
            "Epoch 45/100\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.6270 - accuracy: 0.6800 - val_loss: 0.6006 - val_accuracy: 0.7153\n",
            "Epoch 46/100\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.6270 - accuracy: 0.6800 - val_loss: 0.6001 - val_accuracy: 0.7153\n",
            "Epoch 47/100\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.6269 - accuracy: 0.6800 - val_loss: 0.6003 - val_accuracy: 0.7153\n",
            "Epoch 48/100\n",
            "105/105 [==============================] - 0s 1ms/step - loss: 0.6270 - accuracy: 0.6800 - val_loss: 0.6001 - val_accuracy: 0.7153\n",
            "Epoch 49/100\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.6269 - accuracy: 0.6800 - val_loss: 0.6004 - val_accuracy: 0.7153\n",
            "Epoch 50/100\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.6270 - accuracy: 0.6800 - val_loss: 0.6001 - val_accuracy: 0.7153\n",
            "Epoch 51/100\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.6270 - accuracy: 0.6800 - val_loss: 0.6004 - val_accuracy: 0.7153\n",
            "Epoch 52/100\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.6269 - accuracy: 0.6800 - val_loss: 0.6004 - val_accuracy: 0.7153\n",
            "Epoch 53/100\n",
            "105/105 [==============================] - 0s 1ms/step - loss: 0.6270 - accuracy: 0.6800 - val_loss: 0.6003 - val_accuracy: 0.7153\n",
            "Epoch 54/100\n",
            "105/105 [==============================] - 0s 1ms/step - loss: 0.6270 - accuracy: 0.6800 - val_loss: 0.5997 - val_accuracy: 0.7153\n",
            "Epoch 55/100\n",
            "105/105 [==============================] - 0s 1ms/step - loss: 0.6271 - accuracy: 0.6800 - val_loss: 0.6002 - val_accuracy: 0.7153\n",
            "Epoch 56/100\n",
            "105/105 [==============================] - 0s 1ms/step - loss: 0.6269 - accuracy: 0.6800 - val_loss: 0.6001 - val_accuracy: 0.7153\n",
            "Epoch 57/100\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.6270 - accuracy: 0.6800 - val_loss: 0.6000 - val_accuracy: 0.7153\n",
            "Epoch 58/100\n",
            "105/105 [==============================] - 0s 1ms/step - loss: 0.6269 - accuracy: 0.6800 - val_loss: 0.6002 - val_accuracy: 0.7153\n",
            "Epoch 59/100\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.6270 - accuracy: 0.6800 - val_loss: 0.6003 - val_accuracy: 0.7153\n",
            "Epoch 60/100\n",
            "105/105 [==============================] - 0s 1ms/step - loss: 0.6269 - accuracy: 0.6800 - val_loss: 0.6003 - val_accuracy: 0.7153\n",
            "Epoch 61/100\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.6270 - accuracy: 0.6800 - val_loss: 0.6005 - val_accuracy: 0.7153\n",
            "Epoch 62/100\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.6270 - accuracy: 0.6800 - val_loss: 0.6003 - val_accuracy: 0.7153\n",
            "Epoch 63/100\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.6269 - accuracy: 0.6800 - val_loss: 0.6006 - val_accuracy: 0.7153\n",
            "Epoch 64/100\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.6270 - accuracy: 0.6800 - val_loss: 0.6001 - val_accuracy: 0.7153\n",
            "Epoch 65/100\n",
            "105/105 [==============================] - 0s 1ms/step - loss: 0.6270 - accuracy: 0.6800 - val_loss: 0.6004 - val_accuracy: 0.7153\n",
            "Epoch 66/100\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.6270 - accuracy: 0.6800 - val_loss: 0.6002 - val_accuracy: 0.7153\n",
            "Epoch 67/100\n",
            "105/105 [==============================] - 0s 1ms/step - loss: 0.6270 - accuracy: 0.6800 - val_loss: 0.6001 - val_accuracy: 0.7153\n",
            "Epoch 68/100\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.6269 - accuracy: 0.6800 - val_loss: 0.6005 - val_accuracy: 0.7153\n",
            "Epoch 69/100\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.6269 - accuracy: 0.6800 - val_loss: 0.6004 - val_accuracy: 0.7153\n",
            "Epoch 70/100\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.6269 - accuracy: 0.6800 - val_loss: 0.6004 - val_accuracy: 0.7153\n",
            "Epoch 71/100\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.6270 - accuracy: 0.6800 - val_loss: 0.6005 - val_accuracy: 0.7153\n",
            "Epoch 72/100\n",
            "105/105 [==============================] - 0s 1ms/step - loss: 0.6269 - accuracy: 0.6800 - val_loss: 0.6001 - val_accuracy: 0.7153\n",
            "Epoch 73/100\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.6270 - accuracy: 0.6800 - val_loss: 0.6002 - val_accuracy: 0.7153\n",
            "Epoch 74/100\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.6269 - accuracy: 0.6800 - val_loss: 0.6003 - val_accuracy: 0.7153\n",
            "Epoch 75/100\n",
            "105/105 [==============================] - 0s 1ms/step - loss: 0.6269 - accuracy: 0.6800 - val_loss: 0.6002 - val_accuracy: 0.7153\n",
            "Epoch 76/100\n",
            "105/105 [==============================] - 0s 1ms/step - loss: 0.6269 - accuracy: 0.6800 - val_loss: 0.6007 - val_accuracy: 0.7153\n",
            "Epoch 77/100\n",
            "105/105 [==============================] - 0s 1ms/step - loss: 0.6269 - accuracy: 0.6800 - val_loss: 0.6003 - val_accuracy: 0.7153\n",
            "Epoch 78/100\n",
            "105/105 [==============================] - 0s 1ms/step - loss: 0.6270 - accuracy: 0.6800 - val_loss: 0.6002 - val_accuracy: 0.7153\n",
            "Epoch 79/100\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.6270 - accuracy: 0.6800 - val_loss: 0.6000 - val_accuracy: 0.7153\n",
            "Epoch 80/100\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.6269 - accuracy: 0.6800 - val_loss: 0.6003 - val_accuracy: 0.7153\n",
            "Epoch 81/100\n",
            "105/105 [==============================] - 0s 1ms/step - loss: 0.6269 - accuracy: 0.6800 - val_loss: 0.6005 - val_accuracy: 0.7153\n",
            "Epoch 82/100\n",
            "105/105 [==============================] - 0s 1ms/step - loss: 0.6270 - accuracy: 0.6800 - val_loss: 0.6000 - val_accuracy: 0.7153\n",
            "Epoch 83/100\n",
            "105/105 [==============================] - 0s 1ms/step - loss: 0.6269 - accuracy: 0.6800 - val_loss: 0.6002 - val_accuracy: 0.7153\n",
            "Epoch 84/100\n",
            "105/105 [==============================] - 0s 1ms/step - loss: 0.6269 - accuracy: 0.6800 - val_loss: 0.6006 - val_accuracy: 0.7153\n",
            "Epoch 85/100\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.6269 - accuracy: 0.6800 - val_loss: 0.6003 - val_accuracy: 0.7153\n",
            "Epoch 86/100\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.6270 - accuracy: 0.6800 - val_loss: 0.6000 - val_accuracy: 0.7153\n",
            "Epoch 87/100\n",
            "105/105 [==============================] - 0s 1ms/step - loss: 0.6270 - accuracy: 0.6800 - val_loss: 0.6000 - val_accuracy: 0.7153\n",
            "Epoch 88/100\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.6269 - accuracy: 0.6800 - val_loss: 0.6000 - val_accuracy: 0.7153\n",
            "Epoch 89/100\n",
            "105/105 [==============================] - 0s 1ms/step - loss: 0.6270 - accuracy: 0.6800 - val_loss: 0.6002 - val_accuracy: 0.7153\n",
            "Epoch 90/100\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.6270 - accuracy: 0.6800 - val_loss: 0.6000 - val_accuracy: 0.7153\n",
            "Epoch 91/100\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.6269 - accuracy: 0.6800 - val_loss: 0.6002 - val_accuracy: 0.7153\n",
            "Epoch 92/100\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.6269 - accuracy: 0.6800 - val_loss: 0.5998 - val_accuracy: 0.7153\n",
            "Epoch 93/100\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.6270 - accuracy: 0.6800 - val_loss: 0.6000 - val_accuracy: 0.7153\n",
            "Epoch 94/100\n",
            "105/105 [==============================] - 0s 1ms/step - loss: 0.6269 - accuracy: 0.6800 - val_loss: 0.6003 - val_accuracy: 0.7153\n",
            "Epoch 95/100\n",
            "105/105 [==============================] - 0s 1ms/step - loss: 0.6269 - accuracy: 0.6800 - val_loss: 0.6001 - val_accuracy: 0.7153\n",
            "Epoch 96/100\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.6269 - accuracy: 0.6800 - val_loss: 0.6004 - val_accuracy: 0.7153\n",
            "Epoch 97/100\n",
            "105/105 [==============================] - 0s 1ms/step - loss: 0.6269 - accuracy: 0.6800 - val_loss: 0.6004 - val_accuracy: 0.7153\n",
            "Epoch 98/100\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.6269 - accuracy: 0.6800 - val_loss: 0.6003 - val_accuracy: 0.7153\n",
            "Epoch 99/100\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.6269 - accuracy: 0.6800 - val_loss: 0.6007 - val_accuracy: 0.7153\n",
            "Epoch 100/100\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.6270 - accuracy: 0.6800 - val_loss: 0.6003 - val_accuracy: 0.7153\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.get_weights()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JRiHT1t3ptWl",
        "outputId": "db9f1c97-5812-4005-b939-310906733e80"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[array([[1.3645728 , 1.3645728 ],\n",
              "        [1.331666  , 1.331666  ],\n",
              "        [1.2646497 , 1.2646497 ],\n",
              "        [0.52743477, 0.52743477],\n",
              "        [0.5426643 , 0.5426643 ],\n",
              "        [0.5007292 , 0.5007292 ],\n",
              "        [0.5546721 , 0.5546721 ],\n",
              "        [1.3639214 , 1.3639214 ]], dtype=float32),\n",
              " array([1.9518261, 1.9518261], dtype=float32),\n",
              " array([[0.24973841],\n",
              "        [0.24973841]], dtype=float32),\n",
              " array([0.25352576], dtype=float32)]"
            ]
          },
          "metadata": {},
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = Sequential()\n",
        "\n",
        "model.add(Dense(10,activation='sigmoid',input_dim=8))\n",
        "model.add(Dense(1,activation='sigmoid'))\n",
        "\n",
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qgwaXlOqqYbF",
        "outputId": "d243c444-cb0f-40a0-d89f-8ddc8eb84e55"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_4\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_8 (Dense)             (None, 10)                90        \n",
            "                                                                 \n",
            " dense_9 (Dense)             (None, 1)                 11        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 101 (404.00 Byte)\n",
            "Trainable params: 101 (404.00 Byte)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.get_weights()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UE77IuU6qYiy",
        "outputId": "dfb32948-3865-4e7f-8d6a-0655bf21b25b"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[array([[-0.34579673,  0.49191177,  0.20212388, -0.34274748,  0.31054842,\n",
              "         -0.03155333,  0.4469372 , -0.44728696, -0.47054476,  0.40352452],\n",
              "        [ 0.34657365,  0.05232692, -0.3486994 ,  0.46146858,  0.4139498 ,\n",
              "          0.15936673, -0.11982769,  0.47569525, -0.44896865,  0.13392162],\n",
              "        [ 0.56954956,  0.13114578,  0.20774221,  0.4786749 , -0.435381  ,\n",
              "          0.26063657, -0.05559576,  0.22779828, -0.17472005, -0.56466377],\n",
              "        [ 0.5735291 , -0.11959258, -0.03165394,  0.47244775, -0.4529451 ,\n",
              "         -0.35412985,  0.48704898, -0.09832302,  0.5761826 , -0.3671043 ],\n",
              "        [-0.24742895, -0.07527417, -0.5088386 , -0.2675252 ,  0.5671444 ,\n",
              "         -0.47594756, -0.0229404 , -0.41110885, -0.50342023,  0.24048227],\n",
              "        [ 0.06763345,  0.2484144 , -0.3607602 , -0.15496051,  0.3462236 ,\n",
              "         -0.317555  , -0.45577276,  0.48135936,  0.02880168,  0.06749731],\n",
              "        [-0.11187148,  0.5461168 , -0.559414  , -0.33635786,  0.2674412 ,\n",
              "          0.18357873, -0.22605368, -0.16453812,  0.09586346, -0.10339698],\n",
              "        [-0.5418024 , -0.5270694 , -0.51026106, -0.45162654, -0.52432007,\n",
              "         -0.00539333, -0.45097077, -0.0075438 , -0.5752647 , -0.28788927]],\n",
              "       dtype=float32),\n",
              " array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], dtype=float32),\n",
              " array([[-0.11515635],\n",
              "        [ 0.4598034 ],\n",
              "        [ 0.41891462],\n",
              "        [-0.5237706 ],\n",
              "        [ 0.46498019],\n",
              "        [-0.2134921 ],\n",
              "        [-0.15913117],\n",
              "        [ 0.36920422],\n",
              "        [-0.15622312],\n",
              "        [-0.12802875]], dtype=float32),\n",
              " array([0.], dtype=float32)]"
            ]
          },
          "metadata": {},
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "initial_weights = model.get_weights()"
      ],
      "metadata": {
        "id": "cnUDdQMOqYlp"
      },
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "initial_weights[0] = np.zeros(model.get_weights()[0].shape)\n",
        "initial_weights[1] = np.zeros(model.get_weights()[1].shape)\n",
        "initial_weights[2] = np.zeros(model.get_weights()[2].shape)\n",
        "initial_weights[3] = np.zeros(model.get_weights()[3].shape)"
      ],
      "metadata": {
        "id": "PHxsePV5qYn0"
      },
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.set_weights(initial_weights)"
      ],
      "metadata": {
        "id": "ddHEOQmGqYqF"
      },
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.get_weights()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CsM_yRfGqYr2",
        "outputId": "4bd0ea12-67ac-40fa-a721-d84a7f407cf6"
      },
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[array([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]], dtype=float32),\n",
              " array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], dtype=float32),\n",
              " array([[0.],\n",
              "        [0.],\n",
              "        [0.],\n",
              "        [0.],\n",
              "        [0.],\n",
              "        [0.],\n",
              "        [0.],\n",
              "        [0.],\n",
              "        [0.],\n",
              "        [0.]], dtype=float32),\n",
              " array([0.], dtype=float32)]"
            ]
          },
          "metadata": {},
          "execution_count": 45
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(loss='binary_crossentropy',optimizer='adam',metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "jGMgdCv4qYuN"
      },
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "history = model.fit(X,y,epochs=100,validation_split=0.2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WjCC15tIqYwJ",
        "outputId": "d8a587fa-80a6-45b4-93b6-992d732aa201"
      },
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "105/105 [==============================] - 1s 3ms/step - loss: 0.6536 - accuracy: 0.6782 - val_loss: 0.6123 - val_accuracy: 0.7153\n",
            "Epoch 2/100\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.6334 - accuracy: 0.6800 - val_loss: 0.6052 - val_accuracy: 0.7153\n",
            "Epoch 3/100\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.6306 - accuracy: 0.6800 - val_loss: 0.6031 - val_accuracy: 0.7153\n",
            "Epoch 4/100\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.6253 - accuracy: 0.6800 - val_loss: 0.5988 - val_accuracy: 0.7153\n",
            "Epoch 5/100\n",
            "105/105 [==============================] - 0s 1ms/step - loss: 0.6184 - accuracy: 0.6800 - val_loss: 0.5887 - val_accuracy: 0.7153\n",
            "Epoch 6/100\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.6115 - accuracy: 0.6800 - val_loss: 0.5837 - val_accuracy: 0.7153\n",
            "Epoch 7/100\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.6059 - accuracy: 0.6800 - val_loss: 0.5780 - val_accuracy: 0.7153\n",
            "Epoch 8/100\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.6006 - accuracy: 0.6800 - val_loss: 0.5724 - val_accuracy: 0.7153\n",
            "Epoch 9/100\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.5962 - accuracy: 0.6800 - val_loss: 0.5666 - val_accuracy: 0.7153\n",
            "Epoch 10/100\n",
            "105/105 [==============================] - 0s 1ms/step - loss: 0.5921 - accuracy: 0.6800 - val_loss: 0.5618 - val_accuracy: 0.7153\n",
            "Epoch 11/100\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.5884 - accuracy: 0.6800 - val_loss: 0.5572 - val_accuracy: 0.7153\n",
            "Epoch 12/100\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.5851 - accuracy: 0.6800 - val_loss: 0.5546 - val_accuracy: 0.7153\n",
            "Epoch 13/100\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.5822 - accuracy: 0.6800 - val_loss: 0.5512 - val_accuracy: 0.7153\n",
            "Epoch 14/100\n",
            "105/105 [==============================] - 0s 1ms/step - loss: 0.5795 - accuracy: 0.6800 - val_loss: 0.5474 - val_accuracy: 0.7153\n",
            "Epoch 15/100\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.5769 - accuracy: 0.6800 - val_loss: 0.5439 - val_accuracy: 0.7153\n",
            "Epoch 16/100\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.5749 - accuracy: 0.6800 - val_loss: 0.5431 - val_accuracy: 0.7153\n",
            "Epoch 17/100\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.5732 - accuracy: 0.6800 - val_loss: 0.5417 - val_accuracy: 0.7153\n",
            "Epoch 18/100\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.5711 - accuracy: 0.6800 - val_loss: 0.5379 - val_accuracy: 0.7153\n",
            "Epoch 19/100\n",
            "105/105 [==============================] - 0s 1ms/step - loss: 0.5695 - accuracy: 0.6800 - val_loss: 0.5357 - val_accuracy: 0.7153\n",
            "Epoch 20/100\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.5681 - accuracy: 0.6800 - val_loss: 0.5336 - val_accuracy: 0.7153\n",
            "Epoch 21/100\n",
            "105/105 [==============================] - 0s 1ms/step - loss: 0.5668 - accuracy: 0.6800 - val_loss: 0.5327 - val_accuracy: 0.7153\n",
            "Epoch 22/100\n",
            "105/105 [==============================] - 0s 1ms/step - loss: 0.5656 - accuracy: 0.6800 - val_loss: 0.5330 - val_accuracy: 0.7153\n",
            "Epoch 23/100\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.5646 - accuracy: 0.6800 - val_loss: 0.5330 - val_accuracy: 0.7153\n",
            "Epoch 24/100\n",
            "105/105 [==============================] - 0s 1ms/step - loss: 0.5638 - accuracy: 0.6797 - val_loss: 0.5307 - val_accuracy: 0.7153\n",
            "Epoch 25/100\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.5631 - accuracy: 0.6800 - val_loss: 0.5291 - val_accuracy: 0.7153\n",
            "Epoch 26/100\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.5625 - accuracy: 0.6800 - val_loss: 0.5286 - val_accuracy: 0.7129\n",
            "Epoch 27/100\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.5622 - accuracy: 0.6800 - val_loss: 0.5318 - val_accuracy: 0.7105\n",
            "Epoch 28/100\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.5612 - accuracy: 0.6776 - val_loss: 0.5269 - val_accuracy: 0.7117\n",
            "Epoch 29/100\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.5609 - accuracy: 0.6776 - val_loss: 0.5268 - val_accuracy: 0.7093\n",
            "Epoch 30/100\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.5604 - accuracy: 0.6773 - val_loss: 0.5266 - val_accuracy: 0.7057\n",
            "Epoch 31/100\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.5601 - accuracy: 0.6782 - val_loss: 0.5260 - val_accuracy: 0.7033\n",
            "Epoch 32/100\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.5598 - accuracy: 0.6773 - val_loss: 0.5258 - val_accuracy: 0.7045\n",
            "Epoch 33/100\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.5593 - accuracy: 0.6794 - val_loss: 0.5252 - val_accuracy: 0.7057\n",
            "Epoch 34/100\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.5592 - accuracy: 0.6779 - val_loss: 0.5253 - val_accuracy: 0.7081\n",
            "Epoch 35/100\n",
            "105/105 [==============================] - 0s 1ms/step - loss: 0.5590 - accuracy: 0.6791 - val_loss: 0.5249 - val_accuracy: 0.7093\n",
            "Epoch 36/100\n",
            "105/105 [==============================] - 0s 1ms/step - loss: 0.5588 - accuracy: 0.6797 - val_loss: 0.5251 - val_accuracy: 0.7069\n",
            "Epoch 37/100\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.5586 - accuracy: 0.6729 - val_loss: 0.5229 - val_accuracy: 0.7093\n",
            "Epoch 38/100\n",
            "105/105 [==============================] - 0s 1ms/step - loss: 0.5584 - accuracy: 0.6714 - val_loss: 0.5230 - val_accuracy: 0.7069\n",
            "Epoch 39/100\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.5585 - accuracy: 0.6779 - val_loss: 0.5244 - val_accuracy: 0.7129\n",
            "Epoch 40/100\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.5581 - accuracy: 0.6729 - val_loss: 0.5226 - val_accuracy: 0.7105\n",
            "Epoch 41/100\n",
            "105/105 [==============================] - 0s 1ms/step - loss: 0.5581 - accuracy: 0.6764 - val_loss: 0.5246 - val_accuracy: 0.7093\n",
            "Epoch 42/100\n",
            "105/105 [==============================] - 0s 1ms/step - loss: 0.5578 - accuracy: 0.6732 - val_loss: 0.5232 - val_accuracy: 0.7105\n",
            "Epoch 43/100\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.5577 - accuracy: 0.6752 - val_loss: 0.5254 - val_accuracy: 0.7081\n",
            "Epoch 44/100\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.5576 - accuracy: 0.6749 - val_loss: 0.5218 - val_accuracy: 0.7105\n",
            "Epoch 45/100\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.5575 - accuracy: 0.6735 - val_loss: 0.5235 - val_accuracy: 0.7105\n",
            "Epoch 46/100\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.5576 - accuracy: 0.6729 - val_loss: 0.5234 - val_accuracy: 0.7117\n",
            "Epoch 47/100\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.5575 - accuracy: 0.6729 - val_loss: 0.5230 - val_accuracy: 0.7117\n",
            "Epoch 48/100\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.5574 - accuracy: 0.6723 - val_loss: 0.5229 - val_accuracy: 0.7081\n",
            "Epoch 49/100\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.5575 - accuracy: 0.6711 - val_loss: 0.5229 - val_accuracy: 0.7093\n",
            "Epoch 50/100\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.5572 - accuracy: 0.6720 - val_loss: 0.5237 - val_accuracy: 0.7105\n",
            "Epoch 51/100\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.5573 - accuracy: 0.6735 - val_loss: 0.5234 - val_accuracy: 0.7105\n",
            "Epoch 52/100\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.5571 - accuracy: 0.6708 - val_loss: 0.5218 - val_accuracy: 0.7081\n",
            "Epoch 53/100\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.5573 - accuracy: 0.6711 - val_loss: 0.5249 - val_accuracy: 0.7081\n",
            "Epoch 54/100\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.5570 - accuracy: 0.6702 - val_loss: 0.5214 - val_accuracy: 0.7069\n",
            "Epoch 55/100\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.5570 - accuracy: 0.6720 - val_loss: 0.5224 - val_accuracy: 0.7129\n",
            "Epoch 56/100\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.5569 - accuracy: 0.6708 - val_loss: 0.5214 - val_accuracy: 0.7093\n",
            "Epoch 57/100\n",
            "105/105 [==============================] - 0s 1ms/step - loss: 0.5568 - accuracy: 0.6717 - val_loss: 0.5220 - val_accuracy: 0.7093\n",
            "Epoch 58/100\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.5568 - accuracy: 0.6702 - val_loss: 0.5215 - val_accuracy: 0.7093\n",
            "Epoch 59/100\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.5568 - accuracy: 0.6693 - val_loss: 0.5226 - val_accuracy: 0.7117\n",
            "Epoch 60/100\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.5569 - accuracy: 0.6720 - val_loss: 0.5224 - val_accuracy: 0.7105\n",
            "Epoch 61/100\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.5568 - accuracy: 0.6702 - val_loss: 0.5221 - val_accuracy: 0.7093\n",
            "Epoch 62/100\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.5567 - accuracy: 0.6723 - val_loss: 0.5222 - val_accuracy: 0.7093\n",
            "Epoch 63/100\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.5567 - accuracy: 0.6708 - val_loss: 0.5226 - val_accuracy: 0.7105\n",
            "Epoch 64/100\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.5566 - accuracy: 0.6717 - val_loss: 0.5229 - val_accuracy: 0.7105\n",
            "Epoch 65/100\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.5566 - accuracy: 0.6726 - val_loss: 0.5227 - val_accuracy: 0.7081\n",
            "Epoch 66/100\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.5566 - accuracy: 0.6729 - val_loss: 0.5216 - val_accuracy: 0.7081\n",
            "Epoch 67/100\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.5565 - accuracy: 0.6735 - val_loss: 0.5215 - val_accuracy: 0.7081\n",
            "Epoch 68/100\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.5566 - accuracy: 0.6726 - val_loss: 0.5195 - val_accuracy: 0.7081\n",
            "Epoch 69/100\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.5565 - accuracy: 0.6720 - val_loss: 0.5219 - val_accuracy: 0.7081\n",
            "Epoch 70/100\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.5565 - accuracy: 0.6714 - val_loss: 0.5199 - val_accuracy: 0.7081\n",
            "Epoch 71/100\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.5565 - accuracy: 0.6740 - val_loss: 0.5208 - val_accuracy: 0.7057\n",
            "Epoch 72/100\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.5569 - accuracy: 0.6720 - val_loss: 0.5223 - val_accuracy: 0.7069\n",
            "Epoch 73/100\n",
            "105/105 [==============================] - 0s 1ms/step - loss: 0.5566 - accuracy: 0.6723 - val_loss: 0.5220 - val_accuracy: 0.7093\n",
            "Epoch 74/100\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.5564 - accuracy: 0.6708 - val_loss: 0.5223 - val_accuracy: 0.7081\n",
            "Epoch 75/100\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.5565 - accuracy: 0.6732 - val_loss: 0.5217 - val_accuracy: 0.7093\n",
            "Epoch 76/100\n",
            "105/105 [==============================] - 0s 1ms/step - loss: 0.5564 - accuracy: 0.6714 - val_loss: 0.5212 - val_accuracy: 0.7069\n",
            "Epoch 77/100\n",
            "105/105 [==============================] - 0s 1ms/step - loss: 0.5563 - accuracy: 0.6738 - val_loss: 0.5230 - val_accuracy: 0.7081\n",
            "Epoch 78/100\n",
            "105/105 [==============================] - 0s 1ms/step - loss: 0.5563 - accuracy: 0.6705 - val_loss: 0.5205 - val_accuracy: 0.7057\n",
            "Epoch 79/100\n",
            "105/105 [==============================] - 0s 1ms/step - loss: 0.5562 - accuracy: 0.6732 - val_loss: 0.5221 - val_accuracy: 0.7081\n",
            "Epoch 80/100\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.5564 - accuracy: 0.6723 - val_loss: 0.5210 - val_accuracy: 0.7057\n",
            "Epoch 81/100\n",
            "105/105 [==============================] - 0s 1ms/step - loss: 0.5564 - accuracy: 0.6732 - val_loss: 0.5213 - val_accuracy: 0.7081\n",
            "Epoch 82/100\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.5563 - accuracy: 0.6717 - val_loss: 0.5208 - val_accuracy: 0.7057\n",
            "Epoch 83/100\n",
            "105/105 [==============================] - 0s 1ms/step - loss: 0.5562 - accuracy: 0.6743 - val_loss: 0.5232 - val_accuracy: 0.7093\n",
            "Epoch 84/100\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.5564 - accuracy: 0.6732 - val_loss: 0.5215 - val_accuracy: 0.7057\n",
            "Epoch 85/100\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.5563 - accuracy: 0.6702 - val_loss: 0.5211 - val_accuracy: 0.7045\n",
            "Epoch 86/100\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.5561 - accuracy: 0.6735 - val_loss: 0.5192 - val_accuracy: 0.7069\n",
            "Epoch 87/100\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.5562 - accuracy: 0.6749 - val_loss: 0.5215 - val_accuracy: 0.7057\n",
            "Epoch 88/100\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.5561 - accuracy: 0.6732 - val_loss: 0.5207 - val_accuracy: 0.7081\n",
            "Epoch 89/100\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.5566 - accuracy: 0.6764 - val_loss: 0.5224 - val_accuracy: 0.7069\n",
            "Epoch 90/100\n",
            "105/105 [==============================] - 0s 1ms/step - loss: 0.5562 - accuracy: 0.6735 - val_loss: 0.5221 - val_accuracy: 0.7057\n",
            "Epoch 91/100\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.5562 - accuracy: 0.6735 - val_loss: 0.5217 - val_accuracy: 0.7057\n",
            "Epoch 92/100\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.5560 - accuracy: 0.6720 - val_loss: 0.5198 - val_accuracy: 0.7057\n",
            "Epoch 93/100\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.5561 - accuracy: 0.6743 - val_loss: 0.5211 - val_accuracy: 0.7081\n",
            "Epoch 94/100\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.5562 - accuracy: 0.6749 - val_loss: 0.5204 - val_accuracy: 0.7069\n",
            "Epoch 95/100\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.5560 - accuracy: 0.6738 - val_loss: 0.5203 - val_accuracy: 0.7093\n",
            "Epoch 96/100\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.5560 - accuracy: 0.6767 - val_loss: 0.5234 - val_accuracy: 0.7081\n",
            "Epoch 97/100\n",
            "105/105 [==============================] - 0s 1ms/step - loss: 0.5561 - accuracy: 0.6761 - val_loss: 0.5203 - val_accuracy: 0.7045\n",
            "Epoch 98/100\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.5560 - accuracy: 0.6746 - val_loss: 0.5219 - val_accuracy: 0.7069\n",
            "Epoch 99/100\n",
            "105/105 [==============================] - 0s 1ms/step - loss: 0.5562 - accuracy: 0.6752 - val_loss: 0.5227 - val_accuracy: 0.7057\n",
            "Epoch 100/100\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.5560 - accuracy: 0.6785 - val_loss: 0.5214 - val_accuracy: 0.7069\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.get_weights()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u10mC-mNqY0F",
        "outputId": "8356b99d-b4f4-4e45-c957-23622ff13623"
      },
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[array([[ 0.22535439,  0.22535439,  0.22535439,  0.22535439,  0.22535439,\n",
              "          0.22535439,  0.22535439,  0.22535439,  0.22535428,  0.22535428],\n",
              "        [ 0.08479504,  0.08479504,  0.08479504,  0.08479504,  0.08479504,\n",
              "          0.08479504,  0.08479504,  0.08479504,  0.08479505,  0.08479505],\n",
              "        [-0.6492732 , -0.6492732 , -0.6492732 , -0.6492732 , -0.6492732 ,\n",
              "         -0.6492732 , -0.6492732 , -0.6492732 , -0.6492733 , -0.6492733 ],\n",
              "        [-1.139993  , -1.139993  , -1.139993  , -1.139993  , -1.139993  ,\n",
              "         -1.139993  , -1.139993  , -1.139993  , -1.1399928 , -1.1399928 ],\n",
              "        [-0.57371324, -0.57371324, -0.57371324, -0.57371324, -0.57371324,\n",
              "         -0.57371324, -0.57371324, -0.57371324, -0.5737131 , -0.5737131 ],\n",
              "        [-1.6545714 , -1.6545714 , -1.6545714 , -1.6545714 , -1.6545714 ,\n",
              "         -1.6545714 , -1.6545714 , -1.6545714 , -1.6545719 , -1.6545719 ],\n",
              "        [-1.1311226 , -1.1311226 , -1.1311226 , -1.1311226 , -1.1311226 ,\n",
              "         -1.1311226 , -1.1311226 , -1.1311226 , -1.1311225 , -1.1311225 ],\n",
              "        [-0.2198726 , -0.2198726 , -0.2198726 , -0.2198726 , -0.2198726 ,\n",
              "         -0.2198726 , -0.2198726 , -0.2198726 , -0.2198726 , -0.2198726 ]],\n",
              "       dtype=float32),\n",
              " array([1.0647622, 1.0647622, 1.0647622, 1.0647622, 1.0647622, 1.0647622,\n",
              "        1.0647622, 1.0647622, 1.0647621, 1.0647621], dtype=float32),\n",
              " array([[0.9266026],\n",
              "        [0.9266026],\n",
              "        [0.9266026],\n",
              "        [0.9266026],\n",
              "        [0.9266026],\n",
              "        [0.9266026],\n",
              "        [0.9266026],\n",
              "        [0.9266026],\n",
              "        [0.9266028],\n",
              "        [0.9266028]], dtype=float32),\n",
              " array([-0.04940361], dtype=float32)]"
            ]
          },
          "metadata": {},
          "execution_count": 48
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Case5:Zeros initilization."
      ],
      "metadata": {
        "id": "BmtK96NquDW0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Zero Initialization\n",
        "import tensorflow as tf\n",
        "\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras import initializers\n",
        "\n",
        "initializer = tf.keras.initializers.Zeros()\n"
      ],
      "metadata": {
        "id": "QBbG9T5grovS"
      },
      "execution_count": 61,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = Sequential()\n",
        "\n",
        "model.add(Dense(2,activation='relu',input_dim=8,kernel_initializer=initializer))\n",
        "model.add(Dense(1,activation='sigmoid'))\n",
        "\n",
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qDqjwg8xro4I",
        "outputId": "e358241f-5f8f-4502-d84d-25d02e95469c"
      },
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_7\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_14 (Dense)            (None, 2)                 18        \n",
            "                                                                 \n",
            " dense_15 (Dense)            (None, 1)                 3         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 21 (84.00 Byte)\n",
            "Trainable params: 21 (84.00 Byte)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.get_weights()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ykPixVzxw92U",
        "outputId": "b25a4650-5372-4ff5-a1b8-9a46d098a8fc"
      },
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[array([[0., 0.],\n",
              "        [0., 0.],\n",
              "        [0., 0.],\n",
              "        [0., 0.],\n",
              "        [0., 0.],\n",
              "        [0., 0.],\n",
              "        [0., 0.],\n",
              "        [0., 0.]], dtype=float32),\n",
              " array([0., 0.], dtype=float32),\n",
              " array([[-0.6596491],\n",
              "        [-0.2786696]], dtype=float32),\n",
              " array([0.], dtype=float32)]"
            ]
          },
          "metadata": {},
          "execution_count": 63
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(loss='binary_crossentropy',optimizer='adam',metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "bYau8tndro7k"
      },
      "execution_count": 64,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "history = model.fit(X,y,epochs=100,validation_split=0.2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mzE9a0eBro9w",
        "outputId": "924066f2-4d75-4949-e1ce-a08e136d3bb7"
      },
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "105/105 [==============================] - 1s 3ms/step - loss: 0.6852 - accuracy: 0.6764 - val_loss: 0.6742 - val_accuracy: 0.7153\n",
            "Epoch 2/100\n",
            "105/105 [==============================] - 0s 1ms/step - loss: 0.6710 - accuracy: 0.6800 - val_loss: 0.6584 - val_accuracy: 0.7153\n",
            "Epoch 3/100\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.6598 - accuracy: 0.6800 - val_loss: 0.6457 - val_accuracy: 0.7153\n",
            "Epoch 4/100\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.6511 - accuracy: 0.6800 - val_loss: 0.6358 - val_accuracy: 0.7153\n",
            "Epoch 5/100\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.6444 - accuracy: 0.6800 - val_loss: 0.6279 - val_accuracy: 0.7153\n",
            "Epoch 6/100\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.6393 - accuracy: 0.6800 - val_loss: 0.6214 - val_accuracy: 0.7153\n",
            "Epoch 7/100\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.6356 - accuracy: 0.6800 - val_loss: 0.6164 - val_accuracy: 0.7153\n",
            "Epoch 8/100\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.6330 - accuracy: 0.6800 - val_loss: 0.6128 - val_accuracy: 0.7153\n",
            "Epoch 9/100\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.6311 - accuracy: 0.6800 - val_loss: 0.6098 - val_accuracy: 0.7153\n",
            "Epoch 10/100\n",
            "105/105 [==============================] - 0s 1ms/step - loss: 0.6297 - accuracy: 0.6800 - val_loss: 0.6077 - val_accuracy: 0.7153\n",
            "Epoch 11/100\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.6288 - accuracy: 0.6800 - val_loss: 0.6060 - val_accuracy: 0.7153\n",
            "Epoch 12/100\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.6281 - accuracy: 0.6800 - val_loss: 0.6046 - val_accuracy: 0.7153\n",
            "Epoch 13/100\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.6277 - accuracy: 0.6800 - val_loss: 0.6036 - val_accuracy: 0.7153\n",
            "Epoch 14/100\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.6274 - accuracy: 0.6800 - val_loss: 0.6031 - val_accuracy: 0.7153\n",
            "Epoch 15/100\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.6272 - accuracy: 0.6800 - val_loss: 0.6023 - val_accuracy: 0.7153\n",
            "Epoch 16/100\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.6271 - accuracy: 0.6800 - val_loss: 0.6019 - val_accuracy: 0.7153\n",
            "Epoch 17/100\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.6270 - accuracy: 0.6800 - val_loss: 0.6014 - val_accuracy: 0.7153\n",
            "Epoch 18/100\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.6269 - accuracy: 0.6800 - val_loss: 0.6012 - val_accuracy: 0.7153\n",
            "Epoch 19/100\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.6269 - accuracy: 0.6800 - val_loss: 0.6009 - val_accuracy: 0.7153\n",
            "Epoch 20/100\n",
            "105/105 [==============================] - 0s 1ms/step - loss: 0.6269 - accuracy: 0.6800 - val_loss: 0.6007 - val_accuracy: 0.7153\n",
            "Epoch 21/100\n",
            "105/105 [==============================] - 0s 1ms/step - loss: 0.6269 - accuracy: 0.6800 - val_loss: 0.6006 - val_accuracy: 0.7153\n",
            "Epoch 22/100\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.6269 - accuracy: 0.6800 - val_loss: 0.6005 - val_accuracy: 0.7153\n",
            "Epoch 23/100\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.6269 - accuracy: 0.6800 - val_loss: 0.6004 - val_accuracy: 0.7153\n",
            "Epoch 24/100\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.6269 - accuracy: 0.6800 - val_loss: 0.6004 - val_accuracy: 0.7153\n",
            "Epoch 25/100\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.6269 - accuracy: 0.6800 - val_loss: 0.6004 - val_accuracy: 0.7153\n",
            "Epoch 26/100\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.6269 - accuracy: 0.6800 - val_loss: 0.6003 - val_accuracy: 0.7153\n",
            "Epoch 27/100\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.6269 - accuracy: 0.6800 - val_loss: 0.6004 - val_accuracy: 0.7153\n",
            "Epoch 28/100\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.6269 - accuracy: 0.6800 - val_loss: 0.6003 - val_accuracy: 0.7153\n",
            "Epoch 29/100\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.6269 - accuracy: 0.6800 - val_loss: 0.6005 - val_accuracy: 0.7153\n",
            "Epoch 30/100\n",
            "105/105 [==============================] - 0s 1ms/step - loss: 0.6269 - accuracy: 0.6800 - val_loss: 0.6004 - val_accuracy: 0.7153\n",
            "Epoch 31/100\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.6269 - accuracy: 0.6800 - val_loss: 0.6004 - val_accuracy: 0.7153\n",
            "Epoch 32/100\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.6269 - accuracy: 0.6800 - val_loss: 0.6002 - val_accuracy: 0.7153\n",
            "Epoch 33/100\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.6269 - accuracy: 0.6800 - val_loss: 0.6003 - val_accuracy: 0.7153\n",
            "Epoch 34/100\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.6269 - accuracy: 0.6800 - val_loss: 0.6003 - val_accuracy: 0.7153\n",
            "Epoch 35/100\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.6269 - accuracy: 0.6800 - val_loss: 0.6003 - val_accuracy: 0.7153\n",
            "Epoch 36/100\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.6269 - accuracy: 0.6800 - val_loss: 0.6003 - val_accuracy: 0.7153\n",
            "Epoch 37/100\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.6269 - accuracy: 0.6800 - val_loss: 0.6002 - val_accuracy: 0.7153\n",
            "Epoch 38/100\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.6269 - accuracy: 0.6800 - val_loss: 0.6002 - val_accuracy: 0.7153\n",
            "Epoch 39/100\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.6269 - accuracy: 0.6800 - val_loss: 0.6003 - val_accuracy: 0.7153\n",
            "Epoch 40/100\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.6269 - accuracy: 0.6800 - val_loss: 0.6001 - val_accuracy: 0.7153\n",
            "Epoch 41/100\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.6269 - accuracy: 0.6800 - val_loss: 0.6003 - val_accuracy: 0.7153\n",
            "Epoch 42/100\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.6269 - accuracy: 0.6800 - val_loss: 0.6002 - val_accuracy: 0.7153\n",
            "Epoch 43/100\n",
            "105/105 [==============================] - 0s 1ms/step - loss: 0.6269 - accuracy: 0.6800 - val_loss: 0.6002 - val_accuracy: 0.7153\n",
            "Epoch 44/100\n",
            "105/105 [==============================] - 0s 1ms/step - loss: 0.6269 - accuracy: 0.6800 - val_loss: 0.6002 - val_accuracy: 0.7153\n",
            "Epoch 45/100\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.6269 - accuracy: 0.6800 - val_loss: 0.6001 - val_accuracy: 0.7153\n",
            "Epoch 46/100\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.6269 - accuracy: 0.6800 - val_loss: 0.6003 - val_accuracy: 0.7153\n",
            "Epoch 47/100\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.6269 - accuracy: 0.6800 - val_loss: 0.6003 - val_accuracy: 0.7153\n",
            "Epoch 48/100\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.6269 - accuracy: 0.6800 - val_loss: 0.6002 - val_accuracy: 0.7153\n",
            "Epoch 49/100\n",
            "105/105 [==============================] - 0s 1ms/step - loss: 0.6269 - accuracy: 0.6800 - val_loss: 0.6002 - val_accuracy: 0.7153\n",
            "Epoch 50/100\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.6269 - accuracy: 0.6800 - val_loss: 0.6002 - val_accuracy: 0.7153\n",
            "Epoch 51/100\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.6269 - accuracy: 0.6800 - val_loss: 0.6003 - val_accuracy: 0.7153\n",
            "Epoch 52/100\n",
            "105/105 [==============================] - 0s 1ms/step - loss: 0.6269 - accuracy: 0.6800 - val_loss: 0.6002 - val_accuracy: 0.7153\n",
            "Epoch 53/100\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.6269 - accuracy: 0.6800 - val_loss: 0.6003 - val_accuracy: 0.7153\n",
            "Epoch 54/100\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.6269 - accuracy: 0.6800 - val_loss: 0.6001 - val_accuracy: 0.7153\n",
            "Epoch 55/100\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.6269 - accuracy: 0.6800 - val_loss: 0.6002 - val_accuracy: 0.7153\n",
            "Epoch 56/100\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.6269 - accuracy: 0.6800 - val_loss: 0.6002 - val_accuracy: 0.7153\n",
            "Epoch 57/100\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.6269 - accuracy: 0.6800 - val_loss: 0.6001 - val_accuracy: 0.7153\n",
            "Epoch 58/100\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.6269 - accuracy: 0.6800 - val_loss: 0.6003 - val_accuracy: 0.7153\n",
            "Epoch 59/100\n",
            "105/105 [==============================] - 0s 1ms/step - loss: 0.6269 - accuracy: 0.6800 - val_loss: 0.6002 - val_accuracy: 0.7153\n",
            "Epoch 60/100\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.6269 - accuracy: 0.6800 - val_loss: 0.6003 - val_accuracy: 0.7153\n",
            "Epoch 61/100\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.6269 - accuracy: 0.6800 - val_loss: 0.6003 - val_accuracy: 0.7153\n",
            "Epoch 62/100\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.6269 - accuracy: 0.6800 - val_loss: 0.6002 - val_accuracy: 0.7153\n",
            "Epoch 63/100\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.6269 - accuracy: 0.6800 - val_loss: 0.6003 - val_accuracy: 0.7153\n",
            "Epoch 64/100\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.6269 - accuracy: 0.6800 - val_loss: 0.6004 - val_accuracy: 0.7153\n",
            "Epoch 65/100\n",
            "105/105 [==============================] - 0s 1ms/step - loss: 0.6269 - accuracy: 0.6800 - val_loss: 0.6002 - val_accuracy: 0.7153\n",
            "Epoch 66/100\n",
            "105/105 [==============================] - 0s 1ms/step - loss: 0.6269 - accuracy: 0.6800 - val_loss: 0.6001 - val_accuracy: 0.7153\n",
            "Epoch 67/100\n",
            "105/105 [==============================] - 0s 1ms/step - loss: 0.6269 - accuracy: 0.6800 - val_loss: 0.6003 - val_accuracy: 0.7153\n",
            "Epoch 68/100\n",
            "105/105 [==============================] - 0s 1ms/step - loss: 0.6269 - accuracy: 0.6800 - val_loss: 0.6003 - val_accuracy: 0.7153\n",
            "Epoch 69/100\n",
            "105/105 [==============================] - 0s 1ms/step - loss: 0.6269 - accuracy: 0.6800 - val_loss: 0.6002 - val_accuracy: 0.7153\n",
            "Epoch 70/100\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.6269 - accuracy: 0.6800 - val_loss: 0.6002 - val_accuracy: 0.7153\n",
            "Epoch 71/100\n",
            "105/105 [==============================] - 0s 1ms/step - loss: 0.6269 - accuracy: 0.6800 - val_loss: 0.6002 - val_accuracy: 0.7153\n",
            "Epoch 72/100\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.6269 - accuracy: 0.6800 - val_loss: 0.6003 - val_accuracy: 0.7153\n",
            "Epoch 73/100\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.6269 - accuracy: 0.6800 - val_loss: 0.6003 - val_accuracy: 0.7153\n",
            "Epoch 74/100\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.6269 - accuracy: 0.6800 - val_loss: 0.6003 - val_accuracy: 0.7153\n",
            "Epoch 75/100\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.6269 - accuracy: 0.6800 - val_loss: 0.6002 - val_accuracy: 0.7153\n",
            "Epoch 76/100\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.6269 - accuracy: 0.6800 - val_loss: 0.6003 - val_accuracy: 0.7153\n",
            "Epoch 77/100\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.6269 - accuracy: 0.6800 - val_loss: 0.6004 - val_accuracy: 0.7153\n",
            "Epoch 78/100\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.6269 - accuracy: 0.6800 - val_loss: 0.6003 - val_accuracy: 0.7153\n",
            "Epoch 79/100\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.6269 - accuracy: 0.6800 - val_loss: 0.6002 - val_accuracy: 0.7153\n",
            "Epoch 80/100\n",
            "105/105 [==============================] - 0s 1ms/step - loss: 0.6269 - accuracy: 0.6800 - val_loss: 0.6003 - val_accuracy: 0.7153\n",
            "Epoch 81/100\n",
            "105/105 [==============================] - 0s 1ms/step - loss: 0.6269 - accuracy: 0.6800 - val_loss: 0.6002 - val_accuracy: 0.7153\n",
            "Epoch 82/100\n",
            "105/105 [==============================] - 0s 1ms/step - loss: 0.6269 - accuracy: 0.6800 - val_loss: 0.6003 - val_accuracy: 0.7153\n",
            "Epoch 83/100\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.6269 - accuracy: 0.6800 - val_loss: 0.6002 - val_accuracy: 0.7153\n",
            "Epoch 84/100\n",
            "105/105 [==============================] - 0s 1ms/step - loss: 0.6269 - accuracy: 0.6800 - val_loss: 0.6003 - val_accuracy: 0.7153\n",
            "Epoch 85/100\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.6269 - accuracy: 0.6800 - val_loss: 0.6002 - val_accuracy: 0.7153\n",
            "Epoch 86/100\n",
            "105/105 [==============================] - 0s 1ms/step - loss: 0.6269 - accuracy: 0.6800 - val_loss: 0.6003 - val_accuracy: 0.7153\n",
            "Epoch 87/100\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.6269 - accuracy: 0.6800 - val_loss: 0.6003 - val_accuracy: 0.7153\n",
            "Epoch 88/100\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.6269 - accuracy: 0.6800 - val_loss: 0.6003 - val_accuracy: 0.7153\n",
            "Epoch 89/100\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.6269 - accuracy: 0.6800 - val_loss: 0.6003 - val_accuracy: 0.7153\n",
            "Epoch 90/100\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.6269 - accuracy: 0.6800 - val_loss: 0.6003 - val_accuracy: 0.7153\n",
            "Epoch 91/100\n",
            "105/105 [==============================] - 0s 1ms/step - loss: 0.6269 - accuracy: 0.6800 - val_loss: 0.6002 - val_accuracy: 0.7153\n",
            "Epoch 92/100\n",
            "105/105 [==============================] - 0s 1ms/step - loss: 0.6269 - accuracy: 0.6800 - val_loss: 0.6003 - val_accuracy: 0.7153\n",
            "Epoch 93/100\n",
            "105/105 [==============================] - 0s 1ms/step - loss: 0.6269 - accuracy: 0.6800 - val_loss: 0.6003 - val_accuracy: 0.7153\n",
            "Epoch 94/100\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.6269 - accuracy: 0.6800 - val_loss: 0.6003 - val_accuracy: 0.7153\n",
            "Epoch 95/100\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.6269 - accuracy: 0.6800 - val_loss: 0.6003 - val_accuracy: 0.7153\n",
            "Epoch 96/100\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.6269 - accuracy: 0.6800 - val_loss: 0.6002 - val_accuracy: 0.7153\n",
            "Epoch 97/100\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.6269 - accuracy: 0.6800 - val_loss: 0.6003 - val_accuracy: 0.7153\n",
            "Epoch 98/100\n",
            "105/105 [==============================] - 0s 1ms/step - loss: 0.6269 - accuracy: 0.6800 - val_loss: 0.6002 - val_accuracy: 0.7153\n",
            "Epoch 99/100\n",
            "105/105 [==============================] - 0s 1ms/step - loss: 0.6269 - accuracy: 0.6800 - val_loss: 0.6003 - val_accuracy: 0.7153\n",
            "Epoch 100/100\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.6269 - accuracy: 0.6800 - val_loss: 0.6002 - val_accuracy: 0.7153\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.get_weights()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b9ibsapQrpAA",
        "outputId": "75447f18-a15f-495e-9174-d8c58f91460f"
      },
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[array([[0., 0.],\n",
              "        [0., 0.],\n",
              "        [0., 0.],\n",
              "        [0., 0.],\n",
              "        [0., 0.],\n",
              "        [0., 0.],\n",
              "        [0., 0.],\n",
              "        [0., 0.]], dtype=float32),\n",
              " array([0., 0.], dtype=float32),\n",
              " array([[-0.6596491],\n",
              "        [-0.2786696]], dtype=float32),\n",
              " array([0.7549186], dtype=float32)]"
            ]
          },
          "metadata": {},
          "execution_count": 66
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#2. Random Initialization\n",
        "\n",
        "###In an attempt to overcome the shortcomings of Zero or Constant Initialization, random initialization assigns random values except for zeros as weights to neuron paths. However, assigning values randomly to the weights, problems such as **Overfitting, Vanishing Gradient Problem, Exploding Gradient Problem might occur.**\n",
        "\n",
        "\n",
        "##Reasons for Overfitting:\n",
        " High variance and low bias.\n",
        "\n",
        "The model is too complex.\n",
        "\n",
        "The size of the training data.\n",
        "\n",
        "##Techniques to Reduce Overfitting\n",
        "\n",
        "Increase training data.\n",
        "\n",
        "Reduce model complexity.\n",
        "\n",
        "Early stopping during the training phase (have an eye over the loss over the training period as soon as loss begins to increase stop training).\n",
        "\n",
        "Ridge Regularization and Lasso Regularization.\n",
        "\n",
        "Use dropout for neural networks to tackle overfitting.\n",
        "\n",
        "---------------------------------------------------------------------\n",
        "#Reasons for Underfitting\n",
        "The model is too simple, So it may be not capable to represent the complexities in the data.\n",
        "\n",
        "The input features which is used to train the model is not the adequate representations of underlying factors influencing the target variable.\n",
        "\n",
        "The size of the training dataset used is not enough.\n",
        "\n",
        "Excessive regularization are used to prevent the overfitting, which constraint the model to capture the data well.\n",
        "\n",
        "Features are not scaled.\n",
        "\n",
        "##Techniques to Reduce Underfitting\n",
        "\n",
        "Increase model complexity.\n",
        "\n",
        "Increase the number of features, performing feature engineering.\n",
        "\n",
        "Remove noise from the data.\n",
        "\n",
        "Increase the number of epochs or increase the duration of training to get better results."
      ],
      "metadata": {
        "id": "fUFkW0aoyOZe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Random Normal Distribution\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras import initializers\n",
        "\n",
        "initializer = tf.keras.initializers.RandomNormal(\n",
        "  mean=0., stddev=1.)"
      ],
      "metadata": {
        "id": "MvR-A5hPrpCJ"
      },
      "execution_count": 67,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = Sequential()\n",
        "\n",
        "model.add(Dense(2,activation='relu',input_dim=8,kernel_initializer=initializer))\n",
        "model.add(Dense(1,activation='sigmoid'))\n",
        "\n",
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FJZSqivArpEa",
        "outputId": "bf3d8132-dd8c-4d56-851e-bfe7d9ecf76f"
      },
      "execution_count": 69,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_9\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_18 (Dense)            (None, 2)                 18        \n",
            "                                                                 \n",
            " dense_19 (Dense)            (None, 1)                 3         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 21 (84.00 Byte)\n",
            "Trainable params: 21 (84.00 Byte)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/initializers/initializers.py:120: UserWarning: The initializer RandomNormal is unseeded and being called multiple times, which will return identical values each time (even if the initializer is unseeded). Please update your code to provide a seed to the initializer, or avoid using the same initializer instance more than once.\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.get_weights()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HUWLBYJPrpGe",
        "outputId": "248c1939-f407-49a9-84d3-2fefc583fa74"
      },
      "execution_count": 70,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[array([[-1.0443983 , -0.03269392],\n",
              "        [ 0.13848853,  0.5908715 ],\n",
              "        [-1.7974945 , -0.13845819],\n",
              "        [-2.2207909 ,  0.6692139 ],\n",
              "        [ 0.02082727, -1.5952283 ],\n",
              "        [-2.0529768 ,  2.4495487 ],\n",
              "        [ 0.86785626,  0.6200869 ],\n",
              "        [ 0.63991106,  1.0252864 ]], dtype=float32),\n",
              " array([0., 0.], dtype=float32),\n",
              " array([[-0.8059155 ],\n",
              "        [ 0.30850613]], dtype=float32),\n",
              " array([0.], dtype=float32)]"
            ]
          },
          "metadata": {},
          "execution_count": 70
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(loss='binary_crossentropy',optimizer='adam',metrics=['accuracy'])\n",
        "history = model.fit(X,y,epochs=100,validation_split=0.2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JBaipjUQrpIU",
        "outputId": "4664d7f3-e88b-4ecc-9341-6bd1fd9b44b5"
      },
      "execution_count": 71,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "105/105 [==============================] - 1s 3ms/step - loss: 0.8153 - accuracy: 0.5124 - val_loss: 0.7954 - val_accuracy: 0.5789\n",
            "Epoch 2/100\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.7835 - accuracy: 0.5403 - val_loss: 0.7638 - val_accuracy: 0.5909\n",
            "Epoch 3/100\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.7561 - accuracy: 0.5699 - val_loss: 0.7368 - val_accuracy: 0.6244\n",
            "Epoch 4/100\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.7338 - accuracy: 0.6121 - val_loss: 0.7142 - val_accuracy: 0.6806\n",
            "Epoch 5/100\n",
            "105/105 [==============================] - 0s 1ms/step - loss: 0.7160 - accuracy: 0.6450 - val_loss: 0.6967 - val_accuracy: 0.6938\n",
            "Epoch 6/100\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.7007 - accuracy: 0.6612 - val_loss: 0.6832 - val_accuracy: 0.6926\n",
            "Epoch 7/100\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.6885 - accuracy: 0.6702 - val_loss: 0.6697 - val_accuracy: 0.7069\n",
            "Epoch 8/100\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.6785 - accuracy: 0.6729 - val_loss: 0.6609 - val_accuracy: 0.7081\n",
            "Epoch 9/100\n",
            "105/105 [==============================] - 0s 1ms/step - loss: 0.6692 - accuracy: 0.6755 - val_loss: 0.6507 - val_accuracy: 0.7093\n",
            "Epoch 10/100\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.6615 - accuracy: 0.6788 - val_loss: 0.6416 - val_accuracy: 0.7165\n",
            "Epoch 11/100\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.6547 - accuracy: 0.6806 - val_loss: 0.6345 - val_accuracy: 0.7153\n",
            "Epoch 12/100\n",
            "105/105 [==============================] - 0s 1ms/step - loss: 0.6486 - accuracy: 0.6803 - val_loss: 0.6298 - val_accuracy: 0.7165\n",
            "Epoch 13/100\n",
            "105/105 [==============================] - 0s 1ms/step - loss: 0.6438 - accuracy: 0.6800 - val_loss: 0.6234 - val_accuracy: 0.7153\n",
            "Epoch 14/100\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.6379 - accuracy: 0.6812 - val_loss: 0.6162 - val_accuracy: 0.7153\n",
            "Epoch 15/100\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.6340 - accuracy: 0.6794 - val_loss: 0.6173 - val_accuracy: 0.7117\n",
            "Epoch 16/100\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.6295 - accuracy: 0.6803 - val_loss: 0.6100 - val_accuracy: 0.7141\n",
            "Epoch 17/100\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.6257 - accuracy: 0.6800 - val_loss: 0.6047 - val_accuracy: 0.7153\n",
            "Epoch 18/100\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.6225 - accuracy: 0.6797 - val_loss: 0.5995 - val_accuracy: 0.7153\n",
            "Epoch 19/100\n",
            "105/105 [==============================] - 0s 1ms/step - loss: 0.6184 - accuracy: 0.6803 - val_loss: 0.5949 - val_accuracy: 0.7153\n",
            "Epoch 20/100\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.6163 - accuracy: 0.6800 - val_loss: 0.5930 - val_accuracy: 0.7153\n",
            "Epoch 21/100\n",
            "105/105 [==============================] - 0s 1ms/step - loss: 0.6129 - accuracy: 0.6791 - val_loss: 0.5923 - val_accuracy: 0.7141\n",
            "Epoch 22/100\n",
            "105/105 [==============================] - 0s 1ms/step - loss: 0.6097 - accuracy: 0.6797 - val_loss: 0.5843 - val_accuracy: 0.7153\n",
            "Epoch 23/100\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.6069 - accuracy: 0.6800 - val_loss: 0.5813 - val_accuracy: 0.7153\n",
            "Epoch 24/100\n",
            "105/105 [==============================] - 0s 1ms/step - loss: 0.6052 - accuracy: 0.6782 - val_loss: 0.5810 - val_accuracy: 0.7141\n",
            "Epoch 25/100\n",
            "105/105 [==============================] - 0s 1ms/step - loss: 0.6031 - accuracy: 0.6791 - val_loss: 0.5791 - val_accuracy: 0.7141\n",
            "Epoch 26/100\n",
            "105/105 [==============================] - 0s 1ms/step - loss: 0.6003 - accuracy: 0.6782 - val_loss: 0.5775 - val_accuracy: 0.7105\n",
            "Epoch 27/100\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.5985 - accuracy: 0.6794 - val_loss: 0.5741 - val_accuracy: 0.7105\n",
            "Epoch 28/100\n",
            "105/105 [==============================] - 0s 1ms/step - loss: 0.5967 - accuracy: 0.6749 - val_loss: 0.5727 - val_accuracy: 0.7057\n",
            "Epoch 29/100\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.5952 - accuracy: 0.6788 - val_loss: 0.5710 - val_accuracy: 0.7069\n",
            "Epoch 30/100\n",
            "105/105 [==============================] - 0s 1ms/step - loss: 0.5939 - accuracy: 0.6761 - val_loss: 0.5656 - val_accuracy: 0.7105\n",
            "Epoch 31/100\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.5921 - accuracy: 0.6785 - val_loss: 0.5711 - val_accuracy: 0.7117\n",
            "Epoch 32/100\n",
            "105/105 [==============================] - 0s 1ms/step - loss: 0.5908 - accuracy: 0.6761 - val_loss: 0.5614 - val_accuracy: 0.7093\n",
            "Epoch 33/100\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.5900 - accuracy: 0.6749 - val_loss: 0.5677 - val_accuracy: 0.7141\n",
            "Epoch 34/100\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.5894 - accuracy: 0.6740 - val_loss: 0.5647 - val_accuracy: 0.7129\n",
            "Epoch 35/100\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.5886 - accuracy: 0.6776 - val_loss: 0.5626 - val_accuracy: 0.7117\n",
            "Epoch 36/100\n",
            "105/105 [==============================] - 0s 1ms/step - loss: 0.5877 - accuracy: 0.6720 - val_loss: 0.5630 - val_accuracy: 0.7129\n",
            "Epoch 37/100\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.5874 - accuracy: 0.6732 - val_loss: 0.5576 - val_accuracy: 0.7069\n",
            "Epoch 38/100\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.5866 - accuracy: 0.6735 - val_loss: 0.5584 - val_accuracy: 0.7129\n",
            "Epoch 39/100\n",
            "105/105 [==============================] - 0s 1ms/step - loss: 0.5858 - accuracy: 0.6735 - val_loss: 0.5569 - val_accuracy: 0.7141\n",
            "Epoch 40/100\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.5858 - accuracy: 0.6717 - val_loss: 0.5597 - val_accuracy: 0.7129\n",
            "Epoch 41/100\n",
            "105/105 [==============================] - 0s 1ms/step - loss: 0.5848 - accuracy: 0.6785 - val_loss: 0.5530 - val_accuracy: 0.7069\n",
            "Epoch 42/100\n",
            "105/105 [==============================] - 0s 1ms/step - loss: 0.5845 - accuracy: 0.6767 - val_loss: 0.5547 - val_accuracy: 0.7093\n",
            "Epoch 43/100\n",
            "105/105 [==============================] - 0s 1ms/step - loss: 0.5849 - accuracy: 0.6738 - val_loss: 0.5522 - val_accuracy: 0.7093\n",
            "Epoch 44/100\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.5837 - accuracy: 0.6764 - val_loss: 0.5569 - val_accuracy: 0.7033\n",
            "Epoch 45/100\n",
            "105/105 [==============================] - 0s 1ms/step - loss: 0.5845 - accuracy: 0.6740 - val_loss: 0.5511 - val_accuracy: 0.7117\n",
            "Epoch 46/100\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.5832 - accuracy: 0.6788 - val_loss: 0.5582 - val_accuracy: 0.6986\n",
            "Epoch 47/100\n",
            "105/105 [==============================] - 0s 1ms/step - loss: 0.5837 - accuracy: 0.6749 - val_loss: 0.5516 - val_accuracy: 0.7105\n",
            "Epoch 48/100\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.5832 - accuracy: 0.6779 - val_loss: 0.5561 - val_accuracy: 0.6998\n",
            "Epoch 49/100\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.5828 - accuracy: 0.6743 - val_loss: 0.5516 - val_accuracy: 0.7141\n",
            "Epoch 50/100\n",
            "105/105 [==============================] - 0s 1ms/step - loss: 0.5823 - accuracy: 0.6773 - val_loss: 0.5481 - val_accuracy: 0.7105\n",
            "Epoch 51/100\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.5828 - accuracy: 0.6776 - val_loss: 0.5499 - val_accuracy: 0.7093\n",
            "Epoch 52/100\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.5820 - accuracy: 0.6767 - val_loss: 0.5492 - val_accuracy: 0.7093\n",
            "Epoch 53/100\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.5817 - accuracy: 0.6791 - val_loss: 0.5510 - val_accuracy: 0.7105\n",
            "Epoch 54/100\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.5815 - accuracy: 0.6764 - val_loss: 0.5530 - val_accuracy: 0.7010\n",
            "Epoch 55/100\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.5823 - accuracy: 0.6729 - val_loss: 0.5508 - val_accuracy: 0.7069\n",
            "Epoch 56/100\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.5814 - accuracy: 0.6752 - val_loss: 0.5466 - val_accuracy: 0.7117\n",
            "Epoch 57/100\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.5814 - accuracy: 0.6779 - val_loss: 0.5499 - val_accuracy: 0.7069\n",
            "Epoch 58/100\n",
            "105/105 [==============================] - 0s 1ms/step - loss: 0.5816 - accuracy: 0.6726 - val_loss: 0.5473 - val_accuracy: 0.7069\n",
            "Epoch 59/100\n",
            "105/105 [==============================] - 0s 1ms/step - loss: 0.5814 - accuracy: 0.6729 - val_loss: 0.5468 - val_accuracy: 0.7069\n",
            "Epoch 60/100\n",
            "105/105 [==============================] - 0s 1ms/step - loss: 0.5810 - accuracy: 0.6735 - val_loss: 0.5476 - val_accuracy: 0.7141\n",
            "Epoch 61/100\n",
            "105/105 [==============================] - 0s 1ms/step - loss: 0.5813 - accuracy: 0.6755 - val_loss: 0.5479 - val_accuracy: 0.7129\n",
            "Epoch 62/100\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.5808 - accuracy: 0.6770 - val_loss: 0.5485 - val_accuracy: 0.7069\n",
            "Epoch 63/100\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.5805 - accuracy: 0.6738 - val_loss: 0.5505 - val_accuracy: 0.6986\n",
            "Epoch 64/100\n",
            "105/105 [==============================] - 0s 1ms/step - loss: 0.5807 - accuracy: 0.6740 - val_loss: 0.5459 - val_accuracy: 0.7057\n",
            "Epoch 65/100\n",
            "105/105 [==============================] - 0s 1ms/step - loss: 0.5812 - accuracy: 0.6740 - val_loss: 0.5482 - val_accuracy: 0.7081\n",
            "Epoch 66/100\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.5806 - accuracy: 0.6717 - val_loss: 0.5498 - val_accuracy: 0.6998\n",
            "Epoch 67/100\n",
            "105/105 [==============================] - 0s 1ms/step - loss: 0.5807 - accuracy: 0.6723 - val_loss: 0.5482 - val_accuracy: 0.7069\n",
            "Epoch 68/100\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.5808 - accuracy: 0.6729 - val_loss: 0.5494 - val_accuracy: 0.6998\n",
            "Epoch 69/100\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.5811 - accuracy: 0.6726 - val_loss: 0.5478 - val_accuracy: 0.7069\n",
            "Epoch 70/100\n",
            "105/105 [==============================] - 0s 1ms/step - loss: 0.5807 - accuracy: 0.6717 - val_loss: 0.5468 - val_accuracy: 0.7081\n",
            "Epoch 71/100\n",
            "105/105 [==============================] - 0s 1ms/step - loss: 0.5804 - accuracy: 0.6776 - val_loss: 0.5455 - val_accuracy: 0.7117\n",
            "Epoch 72/100\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.5804 - accuracy: 0.6761 - val_loss: 0.5453 - val_accuracy: 0.7105\n",
            "Epoch 73/100\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.5807 - accuracy: 0.6738 - val_loss: 0.5451 - val_accuracy: 0.7117\n",
            "Epoch 74/100\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.5802 - accuracy: 0.6726 - val_loss: 0.5461 - val_accuracy: 0.7093\n",
            "Epoch 75/100\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.5800 - accuracy: 0.6746 - val_loss: 0.5454 - val_accuracy: 0.7141\n",
            "Epoch 76/100\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.5797 - accuracy: 0.6743 - val_loss: 0.5443 - val_accuracy: 0.7105\n",
            "Epoch 77/100\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.5805 - accuracy: 0.6732 - val_loss: 0.5449 - val_accuracy: 0.7105\n",
            "Epoch 78/100\n",
            "105/105 [==============================] - 0s 1ms/step - loss: 0.5799 - accuracy: 0.6740 - val_loss: 0.5482 - val_accuracy: 0.7010\n",
            "Epoch 79/100\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.5799 - accuracy: 0.6743 - val_loss: 0.5465 - val_accuracy: 0.7069\n",
            "Epoch 80/100\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.5805 - accuracy: 0.6738 - val_loss: 0.5453 - val_accuracy: 0.7093\n",
            "Epoch 81/100\n",
            "105/105 [==============================] - 0s 1ms/step - loss: 0.5802 - accuracy: 0.6732 - val_loss: 0.5452 - val_accuracy: 0.7105\n",
            "Epoch 82/100\n",
            "105/105 [==============================] - 0s 1ms/step - loss: 0.5802 - accuracy: 0.6735 - val_loss: 0.5438 - val_accuracy: 0.7105\n",
            "Epoch 83/100\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.5807 - accuracy: 0.6726 - val_loss: 0.5446 - val_accuracy: 0.7093\n",
            "Epoch 84/100\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.5802 - accuracy: 0.6767 - val_loss: 0.5467 - val_accuracy: 0.7033\n",
            "Epoch 85/100\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.5795 - accuracy: 0.6735 - val_loss: 0.5440 - val_accuracy: 0.7093\n",
            "Epoch 86/100\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.5806 - accuracy: 0.6732 - val_loss: 0.5452 - val_accuracy: 0.7069\n",
            "Epoch 87/100\n",
            "105/105 [==============================] - 0s 1ms/step - loss: 0.5798 - accuracy: 0.6729 - val_loss: 0.5466 - val_accuracy: 0.7045\n",
            "Epoch 88/100\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.5795 - accuracy: 0.6735 - val_loss: 0.5453 - val_accuracy: 0.7057\n",
            "Epoch 89/100\n",
            "105/105 [==============================] - 0s 1ms/step - loss: 0.5796 - accuracy: 0.6735 - val_loss: 0.5443 - val_accuracy: 0.7093\n",
            "Epoch 90/100\n",
            "105/105 [==============================] - 0s 1ms/step - loss: 0.5791 - accuracy: 0.6776 - val_loss: 0.5429 - val_accuracy: 0.7129\n",
            "Epoch 91/100\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.5795 - accuracy: 0.6732 - val_loss: 0.5440 - val_accuracy: 0.7093\n",
            "Epoch 92/100\n",
            "105/105 [==============================] - 0s 1ms/step - loss: 0.5793 - accuracy: 0.6743 - val_loss: 0.5451 - val_accuracy: 0.7069\n",
            "Epoch 93/100\n",
            "105/105 [==============================] - 0s 1ms/step - loss: 0.5795 - accuracy: 0.6785 - val_loss: 0.5430 - val_accuracy: 0.7117\n",
            "Epoch 94/100\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.5798 - accuracy: 0.6761 - val_loss: 0.5461 - val_accuracy: 0.7045\n",
            "Epoch 95/100\n",
            "105/105 [==============================] - 0s 1ms/step - loss: 0.5795 - accuracy: 0.6738 - val_loss: 0.5447 - val_accuracy: 0.7069\n",
            "Epoch 96/100\n",
            "105/105 [==============================] - 0s 1ms/step - loss: 0.5793 - accuracy: 0.6752 - val_loss: 0.5447 - val_accuracy: 0.7069\n",
            "Epoch 97/100\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.5777 - accuracy: 0.6782 - val_loss: 0.5427 - val_accuracy: 0.7129\n",
            "Epoch 98/100\n",
            "105/105 [==============================] - 0s 1ms/step - loss: 0.5793 - accuracy: 0.6767 - val_loss: 0.5435 - val_accuracy: 0.7117\n",
            "Epoch 99/100\n",
            "105/105 [==============================] - 0s 1ms/step - loss: 0.5790 - accuracy: 0.6764 - val_loss: 0.5441 - val_accuracy: 0.7081\n",
            "Epoch 100/100\n",
            "105/105 [==============================] - 0s 1ms/step - loss: 0.5791 - accuracy: 0.6743 - val_loss: 0.5457 - val_accuracy: 0.7045\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.get_weights()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AMVa0JrQYAPX",
        "outputId": "6d461d0f-5c01-497d-839f-4526825d991d"
      },
      "execution_count": 72,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[array([[-0.65506727, -0.47211307],\n",
              "        [ 0.6805475 , -0.01091834],\n",
              "        [-0.8684172 , -1.147423  ],\n",
              "        [-0.76930636, -0.9565217 ],\n",
              "        [ 0.9820397 , -2.712676  ],\n",
              "        [-0.04991752,  0.2562094 ],\n",
              "        [ 2.3113017 , -0.9935366 ],\n",
              "        [ 0.7461884 ,  0.8824253 ]], dtype=float32),\n",
              " array([-1.2946227,  1.3850225], dtype=float32),\n",
              " array([[-0.53812534],\n",
              "        [ 0.35094893]], dtype=float32),\n",
              " array([1.3835901], dtype=float32)]"
            ]
          },
          "metadata": {},
          "execution_count": 72
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#b) Random Uniform:"
      ],
      "metadata": {
        "id": "ixqqo1BQjKZT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Random Uniform Initialization\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras import initializers\n",
        "\n",
        "initializer = tf.keras.initializers.RandomUniform()\n",
        "model = Sequential()\n",
        "\n",
        "model.add(Dense(2,activation='relu',input_dim=8,kernel_initializer=initializer))\n",
        "model.add(Dense(1,activation='sigmoid'))\n",
        "\n",
        "print(model.summary())\n",
        "print(model.get_weights())\n",
        "\n",
        "model.compile(loss='binary_crossentropy',optimizer='adam',metrics=['accuracy'])\n",
        "history = model.fit(X,y,epochs=100,validation_split=0.2)\n",
        "print(model.get_weights())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lGK6FMgPYAgO",
        "outputId": "1fe6cdb6-ee74-40b3-db9c-d7a9215e069c"
      },
      "execution_count": 77,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_13\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_26 (Dense)            (None, 2)                 18        \n",
            "                                                                 \n",
            " dense_27 (Dense)            (None, 1)                 3         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 21 (84.00 Byte)\n",
            "Trainable params: 21 (84.00 Byte)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n",
            "None\n",
            "[array([[-0.02155724,  0.0285247 ],\n",
            "       [-0.00264717,  0.0441986 ],\n",
            "       [ 0.00694698, -0.03464597],\n",
            "       [ 0.0451389 , -0.01085757],\n",
            "       [ 0.02194549,  0.01449269],\n",
            "       [ 0.01315637,  0.03543757],\n",
            "       [-0.02768041, -0.00815946],\n",
            "       [-0.04308265,  0.00274141]], dtype=float32), array([0., 0.], dtype=float32), array([[ 0.5039134 ],\n",
            "       [-0.49225122]], dtype=float32), array([0.], dtype=float32)]\n",
            "Epoch 1/100\n",
            "105/105 [==============================] - 1s 3ms/step - loss: 0.6853 - accuracy: 0.6657 - val_loss: 0.6745 - val_accuracy: 0.7153\n",
            "Epoch 2/100\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.6714 - accuracy: 0.6800 - val_loss: 0.6592 - val_accuracy: 0.7153\n",
            "Epoch 3/100\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.6604 - accuracy: 0.6800 - val_loss: 0.6466 - val_accuracy: 0.7153\n",
            "Epoch 4/100\n",
            "105/105 [==============================] - 0s 1ms/step - loss: 0.6516 - accuracy: 0.6800 - val_loss: 0.6364 - val_accuracy: 0.7153\n",
            "Epoch 5/100\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.6450 - accuracy: 0.6800 - val_loss: 0.6285 - val_accuracy: 0.7153\n",
            "Epoch 6/100\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.6399 - accuracy: 0.6800 - val_loss: 0.6222 - val_accuracy: 0.7153\n",
            "Epoch 7/100\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.6361 - accuracy: 0.6800 - val_loss: 0.6171 - val_accuracy: 0.7153\n",
            "Epoch 8/100\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.6334 - accuracy: 0.6800 - val_loss: 0.6134 - val_accuracy: 0.7153\n",
            "Epoch 9/100\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.6314 - accuracy: 0.6800 - val_loss: 0.6103 - val_accuracy: 0.7153\n",
            "Epoch 10/100\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.6300 - accuracy: 0.6800 - val_loss: 0.6081 - val_accuracy: 0.7153\n",
            "Epoch 11/100\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.6290 - accuracy: 0.6800 - val_loss: 0.6064 - val_accuracy: 0.7153\n",
            "Epoch 12/100\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.6282 - accuracy: 0.6800 - val_loss: 0.6049 - val_accuracy: 0.7153\n",
            "Epoch 13/100\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.6277 - accuracy: 0.6800 - val_loss: 0.6038 - val_accuracy: 0.7153\n",
            "Epoch 14/100\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.6274 - accuracy: 0.6800 - val_loss: 0.6030 - val_accuracy: 0.7153\n",
            "Epoch 15/100\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.6272 - accuracy: 0.6800 - val_loss: 0.6024 - val_accuracy: 0.7153\n",
            "Epoch 16/100\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.6271 - accuracy: 0.6800 - val_loss: 0.6018 - val_accuracy: 0.7153\n",
            "Epoch 17/100\n",
            "105/105 [==============================] - 0s 1ms/step - loss: 0.6270 - accuracy: 0.6800 - val_loss: 0.6013 - val_accuracy: 0.7153\n",
            "Epoch 18/100\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.6270 - accuracy: 0.6800 - val_loss: 0.6013 - val_accuracy: 0.7153\n",
            "Epoch 19/100\n",
            "105/105 [==============================] - 0s 1ms/step - loss: 0.6269 - accuracy: 0.6800 - val_loss: 0.6009 - val_accuracy: 0.7153\n",
            "Epoch 20/100\n",
            "105/105 [==============================] - 0s 1ms/step - loss: 0.6269 - accuracy: 0.6800 - val_loss: 0.6007 - val_accuracy: 0.7153\n",
            "Epoch 21/100\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.6269 - accuracy: 0.6800 - val_loss: 0.6006 - val_accuracy: 0.7153\n",
            "Epoch 22/100\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.6269 - accuracy: 0.6800 - val_loss: 0.6004 - val_accuracy: 0.7153\n",
            "Epoch 23/100\n",
            "105/105 [==============================] - 0s 1ms/step - loss: 0.6269 - accuracy: 0.6800 - val_loss: 0.6004 - val_accuracy: 0.7153\n",
            "Epoch 24/100\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.6269 - accuracy: 0.6800 - val_loss: 0.6004 - val_accuracy: 0.7153\n",
            "Epoch 25/100\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.6269 - accuracy: 0.6800 - val_loss: 0.6004 - val_accuracy: 0.7153\n",
            "Epoch 26/100\n",
            "105/105 [==============================] - 0s 1ms/step - loss: 0.6269 - accuracy: 0.6800 - val_loss: 0.6003 - val_accuracy: 0.7153\n",
            "Epoch 27/100\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.6269 - accuracy: 0.6800 - val_loss: 0.6003 - val_accuracy: 0.7153\n",
            "Epoch 28/100\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.6269 - accuracy: 0.6800 - val_loss: 0.6003 - val_accuracy: 0.7153\n",
            "Epoch 29/100\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.6269 - accuracy: 0.6800 - val_loss: 0.6004 - val_accuracy: 0.7153\n",
            "Epoch 30/100\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.6269 - accuracy: 0.6800 - val_loss: 0.6003 - val_accuracy: 0.7153\n",
            "Epoch 31/100\n",
            "105/105 [==============================] - 0s 1ms/step - loss: 0.6269 - accuracy: 0.6800 - val_loss: 0.6003 - val_accuracy: 0.7153\n",
            "Epoch 32/100\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.6269 - accuracy: 0.6800 - val_loss: 0.6002 - val_accuracy: 0.7153\n",
            "Epoch 33/100\n",
            "105/105 [==============================] - 0s 1ms/step - loss: 0.6269 - accuracy: 0.6800 - val_loss: 0.6002 - val_accuracy: 0.7153\n",
            "Epoch 34/100\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.6269 - accuracy: 0.6800 - val_loss: 0.6004 - val_accuracy: 0.7153\n",
            "Epoch 35/100\n",
            "105/105 [==============================] - 0s 1ms/step - loss: 0.6269 - accuracy: 0.6800 - val_loss: 0.6002 - val_accuracy: 0.7153\n",
            "Epoch 36/100\n",
            "105/105 [==============================] - 0s 1ms/step - loss: 0.6269 - accuracy: 0.6800 - val_loss: 0.6003 - val_accuracy: 0.7153\n",
            "Epoch 37/100\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.6269 - accuracy: 0.6800 - val_loss: 0.6003 - val_accuracy: 0.7153\n",
            "Epoch 38/100\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.6269 - accuracy: 0.6800 - val_loss: 0.6002 - val_accuracy: 0.7153\n",
            "Epoch 39/100\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.6269 - accuracy: 0.6800 - val_loss: 0.6001 - val_accuracy: 0.7153\n",
            "Epoch 40/100\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.6269 - accuracy: 0.6800 - val_loss: 0.6002 - val_accuracy: 0.7153\n",
            "Epoch 41/100\n",
            "105/105 [==============================] - 0s 1ms/step - loss: 0.6269 - accuracy: 0.6800 - val_loss: 0.6002 - val_accuracy: 0.7153\n",
            "Epoch 42/100\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.6269 - accuracy: 0.6800 - val_loss: 0.6002 - val_accuracy: 0.7153\n",
            "Epoch 43/100\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.6269 - accuracy: 0.6800 - val_loss: 0.6002 - val_accuracy: 0.7153\n",
            "Epoch 44/100\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.6269 - accuracy: 0.6800 - val_loss: 0.6003 - val_accuracy: 0.7153\n",
            "Epoch 45/100\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.6269 - accuracy: 0.6800 - val_loss: 0.6004 - val_accuracy: 0.7153\n",
            "Epoch 46/100\n",
            "105/105 [==============================] - 0s 1ms/step - loss: 0.6269 - accuracy: 0.6800 - val_loss: 0.6003 - val_accuracy: 0.7153\n",
            "Epoch 47/100\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.6269 - accuracy: 0.6800 - val_loss: 0.6003 - val_accuracy: 0.7153\n",
            "Epoch 48/100\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.6269 - accuracy: 0.6800 - val_loss: 0.6002 - val_accuracy: 0.7153\n",
            "Epoch 49/100\n",
            "105/105 [==============================] - 0s 1ms/step - loss: 0.6269 - accuracy: 0.6800 - val_loss: 0.6003 - val_accuracy: 0.7153\n",
            "Epoch 50/100\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.6269 - accuracy: 0.6800 - val_loss: 0.6003 - val_accuracy: 0.7153\n",
            "Epoch 51/100\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.6269 - accuracy: 0.6800 - val_loss: 0.6003 - val_accuracy: 0.7153\n",
            "Epoch 52/100\n",
            "105/105 [==============================] - 0s 1ms/step - loss: 0.6269 - accuracy: 0.6800 - val_loss: 0.6004 - val_accuracy: 0.7153\n",
            "Epoch 53/100\n",
            "105/105 [==============================] - 0s 1ms/step - loss: 0.6269 - accuracy: 0.6800 - val_loss: 0.6003 - val_accuracy: 0.7153\n",
            "Epoch 54/100\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.6269 - accuracy: 0.6800 - val_loss: 0.6004 - val_accuracy: 0.7153\n",
            "Epoch 55/100\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.6269 - accuracy: 0.6800 - val_loss: 0.6003 - val_accuracy: 0.7153\n",
            "Epoch 56/100\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.6269 - accuracy: 0.6800 - val_loss: 0.6003 - val_accuracy: 0.7153\n",
            "Epoch 57/100\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.6269 - accuracy: 0.6800 - val_loss: 0.6004 - val_accuracy: 0.7153\n",
            "Epoch 58/100\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.6269 - accuracy: 0.6800 - val_loss: 0.6004 - val_accuracy: 0.7153\n",
            "Epoch 59/100\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.6269 - accuracy: 0.6800 - val_loss: 0.6002 - val_accuracy: 0.7153\n",
            "Epoch 60/100\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.6269 - accuracy: 0.6800 - val_loss: 0.6003 - val_accuracy: 0.7153\n",
            "Epoch 61/100\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.6269 - accuracy: 0.6800 - val_loss: 0.6004 - val_accuracy: 0.7153\n",
            "Epoch 62/100\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.6269 - accuracy: 0.6800 - val_loss: 0.6003 - val_accuracy: 0.7153\n",
            "Epoch 63/100\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.6269 - accuracy: 0.6800 - val_loss: 0.6002 - val_accuracy: 0.7153\n",
            "Epoch 64/100\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.6269 - accuracy: 0.6800 - val_loss: 0.6002 - val_accuracy: 0.7153\n",
            "Epoch 65/100\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.6269 - accuracy: 0.6800 - val_loss: 0.6004 - val_accuracy: 0.7153\n",
            "Epoch 66/100\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.6269 - accuracy: 0.6800 - val_loss: 0.6002 - val_accuracy: 0.7153\n",
            "Epoch 67/100\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.6269 - accuracy: 0.6800 - val_loss: 0.6002 - val_accuracy: 0.7153\n",
            "Epoch 68/100\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.6269 - accuracy: 0.6800 - val_loss: 0.6003 - val_accuracy: 0.7153\n",
            "Epoch 69/100\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.6269 - accuracy: 0.6800 - val_loss: 0.6002 - val_accuracy: 0.7153\n",
            "Epoch 70/100\n",
            "105/105 [==============================] - 0s 1ms/step - loss: 0.6269 - accuracy: 0.6800 - val_loss: 0.6002 - val_accuracy: 0.7153\n",
            "Epoch 71/100\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.6269 - accuracy: 0.6800 - val_loss: 0.6002 - val_accuracy: 0.7153\n",
            "Epoch 72/100\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.6269 - accuracy: 0.6800 - val_loss: 0.6003 - val_accuracy: 0.7153\n",
            "Epoch 73/100\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.6269 - accuracy: 0.6800 - val_loss: 0.6002 - val_accuracy: 0.7153\n",
            "Epoch 74/100\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.6269 - accuracy: 0.6800 - val_loss: 0.6003 - val_accuracy: 0.7153\n",
            "Epoch 75/100\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.6269 - accuracy: 0.6800 - val_loss: 0.6004 - val_accuracy: 0.7153\n",
            "Epoch 76/100\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.6269 - accuracy: 0.6800 - val_loss: 0.6002 - val_accuracy: 0.7153\n",
            "Epoch 77/100\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.6269 - accuracy: 0.6800 - val_loss: 0.6002 - val_accuracy: 0.7153\n",
            "Epoch 78/100\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.6269 - accuracy: 0.6800 - val_loss: 0.6001 - val_accuracy: 0.7153\n",
            "Epoch 79/100\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.6269 - accuracy: 0.6800 - val_loss: 0.6003 - val_accuracy: 0.7153\n",
            "Epoch 80/100\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.6269 - accuracy: 0.6800 - val_loss: 0.6003 - val_accuracy: 0.7153\n",
            "Epoch 81/100\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.6269 - accuracy: 0.6800 - val_loss: 0.6002 - val_accuracy: 0.7153\n",
            "Epoch 82/100\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.6269 - accuracy: 0.6800 - val_loss: 0.6002 - val_accuracy: 0.7153\n",
            "Epoch 83/100\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.6269 - accuracy: 0.6800 - val_loss: 0.6004 - val_accuracy: 0.7153\n",
            "Epoch 84/100\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.6269 - accuracy: 0.6800 - val_loss: 0.6004 - val_accuracy: 0.7153\n",
            "Epoch 85/100\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.6269 - accuracy: 0.6800 - val_loss: 0.6003 - val_accuracy: 0.7153\n",
            "Epoch 86/100\n",
            "105/105 [==============================] - 0s 1ms/step - loss: 0.6269 - accuracy: 0.6800 - val_loss: 0.6003 - val_accuracy: 0.7153\n",
            "Epoch 87/100\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.6269 - accuracy: 0.6800 - val_loss: 0.6002 - val_accuracy: 0.7153\n",
            "Epoch 88/100\n",
            "105/105 [==============================] - 0s 1ms/step - loss: 0.6269 - accuracy: 0.6800 - val_loss: 0.6003 - val_accuracy: 0.7153\n",
            "Epoch 89/100\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.6269 - accuracy: 0.6800 - val_loss: 0.6002 - val_accuracy: 0.7153\n",
            "Epoch 90/100\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.6269 - accuracy: 0.6800 - val_loss: 0.6001 - val_accuracy: 0.7153\n",
            "Epoch 91/100\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.6269 - accuracy: 0.6800 - val_loss: 0.6002 - val_accuracy: 0.7153\n",
            "Epoch 92/100\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.6269 - accuracy: 0.6800 - val_loss: 0.6002 - val_accuracy: 0.7153\n",
            "Epoch 93/100\n",
            "105/105 [==============================] - 0s 1ms/step - loss: 0.6269 - accuracy: 0.6800 - val_loss: 0.6003 - val_accuracy: 0.7153\n",
            "Epoch 94/100\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.6269 - accuracy: 0.6800 - val_loss: 0.6003 - val_accuracy: 0.7153\n",
            "Epoch 95/100\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.6269 - accuracy: 0.6800 - val_loss: 0.6003 - val_accuracy: 0.7153\n",
            "Epoch 96/100\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.6269 - accuracy: 0.6800 - val_loss: 0.6001 - val_accuracy: 0.7153\n",
            "Epoch 97/100\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.6269 - accuracy: 0.6800 - val_loss: 0.6002 - val_accuracy: 0.7153\n",
            "Epoch 98/100\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.6269 - accuracy: 0.6800 - val_loss: 0.6003 - val_accuracy: 0.7153\n",
            "Epoch 99/100\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.6269 - accuracy: 0.6800 - val_loss: 0.6002 - val_accuracy: 0.7153\n",
            "Epoch 100/100\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.6269 - accuracy: 0.6800 - val_loss: 0.6003 - val_accuracy: 0.7153\n",
            "[array([[-0.02155724,  0.01707809],\n",
            "       [-0.00264717,  0.03285329],\n",
            "       [ 0.00694698, -0.04569536],\n",
            "       [ 0.0451389 , -0.01927919],\n",
            "       [ 0.02194549,  0.00575884],\n",
            "       [ 0.01315637,  0.02647375],\n",
            "       [-0.02768041, -0.01636359],\n",
            "       [-0.04308265, -0.0086024 ]], dtype=float32), array([ 0.        , -0.01266141], dtype=float32), array([[ 0.5039134 ],\n",
            "       [-0.48170677]], dtype=float32), array([0.7532446], dtype=float32)]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#3. Xavier/Glorot Initialization\n",
        "\n",
        "\n",
        "##Xavier/Glorot Initialization often termed as Xavier Uniform Initialization, is suitable for layers where the activation function used is **Sigmoid.**"
      ],
      "metadata": {
        "id": "l-ojtDCokKGN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Random Uniform Initialization\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras import initializers\n",
        "\n",
        "initializer = tf.keras.initializers.GlorotUniform()\n",
        "\n",
        "\n",
        "model = Sequential()\n",
        "\n",
        "model.add(Dense(2,activation='sigmoid',input_dim=8,kernel_initializer=initializer))\n",
        "model.add(Dense(1,activation='sigmoid'))\n",
        "\n",
        "print(model.summary())\n",
        "print(model.get_weights())\n",
        "\n",
        "model.compile(loss='binary_crossentropy',optimizer='adam',metrics=['accuracy'])\n",
        "history = model.fit(X,y,epochs=100,validation_split=0.2)\n",
        "print(model.get_weights())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HX9-rLduYAjn",
        "outputId": "8987f2cf-7f39-4512-a12e-107e7be36014"
      },
      "execution_count": 78,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_14\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_28 (Dense)            (None, 2)                 18        \n",
            "                                                                 \n",
            " dense_29 (Dense)            (None, 1)                 3         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 21 (84.00 Byte)\n",
            "Trainable params: 21 (84.00 Byte)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n",
            "None\n",
            "[array([[ 0.7373986 ,  0.77358174],\n",
            "       [ 0.32113147,  0.18028122],\n",
            "       [-0.4132497 , -0.67032754],\n",
            "       [ 0.17214578,  0.68454885],\n",
            "       [-0.256608  , -0.4671423 ],\n",
            "       [ 0.30586112,  0.24584961],\n",
            "       [ 0.46955585, -0.05722791],\n",
            "       [ 0.7468014 , -0.4865156 ]], dtype=float32), array([0., 0.], dtype=float32), array([[-0.8292089],\n",
            "       [-0.7919079]], dtype=float32), array([0.], dtype=float32)]\n",
            "Epoch 1/100\n",
            "105/105 [==============================] - 1s 3ms/step - loss: 0.8953 - accuracy: 0.3200 - val_loss: 0.8794 - val_accuracy: 0.2847\n",
            "Epoch 2/100\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.8249 - accuracy: 0.3200 - val_loss: 0.8089 - val_accuracy: 0.2847\n",
            "Epoch 3/100\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.7622 - accuracy: 0.3200 - val_loss: 0.7327 - val_accuracy: 0.2847\n",
            "Epoch 4/100\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.6928 - accuracy: 0.5214 - val_loss: 0.6631 - val_accuracy: 0.7153\n",
            "Epoch 5/100\n",
            "105/105 [==============================] - 0s 1ms/step - loss: 0.6608 - accuracy: 0.6800 - val_loss: 0.6430 - val_accuracy: 0.7153\n",
            "Epoch 6/100\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.6503 - accuracy: 0.6800 - val_loss: 0.6333 - val_accuracy: 0.7153\n",
            "Epoch 7/100\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.6443 - accuracy: 0.6800 - val_loss: 0.6266 - val_accuracy: 0.7153\n",
            "Epoch 8/100\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.6402 - accuracy: 0.6800 - val_loss: 0.6215 - val_accuracy: 0.7153\n",
            "Epoch 9/100\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.6372 - accuracy: 0.6800 - val_loss: 0.6175 - val_accuracy: 0.7153\n",
            "Epoch 10/100\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.6349 - accuracy: 0.6800 - val_loss: 0.6146 - val_accuracy: 0.7153\n",
            "Epoch 11/100\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.6332 - accuracy: 0.6800 - val_loss: 0.6120 - val_accuracy: 0.7153\n",
            "Epoch 12/100\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.6318 - accuracy: 0.6800 - val_loss: 0.6100 - val_accuracy: 0.7153\n",
            "Epoch 13/100\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.6308 - accuracy: 0.6800 - val_loss: 0.6082 - val_accuracy: 0.7153\n",
            "Epoch 14/100\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.6300 - accuracy: 0.6800 - val_loss: 0.6068 - val_accuracy: 0.7153\n",
            "Epoch 15/100\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.6293 - accuracy: 0.6800 - val_loss: 0.6057 - val_accuracy: 0.7153\n",
            "Epoch 16/100\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.6289 - accuracy: 0.6800 - val_loss: 0.6048 - val_accuracy: 0.7153\n",
            "Epoch 17/100\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.6285 - accuracy: 0.6800 - val_loss: 0.6040 - val_accuracy: 0.7153\n",
            "Epoch 18/100\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.6282 - accuracy: 0.6800 - val_loss: 0.6034 - val_accuracy: 0.7153\n",
            "Epoch 19/100\n",
            "105/105 [==============================] - 0s 1ms/step - loss: 0.6280 - accuracy: 0.6800 - val_loss: 0.6028 - val_accuracy: 0.7153\n",
            "Epoch 20/100\n",
            "105/105 [==============================] - 0s 1ms/step - loss: 0.6278 - accuracy: 0.6800 - val_loss: 0.6024 - val_accuracy: 0.7153\n",
            "Epoch 21/100\n",
            "105/105 [==============================] - 0s 1ms/step - loss: 0.6277 - accuracy: 0.6800 - val_loss: 0.6021 - val_accuracy: 0.7153\n",
            "Epoch 22/100\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.6276 - accuracy: 0.6800 - val_loss: 0.6017 - val_accuracy: 0.7153\n",
            "Epoch 23/100\n",
            "105/105 [==============================] - 0s 1ms/step - loss: 0.6275 - accuracy: 0.6800 - val_loss: 0.6016 - val_accuracy: 0.7153\n",
            "Epoch 24/100\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.6275 - accuracy: 0.6800 - val_loss: 0.6013 - val_accuracy: 0.7153\n",
            "Epoch 25/100\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.6274 - accuracy: 0.6800 - val_loss: 0.6013 - val_accuracy: 0.7153\n",
            "Epoch 26/100\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.6274 - accuracy: 0.6800 - val_loss: 0.6010 - val_accuracy: 0.7153\n",
            "Epoch 27/100\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.6273 - accuracy: 0.6800 - val_loss: 0.6009 - val_accuracy: 0.7153\n",
            "Epoch 28/100\n",
            "105/105 [==============================] - 0s 1ms/step - loss: 0.6273 - accuracy: 0.6800 - val_loss: 0.6009 - val_accuracy: 0.7153\n",
            "Epoch 29/100\n",
            "105/105 [==============================] - 0s 1ms/step - loss: 0.6272 - accuracy: 0.6800 - val_loss: 0.6007 - val_accuracy: 0.7153\n",
            "Epoch 30/100\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.6272 - accuracy: 0.6800 - val_loss: 0.6006 - val_accuracy: 0.7153\n",
            "Epoch 31/100\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.6272 - accuracy: 0.6800 - val_loss: 0.6006 - val_accuracy: 0.7153\n",
            "Epoch 32/100\n",
            "105/105 [==============================] - 0s 1ms/step - loss: 0.6271 - accuracy: 0.6800 - val_loss: 0.6005 - val_accuracy: 0.7153\n",
            "Epoch 33/100\n",
            "105/105 [==============================] - 0s 1ms/step - loss: 0.6271 - accuracy: 0.6800 - val_loss: 0.6006 - val_accuracy: 0.7153\n",
            "Epoch 34/100\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.6271 - accuracy: 0.6800 - val_loss: 0.6005 - val_accuracy: 0.7153\n",
            "Epoch 35/100\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.6270 - accuracy: 0.6800 - val_loss: 0.6003 - val_accuracy: 0.7153\n",
            "Epoch 36/100\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.6270 - accuracy: 0.6800 - val_loss: 0.6004 - val_accuracy: 0.7153\n",
            "Epoch 37/100\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.6269 - accuracy: 0.6800 - val_loss: 0.6003 - val_accuracy: 0.7153\n",
            "Epoch 38/100\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.6269 - accuracy: 0.6800 - val_loss: 0.6001 - val_accuracy: 0.7153\n",
            "Epoch 39/100\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.6267 - accuracy: 0.6800 - val_loss: 0.5998 - val_accuracy: 0.7153\n",
            "Epoch 40/100\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.6262 - accuracy: 0.6800 - val_loss: 0.5983 - val_accuracy: 0.7153\n",
            "Epoch 41/100\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.6228 - accuracy: 0.6800 - val_loss: 0.5916 - val_accuracy: 0.7153\n",
            "Epoch 42/100\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.6177 - accuracy: 0.6800 - val_loss: 0.5861 - val_accuracy: 0.7153\n",
            "Epoch 43/100\n",
            "105/105 [==============================] - 0s 1ms/step - loss: 0.6134 - accuracy: 0.6800 - val_loss: 0.5808 - val_accuracy: 0.7153\n",
            "Epoch 44/100\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.6094 - accuracy: 0.6800 - val_loss: 0.5771 - val_accuracy: 0.7153\n",
            "Epoch 45/100\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.6056 - accuracy: 0.6800 - val_loss: 0.5730 - val_accuracy: 0.7153\n",
            "Epoch 46/100\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.6017 - accuracy: 0.6800 - val_loss: 0.5699 - val_accuracy: 0.7153\n",
            "Epoch 47/100\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.5984 - accuracy: 0.6800 - val_loss: 0.5659 - val_accuracy: 0.7153\n",
            "Epoch 48/100\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.5951 - accuracy: 0.6800 - val_loss: 0.5616 - val_accuracy: 0.7153\n",
            "Epoch 49/100\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.5921 - accuracy: 0.6800 - val_loss: 0.5591 - val_accuracy: 0.7153\n",
            "Epoch 50/100\n",
            "105/105 [==============================] - 0s 1ms/step - loss: 0.5893 - accuracy: 0.6800 - val_loss: 0.5556 - val_accuracy: 0.7153\n",
            "Epoch 51/100\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.5867 - accuracy: 0.6800 - val_loss: 0.5540 - val_accuracy: 0.7153\n",
            "Epoch 52/100\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.5843 - accuracy: 0.6800 - val_loss: 0.5520 - val_accuracy: 0.7153\n",
            "Epoch 53/100\n",
            "105/105 [==============================] - 0s 1ms/step - loss: 0.5822 - accuracy: 0.6800 - val_loss: 0.5490 - val_accuracy: 0.7153\n",
            "Epoch 54/100\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.5802 - accuracy: 0.6800 - val_loss: 0.5475 - val_accuracy: 0.7153\n",
            "Epoch 55/100\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.5785 - accuracy: 0.6800 - val_loss: 0.5458 - val_accuracy: 0.7153\n",
            "Epoch 56/100\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.5768 - accuracy: 0.6800 - val_loss: 0.5446 - val_accuracy: 0.7153\n",
            "Epoch 57/100\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.5753 - accuracy: 0.6800 - val_loss: 0.5418 - val_accuracy: 0.7153\n",
            "Epoch 58/100\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.5740 - accuracy: 0.6800 - val_loss: 0.5416 - val_accuracy: 0.7153\n",
            "Epoch 59/100\n",
            "105/105 [==============================] - 0s 1ms/step - loss: 0.5727 - accuracy: 0.6800 - val_loss: 0.5417 - val_accuracy: 0.7153\n",
            "Epoch 60/100\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.5718 - accuracy: 0.6800 - val_loss: 0.5389 - val_accuracy: 0.7153\n",
            "Epoch 61/100\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.5706 - accuracy: 0.6800 - val_loss: 0.5368 - val_accuracy: 0.7153\n",
            "Epoch 62/100\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.5698 - accuracy: 0.6800 - val_loss: 0.5358 - val_accuracy: 0.7153\n",
            "Epoch 63/100\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.5691 - accuracy: 0.6800 - val_loss: 0.5351 - val_accuracy: 0.7153\n",
            "Epoch 64/100\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.5682 - accuracy: 0.6800 - val_loss: 0.5343 - val_accuracy: 0.7153\n",
            "Epoch 65/100\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.5675 - accuracy: 0.6800 - val_loss: 0.5344 - val_accuracy: 0.7153\n",
            "Epoch 66/100\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.5668 - accuracy: 0.6800 - val_loss: 0.5330 - val_accuracy: 0.7153\n",
            "Epoch 67/100\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.5663 - accuracy: 0.6800 - val_loss: 0.5330 - val_accuracy: 0.7153\n",
            "Epoch 68/100\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.5657 - accuracy: 0.6800 - val_loss: 0.5328 - val_accuracy: 0.7153\n",
            "Epoch 69/100\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.5652 - accuracy: 0.6800 - val_loss: 0.5326 - val_accuracy: 0.7153\n",
            "Epoch 70/100\n",
            "105/105 [==============================] - 0s 1ms/step - loss: 0.5647 - accuracy: 0.6800 - val_loss: 0.5314 - val_accuracy: 0.7153\n",
            "Epoch 71/100\n",
            "105/105 [==============================] - 0s 1ms/step - loss: 0.5643 - accuracy: 0.6800 - val_loss: 0.5304 - val_accuracy: 0.7153\n",
            "Epoch 72/100\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.5639 - accuracy: 0.6800 - val_loss: 0.5294 - val_accuracy: 0.7153\n",
            "Epoch 73/100\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.5635 - accuracy: 0.6800 - val_loss: 0.5291 - val_accuracy: 0.7153\n",
            "Epoch 74/100\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.5634 - accuracy: 0.6800 - val_loss: 0.5299 - val_accuracy: 0.7153\n",
            "Epoch 75/100\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.5628 - accuracy: 0.6800 - val_loss: 0.5286 - val_accuracy: 0.7153\n",
            "Epoch 76/100\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.5625 - accuracy: 0.6800 - val_loss: 0.5299 - val_accuracy: 0.7153\n",
            "Epoch 77/100\n",
            "105/105 [==============================] - 0s 3ms/step - loss: 0.5623 - accuracy: 0.6800 - val_loss: 0.5291 - val_accuracy: 0.7153\n",
            "Epoch 78/100\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.5621 - accuracy: 0.6800 - val_loss: 0.5280 - val_accuracy: 0.7153\n",
            "Epoch 79/100\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.5617 - accuracy: 0.6800 - val_loss: 0.5278 - val_accuracy: 0.7153\n",
            "Epoch 80/100\n",
            "105/105 [==============================] - 0s 1ms/step - loss: 0.5616 - accuracy: 0.6800 - val_loss: 0.5269 - val_accuracy: 0.7153\n",
            "Epoch 81/100\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.5613 - accuracy: 0.6800 - val_loss: 0.5268 - val_accuracy: 0.7153\n",
            "Epoch 82/100\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.5612 - accuracy: 0.6800 - val_loss: 0.5268 - val_accuracy: 0.7153\n",
            "Epoch 83/100\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.5608 - accuracy: 0.6800 - val_loss: 0.5273 - val_accuracy: 0.7153\n",
            "Epoch 84/100\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.5607 - accuracy: 0.6800 - val_loss: 0.5272 - val_accuracy: 0.7153\n",
            "Epoch 85/100\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.5607 - accuracy: 0.6800 - val_loss: 0.5260 - val_accuracy: 0.7153\n",
            "Epoch 86/100\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.5604 - accuracy: 0.6800 - val_loss: 0.5259 - val_accuracy: 0.7153\n",
            "Epoch 87/100\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.5602 - accuracy: 0.6800 - val_loss: 0.5259 - val_accuracy: 0.7153\n",
            "Epoch 88/100\n",
            "105/105 [==============================] - 0s 1ms/step - loss: 0.5600 - accuracy: 0.6800 - val_loss: 0.5259 - val_accuracy: 0.7153\n",
            "Epoch 89/100\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.5600 - accuracy: 0.6800 - val_loss: 0.5253 - val_accuracy: 0.7153\n",
            "Epoch 90/100\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.5597 - accuracy: 0.6800 - val_loss: 0.5258 - val_accuracy: 0.7153\n",
            "Epoch 91/100\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.5596 - accuracy: 0.6800 - val_loss: 0.5253 - val_accuracy: 0.7153\n",
            "Epoch 92/100\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.5596 - accuracy: 0.6800 - val_loss: 0.5270 - val_accuracy: 0.7153\n",
            "Epoch 93/100\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.5597 - accuracy: 0.6800 - val_loss: 0.5259 - val_accuracy: 0.7153\n",
            "Epoch 94/100\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.5594 - accuracy: 0.6800 - val_loss: 0.5256 - val_accuracy: 0.7153\n",
            "Epoch 95/100\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.5594 - accuracy: 0.6800 - val_loss: 0.5266 - val_accuracy: 0.7153\n",
            "Epoch 96/100\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.5591 - accuracy: 0.6800 - val_loss: 0.5250 - val_accuracy: 0.7153\n",
            "Epoch 97/100\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.5590 - accuracy: 0.6800 - val_loss: 0.5253 - val_accuracy: 0.7153\n",
            "Epoch 98/100\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.5589 - accuracy: 0.6800 - val_loss: 0.5241 - val_accuracy: 0.7153\n",
            "Epoch 99/100\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.5587 - accuracy: 0.6800 - val_loss: 0.5245 - val_accuracy: 0.7153\n",
            "Epoch 100/100\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.5587 - accuracy: 0.6800 - val_loss: 0.5242 - val_accuracy: 0.7153\n",
            "[array([[-0.69562083,  1.3048302 ],\n",
            "       [-1.0918636 ,  0.54297096],\n",
            "       [-1.8006138 , -0.8809421 ],\n",
            "       [-0.80367845, -1.2410988 ],\n",
            "       [-1.2465758 , -1.9270195 ],\n",
            "       [-0.649517  , -2.0621028 ],\n",
            "       [-0.5280837 , -1.9525493 ],\n",
            "       [-0.6904767 , -0.21504368]], dtype=float32), array([-1.7066028,  1.9951509], dtype=float32), array([[-0.32604972],\n",
            "       [ 3.9114592 ]], dtype=float32), array([0.02054488], dtype=float32)]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#4. Normalized Xavier/Glorot Initialization\n",
        "\n",
        "##Xavier/Glorot Initialization, too, is suitable for layers where the activation function used is Sigmoid.\n",
        "\n"
      ],
      "metadata": {
        "id": "rjoHeK0UlQer"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras import initializers\n",
        "\n",
        "initializer = tf.keras.initializers.GlorotNormal()\n",
        "\n",
        "\n",
        "model = Sequential()\n",
        "\n",
        "model.add(Dense(2,activation='sigmoid',input_dim=8,kernel_initializer=initializer))\n",
        "model.add(Dense(1,activation='sigmoid'))\n",
        "\n",
        "print(model.summary())\n",
        "print(model.get_weights())\n",
        "\n",
        "model.compile(loss='binary_crossentropy',optimizer='adam',metrics=['accuracy'])\n",
        "history = model.fit(X,y,epochs=100,validation_split=0.2)\n",
        "print(model.get_weights())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ogM2G0ZBYAl9",
        "outputId": "512c6428-a4b5-4e8d-ae5f-ee19ff5c74b2"
      },
      "execution_count": 79,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_15\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_30 (Dense)            (None, 2)                 18        \n",
            "                                                                 \n",
            " dense_31 (Dense)            (None, 1)                 3         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 21 (84.00 Byte)\n",
            "Trainable params: 21 (84.00 Byte)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n",
            "None\n",
            "[array([[-0.01866647,  0.5383708 ],\n",
            "       [ 0.8704364 ,  0.2397974 ],\n",
            "       [-0.07851727, -0.8907971 ],\n",
            "       [ 0.48241413,  0.1291903 ],\n",
            "       [ 0.27534023, -0.10146821],\n",
            "       [ 0.4082537 ,  0.79257005],\n",
            "       [ 0.17022194,  0.45597526],\n",
            "       [-0.51785254, -0.6109341 ]], dtype=float32), array([0., 0.], dtype=float32), array([[-0.36538827],\n",
            "       [-0.17477584]], dtype=float32), array([0.], dtype=float32)]\n",
            "Epoch 1/100\n",
            "105/105 [==============================] - 1s 2ms/step - loss: 0.6873 - accuracy: 0.6241 - val_loss: 0.6752 - val_accuracy: 0.7153\n",
            "Epoch 2/100\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.6722 - accuracy: 0.6800 - val_loss: 0.6599 - val_accuracy: 0.7153\n",
            "Epoch 3/100\n",
            "105/105 [==============================] - 0s 1ms/step - loss: 0.6605 - accuracy: 0.6800 - val_loss: 0.6466 - val_accuracy: 0.7153\n",
            "Epoch 4/100\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.6516 - accuracy: 0.6800 - val_loss: 0.6362 - val_accuracy: 0.7153\n",
            "Epoch 5/100\n",
            "105/105 [==============================] - 0s 1ms/step - loss: 0.6446 - accuracy: 0.6800 - val_loss: 0.6276 - val_accuracy: 0.7153\n",
            "Epoch 6/100\n",
            "105/105 [==============================] - 0s 1ms/step - loss: 0.6367 - accuracy: 0.6800 - val_loss: 0.6124 - val_accuracy: 0.7153\n",
            "Epoch 7/100\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.6264 - accuracy: 0.6800 - val_loss: 0.6024 - val_accuracy: 0.7153\n",
            "Epoch 8/100\n",
            "105/105 [==============================] - 0s 1ms/step - loss: 0.6226 - accuracy: 0.6800 - val_loss: 0.5989 - val_accuracy: 0.7153\n",
            "Epoch 9/100\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.6201 - accuracy: 0.6800 - val_loss: 0.5960 - val_accuracy: 0.7153\n",
            "Epoch 10/100\n",
            "105/105 [==============================] - 0s 1ms/step - loss: 0.6178 - accuracy: 0.6800 - val_loss: 0.5927 - val_accuracy: 0.7153\n",
            "Epoch 11/100\n",
            "105/105 [==============================] - 0s 1ms/step - loss: 0.6157 - accuracy: 0.6800 - val_loss: 0.5905 - val_accuracy: 0.7153\n",
            "Epoch 12/100\n",
            "105/105 [==============================] - 0s 1ms/step - loss: 0.6139 - accuracy: 0.6800 - val_loss: 0.5881 - val_accuracy: 0.7153\n",
            "Epoch 13/100\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.6118 - accuracy: 0.6800 - val_loss: 0.5854 - val_accuracy: 0.7153\n",
            "Epoch 14/100\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.6096 - accuracy: 0.6800 - val_loss: 0.5827 - val_accuracy: 0.7153\n",
            "Epoch 15/100\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.6074 - accuracy: 0.6800 - val_loss: 0.5802 - val_accuracy: 0.7153\n",
            "Epoch 16/100\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.6045 - accuracy: 0.6800 - val_loss: 0.5752 - val_accuracy: 0.7153\n",
            "Epoch 17/100\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.6011 - accuracy: 0.6800 - val_loss: 0.5709 - val_accuracy: 0.7153\n",
            "Epoch 18/100\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.5975 - accuracy: 0.6800 - val_loss: 0.5668 - val_accuracy: 0.7153\n",
            "Epoch 19/100\n",
            "105/105 [==============================] - 0s 1ms/step - loss: 0.5943 - accuracy: 0.6800 - val_loss: 0.5638 - val_accuracy: 0.7153\n",
            "Epoch 20/100\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.5911 - accuracy: 0.6800 - val_loss: 0.5604 - val_accuracy: 0.7153\n",
            "Epoch 21/100\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.5883 - accuracy: 0.6800 - val_loss: 0.5575 - val_accuracy: 0.7153\n",
            "Epoch 22/100\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.5857 - accuracy: 0.6800 - val_loss: 0.5537 - val_accuracy: 0.7153\n",
            "Epoch 23/100\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.5832 - accuracy: 0.6800 - val_loss: 0.5516 - val_accuracy: 0.7153\n",
            "Epoch 24/100\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.5806 - accuracy: 0.6800 - val_loss: 0.5493 - val_accuracy: 0.7153\n",
            "Epoch 25/100\n",
            "105/105 [==============================] - 0s 1ms/step - loss: 0.5786 - accuracy: 0.6800 - val_loss: 0.5466 - val_accuracy: 0.7153\n",
            "Epoch 26/100\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.5767 - accuracy: 0.6800 - val_loss: 0.5450 - val_accuracy: 0.7153\n",
            "Epoch 27/100\n",
            "105/105 [==============================] - 0s 1ms/step - loss: 0.5747 - accuracy: 0.6800 - val_loss: 0.5415 - val_accuracy: 0.7153\n",
            "Epoch 28/100\n",
            "105/105 [==============================] - 0s 1ms/step - loss: 0.5733 - accuracy: 0.6800 - val_loss: 0.5414 - val_accuracy: 0.7153\n",
            "Epoch 29/100\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.5717 - accuracy: 0.6800 - val_loss: 0.5404 - val_accuracy: 0.7153\n",
            "Epoch 30/100\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.5703 - accuracy: 0.6800 - val_loss: 0.5378 - val_accuracy: 0.7153\n",
            "Epoch 31/100\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.5691 - accuracy: 0.6800 - val_loss: 0.5369 - val_accuracy: 0.7153\n",
            "Epoch 32/100\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.5680 - accuracy: 0.6800 - val_loss: 0.5353 - val_accuracy: 0.7153\n",
            "Epoch 33/100\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.5670 - accuracy: 0.6800 - val_loss: 0.5330 - val_accuracy: 0.7153\n",
            "Epoch 34/100\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.5661 - accuracy: 0.6800 - val_loss: 0.5339 - val_accuracy: 0.7153\n",
            "Epoch 35/100\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.5652 - accuracy: 0.6800 - val_loss: 0.5316 - val_accuracy: 0.7153\n",
            "Epoch 36/100\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.5644 - accuracy: 0.6800 - val_loss: 0.5311 - val_accuracy: 0.7153\n",
            "Epoch 37/100\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.5639 - accuracy: 0.6800 - val_loss: 0.5304 - val_accuracy: 0.7153\n",
            "Epoch 38/100\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.5631 - accuracy: 0.6800 - val_loss: 0.5309 - val_accuracy: 0.7153\n",
            "Epoch 39/100\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.5626 - accuracy: 0.6800 - val_loss: 0.5313 - val_accuracy: 0.7153\n",
            "Epoch 40/100\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.5622 - accuracy: 0.6800 - val_loss: 0.5298 - val_accuracy: 0.7153\n",
            "Epoch 41/100\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.5618 - accuracy: 0.6800 - val_loss: 0.5283 - val_accuracy: 0.7153\n",
            "Epoch 42/100\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.5613 - accuracy: 0.6800 - val_loss: 0.5279 - val_accuracy: 0.7153\n",
            "Epoch 43/100\n",
            "105/105 [==============================] - 0s 1ms/step - loss: 0.5610 - accuracy: 0.6800 - val_loss: 0.5278 - val_accuracy: 0.7153\n",
            "Epoch 44/100\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.5606 - accuracy: 0.6800 - val_loss: 0.5266 - val_accuracy: 0.7153\n",
            "Epoch 45/100\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.5603 - accuracy: 0.6800 - val_loss: 0.5279 - val_accuracy: 0.7153\n",
            "Epoch 46/100\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.5601 - accuracy: 0.6800 - val_loss: 0.5254 - val_accuracy: 0.7153\n",
            "Epoch 47/100\n",
            "105/105 [==============================] - 0s 1ms/step - loss: 0.5598 - accuracy: 0.6800 - val_loss: 0.5261 - val_accuracy: 0.7153\n",
            "Epoch 48/100\n",
            "105/105 [==============================] - 0s 1ms/step - loss: 0.5597 - accuracy: 0.6797 - val_loss: 0.5256 - val_accuracy: 0.7153\n",
            "Epoch 49/100\n",
            "105/105 [==============================] - 0s 1ms/step - loss: 0.5595 - accuracy: 0.6803 - val_loss: 0.5256 - val_accuracy: 0.7141\n",
            "Epoch 50/100\n",
            "105/105 [==============================] - 0s 1ms/step - loss: 0.5593 - accuracy: 0.6815 - val_loss: 0.5260 - val_accuracy: 0.7129\n",
            "Epoch 51/100\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.5591 - accuracy: 0.6797 - val_loss: 0.5257 - val_accuracy: 0.7117\n",
            "Epoch 52/100\n",
            "105/105 [==============================] - 0s 1ms/step - loss: 0.5590 - accuracy: 0.6773 - val_loss: 0.5250 - val_accuracy: 0.7117\n",
            "Epoch 53/100\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.5588 - accuracy: 0.6788 - val_loss: 0.5242 - val_accuracy: 0.7117\n",
            "Epoch 54/100\n",
            "105/105 [==============================] - 0s 1ms/step - loss: 0.5586 - accuracy: 0.6773 - val_loss: 0.5238 - val_accuracy: 0.7117\n",
            "Epoch 55/100\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.5588 - accuracy: 0.6776 - val_loss: 0.5255 - val_accuracy: 0.7069\n",
            "Epoch 56/100\n",
            "105/105 [==============================] - 0s 1ms/step - loss: 0.5583 - accuracy: 0.6785 - val_loss: 0.5236 - val_accuracy: 0.7093\n",
            "Epoch 57/100\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.5582 - accuracy: 0.6782 - val_loss: 0.5237 - val_accuracy: 0.7069\n",
            "Epoch 58/100\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.5582 - accuracy: 0.6779 - val_loss: 0.5261 - val_accuracy: 0.7069\n",
            "Epoch 59/100\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.5583 - accuracy: 0.6791 - val_loss: 0.5239 - val_accuracy: 0.7033\n",
            "Epoch 60/100\n",
            "105/105 [==============================] - 0s 1ms/step - loss: 0.5579 - accuracy: 0.6782 - val_loss: 0.5246 - val_accuracy: 0.7069\n",
            "Epoch 61/100\n",
            "105/105 [==============================] - 0s 1ms/step - loss: 0.5579 - accuracy: 0.6788 - val_loss: 0.5233 - val_accuracy: 0.7057\n",
            "Epoch 62/100\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.5578 - accuracy: 0.6785 - val_loss: 0.5226 - val_accuracy: 0.7045\n",
            "Epoch 63/100\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.5577 - accuracy: 0.6776 - val_loss: 0.5236 - val_accuracy: 0.7069\n",
            "Epoch 64/100\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.5578 - accuracy: 0.6806 - val_loss: 0.5232 - val_accuracy: 0.7057\n",
            "Epoch 65/100\n",
            "105/105 [==============================] - 0s 1ms/step - loss: 0.5575 - accuracy: 0.6782 - val_loss: 0.5237 - val_accuracy: 0.7069\n",
            "Epoch 66/100\n",
            "105/105 [==============================] - 0s 1ms/step - loss: 0.5574 - accuracy: 0.6788 - val_loss: 0.5233 - val_accuracy: 0.7057\n",
            "Epoch 67/100\n",
            "105/105 [==============================] - 0s 1ms/step - loss: 0.5575 - accuracy: 0.6782 - val_loss: 0.5233 - val_accuracy: 0.7057\n",
            "Epoch 68/100\n",
            "105/105 [==============================] - 0s 1ms/step - loss: 0.5574 - accuracy: 0.6785 - val_loss: 0.5234 - val_accuracy: 0.7057\n",
            "Epoch 69/100\n",
            "105/105 [==============================] - 0s 1ms/step - loss: 0.5574 - accuracy: 0.6803 - val_loss: 0.5227 - val_accuracy: 0.7057\n",
            "Epoch 70/100\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.5572 - accuracy: 0.6779 - val_loss: 0.5235 - val_accuracy: 0.7081\n",
            "Epoch 71/100\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.5572 - accuracy: 0.6782 - val_loss: 0.5219 - val_accuracy: 0.7057\n",
            "Epoch 72/100\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.5571 - accuracy: 0.6779 - val_loss: 0.5233 - val_accuracy: 0.7081\n",
            "Epoch 73/100\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.5571 - accuracy: 0.6776 - val_loss: 0.5228 - val_accuracy: 0.7081\n",
            "Epoch 74/100\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.5576 - accuracy: 0.6764 - val_loss: 0.5230 - val_accuracy: 0.7057\n",
            "Epoch 75/100\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.5571 - accuracy: 0.6797 - val_loss: 0.5222 - val_accuracy: 0.7057\n",
            "Epoch 76/100\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.5569 - accuracy: 0.6767 - val_loss: 0.5230 - val_accuracy: 0.7057\n",
            "Epoch 77/100\n",
            "105/105 [==============================] - 0s 1ms/step - loss: 0.5569 - accuracy: 0.6785 - val_loss: 0.5225 - val_accuracy: 0.7069\n",
            "Epoch 78/100\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.5569 - accuracy: 0.6779 - val_loss: 0.5224 - val_accuracy: 0.7045\n",
            "Epoch 79/100\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.5568 - accuracy: 0.6776 - val_loss: 0.5238 - val_accuracy: 0.7081\n",
            "Epoch 80/100\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.5569 - accuracy: 0.6776 - val_loss: 0.5235 - val_accuracy: 0.7069\n",
            "Epoch 81/100\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.5569 - accuracy: 0.6785 - val_loss: 0.5224 - val_accuracy: 0.7045\n",
            "Epoch 82/100\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.5569 - accuracy: 0.6773 - val_loss: 0.5216 - val_accuracy: 0.7057\n",
            "Epoch 83/100\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.5567 - accuracy: 0.6785 - val_loss: 0.5222 - val_accuracy: 0.7057\n",
            "Epoch 84/100\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.5566 - accuracy: 0.6773 - val_loss: 0.5219 - val_accuracy: 0.7057\n",
            "Epoch 85/100\n",
            "105/105 [==============================] - 0s 1ms/step - loss: 0.5567 - accuracy: 0.6785 - val_loss: 0.5223 - val_accuracy: 0.7057\n",
            "Epoch 86/100\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.5566 - accuracy: 0.6782 - val_loss: 0.5216 - val_accuracy: 0.7057\n",
            "Epoch 87/100\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.5567 - accuracy: 0.6779 - val_loss: 0.5209 - val_accuracy: 0.7081\n",
            "Epoch 88/100\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.5565 - accuracy: 0.6773 - val_loss: 0.5224 - val_accuracy: 0.7057\n",
            "Epoch 89/100\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.5565 - accuracy: 0.6785 - val_loss: 0.5212 - val_accuracy: 0.7081\n",
            "Epoch 90/100\n",
            "105/105 [==============================] - 0s 1ms/step - loss: 0.5565 - accuracy: 0.6803 - val_loss: 0.5216 - val_accuracy: 0.7093\n",
            "Epoch 91/100\n",
            "105/105 [==============================] - 0s 1ms/step - loss: 0.5566 - accuracy: 0.6806 - val_loss: 0.5204 - val_accuracy: 0.7117\n",
            "Epoch 92/100\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.5564 - accuracy: 0.6788 - val_loss: 0.5218 - val_accuracy: 0.7081\n",
            "Epoch 93/100\n",
            "105/105 [==============================] - 0s 1ms/step - loss: 0.5564 - accuracy: 0.6800 - val_loss: 0.5226 - val_accuracy: 0.7057\n",
            "Epoch 94/100\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.5562 - accuracy: 0.6779 - val_loss: 0.5210 - val_accuracy: 0.7129\n",
            "Epoch 95/100\n",
            "105/105 [==============================] - 0s 1ms/step - loss: 0.5563 - accuracy: 0.6788 - val_loss: 0.5206 - val_accuracy: 0.7117\n",
            "Epoch 96/100\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.5563 - accuracy: 0.6776 - val_loss: 0.5219 - val_accuracy: 0.7117\n",
            "Epoch 97/100\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.5564 - accuracy: 0.6776 - val_loss: 0.5220 - val_accuracy: 0.7129\n",
            "Epoch 98/100\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.5563 - accuracy: 0.6803 - val_loss: 0.5211 - val_accuracy: 0.7129\n",
            "Epoch 99/100\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.5562 - accuracy: 0.6791 - val_loss: 0.5207 - val_accuracy: 0.7141\n",
            "Epoch 100/100\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.5560 - accuracy: 0.6806 - val_loss: 0.5240 - val_accuracy: 0.7057\n",
            "[array([[ 0.365278  ,  1.028557  ],\n",
            "       [ 1.0855008 ,  0.5586715 ],\n",
            "       [-0.5985794 , -1.2140353 ],\n",
            "       [-1.3562338 , -1.5436182 ],\n",
            "       [-1.0270426 , -1.248271  ],\n",
            "       [-1.9354318 , -1.3678513 ],\n",
            "       [-1.6060277 , -1.1698194 ],\n",
            "       [-0.24064931, -0.26854938]], dtype=float32), array([1.658164 , 1.8936733], dtype=float32), array([[2.7438345],\n",
            "       [2.8393013]], dtype=float32), array([-0.01671139], dtype=float32)]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#5. He Uniform Initialization\n",
        "\n",
        "##He Uniform Initialization is suitable for layers where **ReLU** activation function is used."
      ],
      "metadata": {
        "id": "K-sZPXX_qGaz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras import initializers\n",
        "\n",
        "initializer = tf.keras.initializers.HeUniform()\n",
        "\n",
        "\n",
        "model = Sequential()\n",
        "\n",
        "model.add(Dense(2,activation='relu',input_dim=8,kernel_initializer=initializer))\n",
        "model.add(Dense(1,activation='sigmoid'))\n",
        "\n",
        "print(model.summary())\n",
        "print(model.get_weights())\n",
        "\n",
        "model.compile(loss='binary_crossentropy',optimizer='adam',metrics=['accuracy'])\n",
        "history = model.fit(X,y,epochs=100,validation_split=0.2)\n",
        "print(model.get_weights())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vCBVDv9KYAot",
        "outputId": "6add8e48-9e0c-4042-9ac5-eda358c0ce2c"
      },
      "execution_count": 80,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_16\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_32 (Dense)            (None, 2)                 18        \n",
            "                                                                 \n",
            " dense_33 (Dense)            (None, 1)                 3         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 21 (84.00 Byte)\n",
            "Trainable params: 21 (84.00 Byte)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n",
            "None\n",
            "[array([[ 0.0047465 , -0.24663872],\n",
            "       [ 0.7210613 , -0.57938206],\n",
            "       [-0.35909182,  0.66962844],\n",
            "       [ 0.2841714 , -0.8145665 ],\n",
            "       [-0.74964136, -0.05001771],\n",
            "       [-0.12666923, -0.02414519],\n",
            "       [-0.6735139 ,  0.6854008 ],\n",
            "       [-0.5418669 , -0.5974921 ]], dtype=float32), array([0., 0.], dtype=float32), array([[-1.3862661 ],\n",
            "       [-0.36620188]], dtype=float32), array([0.], dtype=float32)]\n",
            "Epoch 1/100\n",
            "105/105 [==============================] - 1s 3ms/step - loss: 0.6854 - accuracy: 0.6764 - val_loss: 0.6747 - val_accuracy: 0.7153\n",
            "Epoch 2/100\n",
            "105/105 [==============================] - 0s 1ms/step - loss: 0.6713 - accuracy: 0.6800 - val_loss: 0.6589 - val_accuracy: 0.7153\n",
            "Epoch 3/100\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.6599 - accuracy: 0.6800 - val_loss: 0.6459 - val_accuracy: 0.7153\n",
            "Epoch 4/100\n",
            "105/105 [==============================] - 0s 1ms/step - loss: 0.6512 - accuracy: 0.6800 - val_loss: 0.6361 - val_accuracy: 0.7153\n",
            "Epoch 5/100\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.6447 - accuracy: 0.6800 - val_loss: 0.6281 - val_accuracy: 0.7153\n",
            "Epoch 6/100\n",
            "105/105 [==============================] - 0s 1ms/step - loss: 0.6397 - accuracy: 0.6800 - val_loss: 0.6221 - val_accuracy: 0.7153\n",
            "Epoch 7/100\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.6359 - accuracy: 0.6800 - val_loss: 0.6171 - val_accuracy: 0.7153\n",
            "Epoch 8/100\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.6332 - accuracy: 0.6800 - val_loss: 0.6134 - val_accuracy: 0.7153\n",
            "Epoch 9/100\n",
            "105/105 [==============================] - 0s 1ms/step - loss: 0.6312 - accuracy: 0.6800 - val_loss: 0.6101 - val_accuracy: 0.7153\n",
            "Epoch 10/100\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.6298 - accuracy: 0.6800 - val_loss: 0.6079 - val_accuracy: 0.7153\n",
            "Epoch 11/100\n",
            "105/105 [==============================] - 0s 1ms/step - loss: 0.6289 - accuracy: 0.6800 - val_loss: 0.6061 - val_accuracy: 0.7153\n",
            "Epoch 12/100\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.6282 - accuracy: 0.6800 - val_loss: 0.6049 - val_accuracy: 0.7153\n",
            "Epoch 13/100\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.6278 - accuracy: 0.6800 - val_loss: 0.6037 - val_accuracy: 0.7153\n",
            "Epoch 14/100\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.6274 - accuracy: 0.6800 - val_loss: 0.6031 - val_accuracy: 0.7153\n",
            "Epoch 15/100\n",
            "105/105 [==============================] - 0s 1ms/step - loss: 0.6272 - accuracy: 0.6800 - val_loss: 0.6024 - val_accuracy: 0.7153\n",
            "Epoch 16/100\n",
            "105/105 [==============================] - 0s 1ms/step - loss: 0.6271 - accuracy: 0.6800 - val_loss: 0.6020 - val_accuracy: 0.7153\n",
            "Epoch 17/100\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.6270 - accuracy: 0.6800 - val_loss: 0.6015 - val_accuracy: 0.7153\n",
            "Epoch 18/100\n",
            "105/105 [==============================] - 0s 1ms/step - loss: 0.6270 - accuracy: 0.6800 - val_loss: 0.6013 - val_accuracy: 0.7153\n",
            "Epoch 19/100\n",
            "105/105 [==============================] - 0s 1ms/step - loss: 0.6269 - accuracy: 0.6800 - val_loss: 0.6010 - val_accuracy: 0.7153\n",
            "Epoch 20/100\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.6269 - accuracy: 0.6800 - val_loss: 0.6008 - val_accuracy: 0.7153\n",
            "Epoch 21/100\n",
            "105/105 [==============================] - 0s 1ms/step - loss: 0.6269 - accuracy: 0.6800 - val_loss: 0.6009 - val_accuracy: 0.7153\n",
            "Epoch 22/100\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.6269 - accuracy: 0.6800 - val_loss: 0.6006 - val_accuracy: 0.7153\n",
            "Epoch 23/100\n",
            "105/105 [==============================] - 0s 1ms/step - loss: 0.6269 - accuracy: 0.6800 - val_loss: 0.6006 - val_accuracy: 0.7153\n",
            "Epoch 24/100\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.6269 - accuracy: 0.6800 - val_loss: 0.6005 - val_accuracy: 0.7153\n",
            "Epoch 25/100\n",
            "105/105 [==============================] - 0s 1ms/step - loss: 0.6269 - accuracy: 0.6800 - val_loss: 0.6005 - val_accuracy: 0.7153\n",
            "Epoch 26/100\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.6269 - accuracy: 0.6800 - val_loss: 0.6005 - val_accuracy: 0.7153\n",
            "Epoch 27/100\n",
            "105/105 [==============================] - 0s 1ms/step - loss: 0.6269 - accuracy: 0.6800 - val_loss: 0.6004 - val_accuracy: 0.7153\n",
            "Epoch 28/100\n",
            "105/105 [==============================] - 0s 1ms/step - loss: 0.6269 - accuracy: 0.6800 - val_loss: 0.6002 - val_accuracy: 0.7153\n",
            "Epoch 29/100\n",
            "105/105 [==============================] - 0s 1ms/step - loss: 0.6269 - accuracy: 0.6800 - val_loss: 0.6003 - val_accuracy: 0.7153\n",
            "Epoch 30/100\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.6269 - accuracy: 0.6800 - val_loss: 0.6004 - val_accuracy: 0.7153\n",
            "Epoch 31/100\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.6269 - accuracy: 0.6800 - val_loss: 0.6003 - val_accuracy: 0.7153\n",
            "Epoch 32/100\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.6269 - accuracy: 0.6800 - val_loss: 0.6002 - val_accuracy: 0.7153\n",
            "Epoch 33/100\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.6269 - accuracy: 0.6800 - val_loss: 0.6001 - val_accuracy: 0.7153\n",
            "Epoch 34/100\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.6269 - accuracy: 0.6800 - val_loss: 0.6003 - val_accuracy: 0.7153\n",
            "Epoch 35/100\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.6269 - accuracy: 0.6800 - val_loss: 0.6002 - val_accuracy: 0.7153\n",
            "Epoch 36/100\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.6269 - accuracy: 0.6800 - val_loss: 0.6002 - val_accuracy: 0.7153\n",
            "Epoch 37/100\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.6269 - accuracy: 0.6800 - val_loss: 0.6002 - val_accuracy: 0.7153\n",
            "Epoch 38/100\n",
            "105/105 [==============================] - 0s 1ms/step - loss: 0.6269 - accuracy: 0.6800 - val_loss: 0.6002 - val_accuracy: 0.7153\n",
            "Epoch 39/100\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.6269 - accuracy: 0.6800 - val_loss: 0.6003 - val_accuracy: 0.7153\n",
            "Epoch 40/100\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.6269 - accuracy: 0.6800 - val_loss: 0.6002 - val_accuracy: 0.7153\n",
            "Epoch 41/100\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.6269 - accuracy: 0.6800 - val_loss: 0.6003 - val_accuracy: 0.7153\n",
            "Epoch 42/100\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.6269 - accuracy: 0.6800 - val_loss: 0.6002 - val_accuracy: 0.7153\n",
            "Epoch 43/100\n",
            "105/105 [==============================] - 0s 1ms/step - loss: 0.6269 - accuracy: 0.6800 - val_loss: 0.6002 - val_accuracy: 0.7153\n",
            "Epoch 44/100\n",
            "105/105 [==============================] - 0s 1ms/step - loss: 0.6269 - accuracy: 0.6800 - val_loss: 0.6002 - val_accuracy: 0.7153\n",
            "Epoch 45/100\n",
            "105/105 [==============================] - 0s 1ms/step - loss: 0.6269 - accuracy: 0.6800 - val_loss: 0.6002 - val_accuracy: 0.7153\n",
            "Epoch 46/100\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.6269 - accuracy: 0.6800 - val_loss: 0.6002 - val_accuracy: 0.7153\n",
            "Epoch 47/100\n",
            "105/105 [==============================] - 0s 1ms/step - loss: 0.6269 - accuracy: 0.6800 - val_loss: 0.6002 - val_accuracy: 0.7153\n",
            "Epoch 48/100\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.6269 - accuracy: 0.6800 - val_loss: 0.6002 - val_accuracy: 0.7153\n",
            "Epoch 49/100\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.6269 - accuracy: 0.6800 - val_loss: 0.6002 - val_accuracy: 0.7153\n",
            "Epoch 50/100\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.6269 - accuracy: 0.6800 - val_loss: 0.6002 - val_accuracy: 0.7153\n",
            "Epoch 51/100\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.6269 - accuracy: 0.6800 - val_loss: 0.6002 - val_accuracy: 0.7153\n",
            "Epoch 52/100\n",
            "105/105 [==============================] - 0s 1ms/step - loss: 0.6269 - accuracy: 0.6800 - val_loss: 0.6002 - val_accuracy: 0.7153\n",
            "Epoch 53/100\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.6269 - accuracy: 0.6800 - val_loss: 0.6002 - val_accuracy: 0.7153\n",
            "Epoch 54/100\n",
            "105/105 [==============================] - 0s 1ms/step - loss: 0.6269 - accuracy: 0.6800 - val_loss: 0.6003 - val_accuracy: 0.7153\n",
            "Epoch 55/100\n",
            "105/105 [==============================] - 0s 1ms/step - loss: 0.6269 - accuracy: 0.6800 - val_loss: 0.6003 - val_accuracy: 0.7153\n",
            "Epoch 56/100\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.6269 - accuracy: 0.6800 - val_loss: 0.6003 - val_accuracy: 0.7153\n",
            "Epoch 57/100\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.6269 - accuracy: 0.6800 - val_loss: 0.6003 - val_accuracy: 0.7153\n",
            "Epoch 58/100\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.6269 - accuracy: 0.6800 - val_loss: 0.6002 - val_accuracy: 0.7153\n",
            "Epoch 59/100\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.6269 - accuracy: 0.6800 - val_loss: 0.6002 - val_accuracy: 0.7153\n",
            "Epoch 60/100\n",
            "105/105 [==============================] - 0s 1ms/step - loss: 0.6269 - accuracy: 0.6800 - val_loss: 0.6001 - val_accuracy: 0.7153\n",
            "Epoch 61/100\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.6269 - accuracy: 0.6800 - val_loss: 0.6003 - val_accuracy: 0.7153\n",
            "Epoch 62/100\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.6269 - accuracy: 0.6800 - val_loss: 0.6002 - val_accuracy: 0.7153\n",
            "Epoch 63/100\n",
            "105/105 [==============================] - 0s 1ms/step - loss: 0.6269 - accuracy: 0.6800 - val_loss: 0.6002 - val_accuracy: 0.7153\n",
            "Epoch 64/100\n",
            "105/105 [==============================] - 0s 1ms/step - loss: 0.6269 - accuracy: 0.6800 - val_loss: 0.6002 - val_accuracy: 0.7153\n",
            "Epoch 65/100\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.6269 - accuracy: 0.6800 - val_loss: 0.6002 - val_accuracy: 0.7153\n",
            "Epoch 66/100\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.6269 - accuracy: 0.6800 - val_loss: 0.6002 - val_accuracy: 0.7153\n",
            "Epoch 67/100\n",
            "105/105 [==============================] - 0s 1ms/step - loss: 0.6269 - accuracy: 0.6800 - val_loss: 0.6002 - val_accuracy: 0.7153\n",
            "Epoch 68/100\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.6269 - accuracy: 0.6800 - val_loss: 0.6002 - val_accuracy: 0.7153\n",
            "Epoch 69/100\n",
            "105/105 [==============================] - 0s 1ms/step - loss: 0.6269 - accuracy: 0.6800 - val_loss: 0.6002 - val_accuracy: 0.7153\n",
            "Epoch 70/100\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.6269 - accuracy: 0.6800 - val_loss: 0.6002 - val_accuracy: 0.7153\n",
            "Epoch 71/100\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.6269 - accuracy: 0.6800 - val_loss: 0.6002 - val_accuracy: 0.7153\n",
            "Epoch 72/100\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.6269 - accuracy: 0.6800 - val_loss: 0.6001 - val_accuracy: 0.7153\n",
            "Epoch 73/100\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.6269 - accuracy: 0.6800 - val_loss: 0.6003 - val_accuracy: 0.7153\n",
            "Epoch 74/100\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.6269 - accuracy: 0.6800 - val_loss: 0.6001 - val_accuracy: 0.7153\n",
            "Epoch 75/100\n",
            "105/105 [==============================] - 0s 1ms/step - loss: 0.6269 - accuracy: 0.6800 - val_loss: 0.6002 - val_accuracy: 0.7153\n",
            "Epoch 76/100\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.6269 - accuracy: 0.6800 - val_loss: 0.6001 - val_accuracy: 0.7153\n",
            "Epoch 77/100\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.6269 - accuracy: 0.6800 - val_loss: 0.6002 - val_accuracy: 0.7153\n",
            "Epoch 78/100\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.6269 - accuracy: 0.6800 - val_loss: 0.6002 - val_accuracy: 0.7153\n",
            "Epoch 79/100\n",
            "105/105 [==============================] - 0s 1ms/step - loss: 0.6269 - accuracy: 0.6800 - val_loss: 0.6004 - val_accuracy: 0.7153\n",
            "Epoch 80/100\n",
            "105/105 [==============================] - 0s 1ms/step - loss: 0.6269 - accuracy: 0.6800 - val_loss: 0.6003 - val_accuracy: 0.7153\n",
            "Epoch 81/100\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.6269 - accuracy: 0.6800 - val_loss: 0.6004 - val_accuracy: 0.7153\n",
            "Epoch 82/100\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.6269 - accuracy: 0.6800 - val_loss: 0.6002 - val_accuracy: 0.7153\n",
            "Epoch 83/100\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.6269 - accuracy: 0.6800 - val_loss: 0.6001 - val_accuracy: 0.7153\n",
            "Epoch 84/100\n",
            "105/105 [==============================] - 0s 1ms/step - loss: 0.6269 - accuracy: 0.6800 - val_loss: 0.6003 - val_accuracy: 0.7153\n",
            "Epoch 85/100\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.6269 - accuracy: 0.6800 - val_loss: 0.6001 - val_accuracy: 0.7153\n",
            "Epoch 86/100\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.6269 - accuracy: 0.6800 - val_loss: 0.6001 - val_accuracy: 0.7153\n",
            "Epoch 87/100\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.6269 - accuracy: 0.6800 - val_loss: 0.6002 - val_accuracy: 0.7153\n",
            "Epoch 88/100\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.6269 - accuracy: 0.6800 - val_loss: 0.6002 - val_accuracy: 0.7153\n",
            "Epoch 89/100\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.6269 - accuracy: 0.6800 - val_loss: 0.6002 - val_accuracy: 0.7153\n",
            "Epoch 90/100\n",
            "105/105 [==============================] - 0s 1ms/step - loss: 0.6269 - accuracy: 0.6800 - val_loss: 0.6002 - val_accuracy: 0.7153\n",
            "Epoch 91/100\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.6269 - accuracy: 0.6800 - val_loss: 0.6001 - val_accuracy: 0.7153\n",
            "Epoch 92/100\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.6269 - accuracy: 0.6800 - val_loss: 0.6001 - val_accuracy: 0.7153\n",
            "Epoch 93/100\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.6269 - accuracy: 0.6800 - val_loss: 0.6001 - val_accuracy: 0.7153\n",
            "Epoch 94/100\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.6269 - accuracy: 0.6800 - val_loss: 0.6003 - val_accuracy: 0.7153\n",
            "Epoch 95/100\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.6269 - accuracy: 0.6800 - val_loss: 0.6002 - val_accuracy: 0.7153\n",
            "Epoch 96/100\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.6269 - accuracy: 0.6800 - val_loss: 0.6002 - val_accuracy: 0.7153\n",
            "Epoch 97/100\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.6269 - accuracy: 0.6800 - val_loss: 0.6002 - val_accuracy: 0.7153\n",
            "Epoch 98/100\n",
            "105/105 [==============================] - 0s 1ms/step - loss: 0.6269 - accuracy: 0.6800 - val_loss: 0.6002 - val_accuracy: 0.7153\n",
            "Epoch 99/100\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.6269 - accuracy: 0.6800 - val_loss: 0.6003 - val_accuracy: 0.7153\n",
            "Epoch 100/100\n",
            "105/105 [==============================] - 0s 1ms/step - loss: 0.6269 - accuracy: 0.6800 - val_loss: 0.6004 - val_accuracy: 0.7153\n",
            "[array([[ 0.0047465 , -0.24663872],\n",
            "       [ 0.7210613 , -0.57938206],\n",
            "       [-0.35909182,  0.66962844],\n",
            "       [ 0.2841714 , -0.8145665 ],\n",
            "       [-0.74964136, -0.05001771],\n",
            "       [-0.12666923, -0.02414519],\n",
            "       [-0.6735139 ,  0.6854008 ],\n",
            "       [-0.5418669 , -0.5974921 ]], dtype=float32), array([0., 0.], dtype=float32), array([[-1.3862661 ],\n",
            "       [-0.36620188]], dtype=float32), array([0.7506338], dtype=float32)]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "tRAEDC6TYAtA"
      },
      "execution_count": 78,
      "outputs": []
    }
  ]
}